{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DAOS Documentation","title":"Home"},{"location":"#daos-documentation","text":"","title":"DAOS Documentation"},{"location":"coding/","text":"DAOS Coding Rules","title":"DAOS Coding Rules"},{"location":"coding/#daos-coding-rules","text":"","title":"DAOS Coding Rules"},{"location":"contributing/","text":"Contributing to DAOS Development","title":"Contributing to DAOS Development"},{"location":"contributing/#contributing-to-daos-development","text":"","title":"Contributing to DAOS Development"},{"location":"debugging/","text":"DAOS Debugging DAOS uses the debug system defined in CaRT but more specifically the GURT library. Logging for both client and server are written to \"/tmp/daos.log\" unless otherwise set by D_LOG_FILE . Registered Subsystems/Facilities The debug logging system includes a series of subsystems or facilities which define groups for related log messages (defined per source file). There are common facilities which are defined in GURT, as well as other facilities that can be defined on a per-project basis (such as those for CaRT and DAOS). DD_SUBSYS can be used to set which subsystems to enable logging for. By default all subsystems are enabled (\"DD_SUBSYS=all\"). - DAOS Facilities: [common, tree, vos, client, server, rdb, pool, container, object, placement, rebuild, tier, mgmt, eio, tests] - Common Facilities (GURT): [MISC, MEM] - CaRT Facilities: [RPC, BULK, CORPC, GRP, LM, HG, PMIX, ST, IV] Priority Logging All macros which output logs have a priority level, shown in decending order below. - D_FATAL(fmt, ...) FATAL - D_CRIT(fmt, ...) CRIT - D_ERROR(fmt, ...) ERR - D_WARN(fmt, ...) WARN - D_NOTE(fmt, ...) NOTE - D_INFO(fmt, ...) INFO - D_DEBUG(mask, fmt, ...) DEBUG The priority level that outputs to stderr can be set with DD_STDERR . By default in DAOS (specific to project), this is set to CRIT (\"DD_STDERR=CRIT\") meaning that all CRIT and more severe log messages will dump to stderr. This however is separate from the priority of logging to \"/tmp/daos.log\". The priority level of logging can be set with D_LOG_MASK , which by default is set to INFO (\"D_LOG_MASK=INFO\"), which will result in all messages excluding DEBUG messages being logged. D_LOG_MASK can also be used to specify the level of logging on a per-subsystem basis as well (\"D_LOG_MASK=DEBUG,MEM=ERR\"). Debug Masks/Streams: DEBUG messages account for a majority of the log messages, and finer-granularity might be desired. Mask bits are set as the first argument passed in D_DEBUG(mask, ...). In order to accomplish this, DD_MASK can be set to enable different debug streams. Similar to facilities, there are common debug streams defined in GURT, as well as other streams that can defined on a per-project basis (CaRT and DAOS). All debug streams are enabled by default (\"DD_MASK=all\"). - DAOS Debug Masks: - md = metadata operations - pl = placement operations - mgmt = pool management - epc = epoch system - df = durable format - rebuild = rebuild process - daos_default = (group mask) io, md, pl, and rebuild operations - Common Debug Masks (GURT): - any = generic messages, no classification - trace = function trace, tree/hash/lru operations - mem = memory operations - net = network operations - io = object I/O - test = test programs Common Use Cases Generic setup for all messages (default settings) $ D_LOG_MASK=DEBUG $ DD_SUBSYS=all $ DD_MASK=all Disable all logs for performance tuning $ D_LOG_MASK=ERR -> will only log error messages from all facilities $ D_LOG_MASK=FATAL -> will only log system fatal messages Disable a noisy debug logging subsystem $ D_LOG_MASK=DEBUG,MEM=ERR -> disables MEM facility by restricting all logs from that facility to ERROR or higher priority only Enable a subset of facilities of interest $ DD_SUBSYS=rpc,tests $ D_LOG_MASK=DEBUG -> required to see logs for RPC and TESTS less severe than INFO (majority of log messages) Fine-tune the debug messages by setting a debug mask $ D_LOG_MASK=DEBUG $ DD_MASK=mgmt -> only logs DEBUG messages related to pool management See DAOS Environment Variables documentation for more info about debug system environment.","title":"DAOS Debugging"},{"location":"debugging/#daos-debugging","text":"DAOS uses the debug system defined in CaRT but more specifically the GURT library. Logging for both client and server are written to \"/tmp/daos.log\" unless otherwise set by D_LOG_FILE .","title":"DAOS Debugging"},{"location":"debugging/#registered-subsystemsfacilities","text":"The debug logging system includes a series of subsystems or facilities which define groups for related log messages (defined per source file). There are common facilities which are defined in GURT, as well as other facilities that can be defined on a per-project basis (such as those for CaRT and DAOS). DD_SUBSYS can be used to set which subsystems to enable logging for. By default all subsystems are enabled (\"DD_SUBSYS=all\"). - DAOS Facilities: [common, tree, vos, client, server, rdb, pool, container, object, placement, rebuild, tier, mgmt, eio, tests] - Common Facilities (GURT): [MISC, MEM] - CaRT Facilities: [RPC, BULK, CORPC, GRP, LM, HG, PMIX, ST, IV]","title":"Registered Subsystems/Facilities"},{"location":"debugging/#priority-logging","text":"All macros which output logs have a priority level, shown in decending order below. - D_FATAL(fmt, ...) FATAL - D_CRIT(fmt, ...) CRIT - D_ERROR(fmt, ...) ERR - D_WARN(fmt, ...) WARN - D_NOTE(fmt, ...) NOTE - D_INFO(fmt, ...) INFO - D_DEBUG(mask, fmt, ...) DEBUG The priority level that outputs to stderr can be set with DD_STDERR . By default in DAOS (specific to project), this is set to CRIT (\"DD_STDERR=CRIT\") meaning that all CRIT and more severe log messages will dump to stderr. This however is separate from the priority of logging to \"/tmp/daos.log\". The priority level of logging can be set with D_LOG_MASK , which by default is set to INFO (\"D_LOG_MASK=INFO\"), which will result in all messages excluding DEBUG messages being logged. D_LOG_MASK can also be used to specify the level of logging on a per-subsystem basis as well (\"D_LOG_MASK=DEBUG,MEM=ERR\").","title":"Priority Logging"},{"location":"debugging/#debug-masksstreams","text":"DEBUG messages account for a majority of the log messages, and finer-granularity might be desired. Mask bits are set as the first argument passed in D_DEBUG(mask, ...). In order to accomplish this, DD_MASK can be set to enable different debug streams. Similar to facilities, there are common debug streams defined in GURT, as well as other streams that can defined on a per-project basis (CaRT and DAOS). All debug streams are enabled by default (\"DD_MASK=all\"). - DAOS Debug Masks: - md = metadata operations - pl = placement operations - mgmt = pool management - epc = epoch system - df = durable format - rebuild = rebuild process - daos_default = (group mask) io, md, pl, and rebuild operations - Common Debug Masks (GURT): - any = generic messages, no classification - trace = function trace, tree/hash/lru operations - mem = memory operations - net = network operations - io = object I/O - test = test programs","title":"Debug Masks/Streams:"},{"location":"debugging/#common-use-cases","text":"Generic setup for all messages (default settings) $ D_LOG_MASK=DEBUG $ DD_SUBSYS=all $ DD_MASK=all Disable all logs for performance tuning $ D_LOG_MASK=ERR -> will only log error messages from all facilities $ D_LOG_MASK=FATAL -> will only log system fatal messages Disable a noisy debug logging subsystem $ D_LOG_MASK=DEBUG,MEM=ERR -> disables MEM facility by restricting all logs from that facility to ERROR or higher priority only Enable a subset of facilities of interest $ DD_SUBSYS=rpc,tests $ D_LOG_MASK=DEBUG -> required to see logs for RPC and TESTS less severe than INFO (majority of log messages) Fine-tune the debug messages by setting a debug mask $ D_LOG_MASK=DEBUG $ DD_MASK=mgmt -> only logs DEBUG messages related to pool management See DAOS Environment Variables documentation for more info about debug system environment.","title":"Common Use Cases"},{"location":"development/","text":"DAOS for Development Building DAOS for Development For development, it is recommended to build and install each dependency in a unique subdirectory. The DAOS build system supports this through the TARGET_PREFIX variable. Once the submodules have been initialized and updated, run the following: scons PREFIX=${daos_prefix_path} TARGET_PREFIX=${daos_prefix_path}/opt install --build-deps=yes --config=force Installing the components into seperate directories allow to upgrade the components individually replacing --build-deps=yes with --update-prereq={component_name}. This requires change to the environment configuration from before. For automated environment setup, source scons_local/utils/setup_local.sh. ARGOBOTS=${daos_prefix_path}/opt/argobots CART=${daos_prefix_path}/opt/cart HWLOC=${daos_prefix_path}/opt/hwloc MERCURY=${daos_prefix_path}/opt/mercury PMDK=${daos_prefix_path}/opt/pmdk OMPI=${daos_prefix_path}/opt/ompi OPA=${daos_prefix_path}/opt/openpa PMIX=${daos_prefix_path}/opt/pmix FIO=${daos_prefix_path}/opt/fio SPDK=${daos_prefix_path}/opt/spdk PATH=$CART/bin/:$OMPI/bin/:${daos_prefix_path}/bin/:$PATH With this approach DAOS would get built using the prebuilt dependencies in ${daos_prefix_path}/opt and required options are saved for future compilations. So, after the first time, during development, a mere \"scons --config=force\" and \"scons --config=force install\" would suffice for compiling changes to daos source code. If you wish to compile DAOS with clang rather than gcc, set COMPILER=clang on the scons command line. This option is also saved for future compilations. Go dependencies Developers contributing Go code may need to change the external dependencies located in the src/control/vendor directory. The DAOS codebase uses dep to manage these dependencies. On EL7 and later: yum install yum-plugin-copr yum copr enable hnakamur/golang-dep yum install golang-dep On Fedora 27 and later: dnf install dep On Ubuntu 18.04 and later: apt-get install go-dep For OSes that don't supply a package: * Ensure that you have a personal GOPATH (see \"go env GOPATH\", referred to as \"$GOPATH\" in this document) and a GOBIN ($GOPATH/bin) set up and included in your PATH: mkdir -p $GOPATH/bin export PATH=$GOPATH/bin:$PATH Then follow the installation instructions on Github . To update the vendor directory using dep after changing Gopkg.toml, first make sure DAOS is cloned into $GOPATH/src/github.com/daos-stack/daos Then: cd $GOPATH/src/github.com/daos-stack/daos/src/control dep ensure Protobuf Compiler The DAOS control plane infrastructure uses Protocol Buffers as the data serialization format for its RPC requests. Not all developers will need to compile the *.proto files, but if Protobuf changes are needed, the developer must regenerate the corresponding C and Go source files using a Protobuf compiler compatible with proto3 syntax. Recommended Versions The recommended installation method is to clone the git repositories, check out the tagged releases noted below, and install from source. Later versions may work, but are not guaranteed. Protocol Buffers v3.5.1. Installation instructions . Protobuf-C v1.3.1. Installation instructions . gRPC plugin: protoc-gen-go v1.2.0. Must match the proto version in src/control/Gopkg.toml. Install the specific version using GIT_TAG instructions here . Compiling Protobuf Files Generate the Go file using the gRPC plugin. You can designate the directory location: protoc myfile.proto --go_out=plugins=grpc:<go_file_dir> Generate the C files using Protobuf-C. As the header and source files in DAOS are typically kept in separate locations, you will need to move them manually to their destination directories: protoc-c myfile.proto --c_out=. mv myfile.pb-c.h <c_file_include_dir> mv myfile.pb-c.c <c_file_src_dir>","title":"DAOS for Development"},{"location":"development/#daos-for-development","text":"","title":"DAOS for Development"},{"location":"development/#building-daos-for-development","text":"For development, it is recommended to build and install each dependency in a unique subdirectory. The DAOS build system supports this through the TARGET_PREFIX variable. Once the submodules have been initialized and updated, run the following: scons PREFIX=${daos_prefix_path} TARGET_PREFIX=${daos_prefix_path}/opt install --build-deps=yes --config=force Installing the components into seperate directories allow to upgrade the components individually replacing --build-deps=yes with --update-prereq={component_name}. This requires change to the environment configuration from before. For automated environment setup, source scons_local/utils/setup_local.sh. ARGOBOTS=${daos_prefix_path}/opt/argobots CART=${daos_prefix_path}/opt/cart HWLOC=${daos_prefix_path}/opt/hwloc MERCURY=${daos_prefix_path}/opt/mercury PMDK=${daos_prefix_path}/opt/pmdk OMPI=${daos_prefix_path}/opt/ompi OPA=${daos_prefix_path}/opt/openpa PMIX=${daos_prefix_path}/opt/pmix FIO=${daos_prefix_path}/opt/fio SPDK=${daos_prefix_path}/opt/spdk PATH=$CART/bin/:$OMPI/bin/:${daos_prefix_path}/bin/:$PATH With this approach DAOS would get built using the prebuilt dependencies in ${daos_prefix_path}/opt and required options are saved for future compilations. So, after the first time, during development, a mere \"scons --config=force\" and \"scons --config=force install\" would suffice for compiling changes to daos source code. If you wish to compile DAOS with clang rather than gcc, set COMPILER=clang on the scons command line. This option is also saved for future compilations.","title":"Building DAOS for Development"},{"location":"development/#go-dependencies","text":"Developers contributing Go code may need to change the external dependencies located in the src/control/vendor directory. The DAOS codebase uses dep to manage these dependencies. On EL7 and later: yum install yum-plugin-copr yum copr enable hnakamur/golang-dep yum install golang-dep On Fedora 27 and later: dnf install dep On Ubuntu 18.04 and later: apt-get install go-dep For OSes that don't supply a package: * Ensure that you have a personal GOPATH (see \"go env GOPATH\", referred to as \"$GOPATH\" in this document) and a GOBIN ($GOPATH/bin) set up and included in your PATH: mkdir -p $GOPATH/bin export PATH=$GOPATH/bin:$PATH Then follow the installation instructions on Github . To update the vendor directory using dep after changing Gopkg.toml, first make sure DAOS is cloned into $GOPATH/src/github.com/daos-stack/daos Then: cd $GOPATH/src/github.com/daos-stack/daos/src/control dep ensure","title":"Go dependencies"},{"location":"development/#protobuf-compiler","text":"The DAOS control plane infrastructure uses Protocol Buffers as the data serialization format for its RPC requests. Not all developers will need to compile the *.proto files, but if Protobuf changes are needed, the developer must regenerate the corresponding C and Go source files using a Protobuf compiler compatible with proto3 syntax.","title":"Protobuf Compiler"},{"location":"development/#recommended-versions","text":"The recommended installation method is to clone the git repositories, check out the tagged releases noted below, and install from source. Later versions may work, but are not guaranteed. Protocol Buffers v3.5.1. Installation instructions . Protobuf-C v1.3.1. Installation instructions . gRPC plugin: protoc-gen-go v1.2.0. Must match the proto version in src/control/Gopkg.toml. Install the specific version using GIT_TAG instructions here .","title":"Recommended Versions"},{"location":"development/#compiling-protobuf-files","text":"Generate the Go file using the gRPC plugin. You can designate the directory location: protoc myfile.proto --go_out=plugins=grpc:<go_file_dir> Generate the C files using Protobuf-C. As the header and source files in DAOS are typically kept in separate locations, you will need to move them manually to their destination directories: protoc-c myfile.proto --c_out=. mv myfile.pb-c.h <c_file_include_dir> mv myfile.pb-c.c <c_file_src_dir>","title":"Compiling Protobuf Files"},{"location":"environ/","text":"DAOS Environment Variables This file lists the environment variables used by DAOS. Many of them are meant for development purposes only and may be removed or changed in the future. The description of each variable follows the following format: A short description. Type . Default to what behavior if not set. A longer description if necessary. Type is defined by this table: Type Values BOOL 0 means false; any other value means true BOOL2 no means false; any other value means true BOOL3 set to empty or any value means true; unset means false INTEGER Non-negative decimal integer STRING String Common Environment variables in this section apply to both the server side and the client side DAOS_IO_MODE Control the DAOS IO mode: server dispatches modification RPCs to replicas or client does that, if it is the former case, whether enable DTX or not. INTEGER . Valid values are as following, default to 0 (server dispatches RPCs and enable DTX). 0: server dispatches RPCs, enable DTX. 1: server dispatches RPCs, disable DTX. 2: client disptaches RPCs, disable DTX. DAOS_IO_BYPASS Server Environment variables in this section only apply to the server side. VOS_CHECKSUM Checksum algorithm used by VOS. STRING . Default to disabling checksums. These checksum algorithms are currently supported: crc64 and crc32 . VOS_MEM_CLASS Memory class used by VOS. STRING . Default to persistent memory. If the value is set to DRAM , all data will be stored in volatile memory; otherwise, all data will be stored to persistent memory. VOS_BDEV_CLASS SPDK bdev class used by VOS. STRING . Default to NVMe bdev. When testing on node without NVMe device available, it can be set to MALLOC or AIO to make VOS using SPDK malloc or AIO device. IO_STAT_PERIOD Print SPDK bdev io statistics periodically. INTEGER . Default to 0 (disabled). If it is set to N (non-zero), SPDK bdev io statistics will be printed on server console in every N seconds. RDB_ELECTION_TIMEOUT Raft election timeout used by RDBs in milliseconds. INTEGER . Default to 7000 ms. RDB_REQUEST_TIMEOUT Raft request timeout used by RDBs in milliseconds. INTEGER . Default to 3000 ms. RDB_COMPACT_THRESHOLD Raft log compaction threshold in applied entries. INTEGER . Default to 0 entries. If set to 0, Raft log entries will never be compacted. DAOS_REBUILD Whether to start rebuilds when excluding targets. BOOL2 . Default to true. DAOS_MD_CAP Size of a metadata pmem pool/file in MBs. INTEGER . Default to 128 MB. DAOS_START_POOL_SVC Whether to start existing pool services when starting a daos_server . BOOL . Default to true. DAOS_IMPLICIT_PURGE Whether to aggregate unreferenced epochs. BOOL . Default to false. DAOS_PMIXLESS Whether to disable PMIx. BOOL . Default to false. Client Environment variables in this section only apply to the client side. DAOS_SINGLETON_CLI Whether to run in the singleton mode, in which the client does not need to be launched by orterun. BOOL . Default to false. DAOS_IO_SRV_DISPATCH Whether to enable the server-side IO dispatch, in that case the replica IO will be sent to a leader shard which will dispatch to other shards. BOOL . Default to true. Debug System (Client & Server) D_LOG_FILE DAOS debug logs (both server and client) are written to /tmp/daos.log by default. This can be modified by setting this environment variable (\"D_LOG_FILE=/tmp/daos_server\"). DD_SUBSYS Used to specify which subsystems to enable. DD_SUBSYS can be set to individual subsystems for finer-grained debugging (\"DD_SUBSYS=vos\"), multiple facilities (\"DD_SUBSYS=eio,mgmt,misc,mem\"), or all facilities (\"DD_SUBSYS=all\") which is also the default setting. If a facility is not enabled, then only ERR messages or more severe messages will print. DD_STDERR Used to specify the priority level to output to stderr. Options in decreasing priority level order: FATAL, CRIT, ERR, WARN, NOTE, INFO, DEBUG. By default, all CRIT and more severe DAOS messages will log to stderr (\"DD_STDERR=CRIT\"), and the default for CaRT/GURT is FATAL. D_LOG_MASK Used to specify what type/level of logging will be present for either all of the registered subsystems, or a select few. Options in decreasing priority level order: FATAL, CRIT, ERR, WARN, NOTE, INFO, DEBUG. DEBUG option is used to enable all logging (debug messages as well as all higher priority level messages). Note that if D_LOG_MASK is not set, it will default to logging all messages excluding debug (\"D_LOG_MASK=INFO\"). EX: \"D_LOG_MASK=DEBUG\" This will set the logging level for all facilities to DEBUG, meaning that all debug messages, as well as higher priority messages will be logged (INFO, NOTE, WARN, ERR, CRIT, FATAL). EX: \"D_LOG_MASK=DEBUG,MEM=ERR,RPC=ERR\" This will set the logging level to DEBUG for all facilities except MEM & RPC (which will now only log ERR and higher priority level messages, skipping all DEBUG, INFO, NOTE & WARN messages) DD_MASK Used to enable different debug streams for finer-grained debug messages, essentially allowing the user to specify an area of interest to debug (possibly involving many different subsystems) as opposed to parsing through many lines of generic DEBUG messages. All debug streams will be enabled by default (\"DD_MASK=all\"). Single debug masks can be set (\"DD_MASK=trace\") or multiple masks (\"DD_MASK=trace,test,mgmt\"). Note that since these debug streams are strictly related to the debug log messages, D_LOG_MASK must be set to DEBUG.","title":"DAOS Environment Variables"},{"location":"environ/#daos-environment-variables","text":"This file lists the environment variables used by DAOS. Many of them are meant for development purposes only and may be removed or changed in the future. The description of each variable follows the following format: A short description. Type . Default to what behavior if not set. A longer description if necessary. Type is defined by this table: Type Values BOOL 0 means false; any other value means true BOOL2 no means false; any other value means true BOOL3 set to empty or any value means true; unset means false INTEGER Non-negative decimal integer STRING String","title":"DAOS Environment Variables"},{"location":"environ/#common","text":"Environment variables in this section apply to both the server side and the client side","title":"Common"},{"location":"environ/#daos_io_mode","text":"Control the DAOS IO mode: server dispatches modification RPCs to replicas or client does that, if it is the former case, whether enable DTX or not. INTEGER . Valid values are as following, default to 0 (server dispatches RPCs and enable DTX). 0: server dispatches RPCs, enable DTX. 1: server dispatches RPCs, disable DTX. 2: client disptaches RPCs, disable DTX.","title":"DAOS_IO_MODE"},{"location":"environ/#daos_io_bypass","text":"","title":"DAOS_IO_BYPASS"},{"location":"environ/#server","text":"Environment variables in this section only apply to the server side.","title":"Server"},{"location":"environ/#vos_checksum","text":"Checksum algorithm used by VOS. STRING . Default to disabling checksums. These checksum algorithms are currently supported: crc64 and crc32 .","title":"VOS_CHECKSUM"},{"location":"environ/#vos_mem_class","text":"Memory class used by VOS. STRING . Default to persistent memory. If the value is set to DRAM , all data will be stored in volatile memory; otherwise, all data will be stored to persistent memory.","title":"VOS_MEM_CLASS"},{"location":"environ/#vos_bdev_class","text":"SPDK bdev class used by VOS. STRING . Default to NVMe bdev. When testing on node without NVMe device available, it can be set to MALLOC or AIO to make VOS using SPDK malloc or AIO device.","title":"VOS_BDEV_CLASS"},{"location":"environ/#io_stat_period","text":"Print SPDK bdev io statistics periodically. INTEGER . Default to 0 (disabled). If it is set to N (non-zero), SPDK bdev io statistics will be printed on server console in every N seconds.","title":"IO_STAT_PERIOD"},{"location":"environ/#rdb_election_timeout","text":"Raft election timeout used by RDBs in milliseconds. INTEGER . Default to 7000 ms.","title":"RDB_ELECTION_TIMEOUT"},{"location":"environ/#rdb_request_timeout","text":"Raft request timeout used by RDBs in milliseconds. INTEGER . Default to 3000 ms.","title":"RDB_REQUEST_TIMEOUT"},{"location":"environ/#rdb_compact_threshold","text":"Raft log compaction threshold in applied entries. INTEGER . Default to 0 entries. If set to 0, Raft log entries will never be compacted.","title":"RDB_COMPACT_THRESHOLD"},{"location":"environ/#daos_rebuild","text":"Whether to start rebuilds when excluding targets. BOOL2 . Default to true.","title":"DAOS_REBUILD"},{"location":"environ/#daos_md_cap","text":"Size of a metadata pmem pool/file in MBs. INTEGER . Default to 128 MB.","title":"DAOS_MD_CAP"},{"location":"environ/#daos_start_pool_svc","text":"Whether to start existing pool services when starting a daos_server . BOOL . Default to true.","title":"DAOS_START_POOL_SVC"},{"location":"environ/#daos_implicit_purge","text":"Whether to aggregate unreferenced epochs. BOOL . Default to false.","title":"DAOS_IMPLICIT_PURGE"},{"location":"environ/#daos_pmixless","text":"Whether to disable PMIx. BOOL . Default to false.","title":"DAOS_PMIXLESS"},{"location":"environ/#client","text":"Environment variables in this section only apply to the client side.","title":"Client"},{"location":"environ/#daos_singleton_cli","text":"Whether to run in the singleton mode, in which the client does not need to be launched by orterun. BOOL . Default to false.","title":"DAOS_SINGLETON_CLI"},{"location":"environ/#daos_io_srv_dispatch","text":"Whether to enable the server-side IO dispatch, in that case the replica IO will be sent to a leader shard which will dispatch to other shards. BOOL . Default to true.","title":"DAOS_IO_SRV_DISPATCH"},{"location":"environ/#debug-system-client-server","text":"","title":"Debug System (Client &amp; Server)"},{"location":"environ/#d_log_file","text":"DAOS debug logs (both server and client) are written to /tmp/daos.log by default. This can be modified by setting this environment variable (\"D_LOG_FILE=/tmp/daos_server\").","title":"D_LOG_FILE"},{"location":"environ/#dd_subsys","text":"Used to specify which subsystems to enable. DD_SUBSYS can be set to individual subsystems for finer-grained debugging (\"DD_SUBSYS=vos\"), multiple facilities (\"DD_SUBSYS=eio,mgmt,misc,mem\"), or all facilities (\"DD_SUBSYS=all\") which is also the default setting. If a facility is not enabled, then only ERR messages or more severe messages will print.","title":"DD_SUBSYS"},{"location":"environ/#dd_stderr","text":"Used to specify the priority level to output to stderr. Options in decreasing priority level order: FATAL, CRIT, ERR, WARN, NOTE, INFO, DEBUG. By default, all CRIT and more severe DAOS messages will log to stderr (\"DD_STDERR=CRIT\"), and the default for CaRT/GURT is FATAL.","title":"DD_STDERR"},{"location":"environ/#d_log_mask","text":"Used to specify what type/level of logging will be present for either all of the registered subsystems, or a select few. Options in decreasing priority level order: FATAL, CRIT, ERR, WARN, NOTE, INFO, DEBUG. DEBUG option is used to enable all logging (debug messages as well as all higher priority level messages). Note that if D_LOG_MASK is not set, it will default to logging all messages excluding debug (\"D_LOG_MASK=INFO\"). EX: \"D_LOG_MASK=DEBUG\" This will set the logging level for all facilities to DEBUG, meaning that all debug messages, as well as higher priority messages will be logged (INFO, NOTE, WARN, ERR, CRIT, FATAL). EX: \"D_LOG_MASK=DEBUG,MEM=ERR,RPC=ERR\" This will set the logging level to DEBUG for all facilities except MEM & RPC (which will now only log ERR and higher priority level messages, skipping all DEBUG, INFO, NOTE & WARN messages)","title":"D_LOG_MASK"},{"location":"environ/#dd_mask","text":"Used to enable different debug streams for finer-grained debug messages, essentially allowing the user to specify an area of interest to debug (possibly involving many different subsystems) as opposed to parsing through many lines of generic DEBUG messages. All debug streams will be enabled by default (\"DD_MASK=all\"). Single debug masks can be set (\"DD_MASK=trace\") or multiple masks (\"DD_MASK=trace,test,mgmt\"). Note that since these debug streams are strictly related to the debug log messages, D_LOG_MASK must be set to DEBUG.","title":"DD_MASK"},{"location":"admin/","text":"DAOS Administrator Guide","title":"DAOS Administrator Guide"},{"location":"admin/#daos-administrator-guide","text":"","title":"DAOS Administrator Guide"},{"location":"admin/administration/","text":"DAOS System Administration System Monitoring System monitoring and telemetry data will be provided as part of the control plane and will be documented in a future revision. System Operations Full Shutdown and Restart Details on how to support proper DAOS server shutdown will be provided in a future revision. Fault Domain Maintenance and Reintegration Details on how to drain an individual storage node or fault domain (e.g. rack) in preparation for maintenance activity and how to reintegrate it will be provided in a future revision. DAOS System Extension Ability to add new DAOS server instances to a pre-existing DAOS system will be documented in a future revision. Fault Management DAOS relies on massively distributed single-ported storage. Each target is thus effectively a single point of failure. DAOS achieves availability and durability of both data and metadata by providing redundancy across targets in different fault domains. Fault Detection & Isolation DAOS servers are monitored within a DAOS system through a gossip-based protocol called SWIM ^1 that provides accurate, efficient, and scalable server fault detection. Storage attached to each DAOS target is monitored through periodic local health assessment. Whenever a local storage I/O error is returned to the DAOS server, an internal health check procedure will be called automatically. This procedure makes an overall health assessment by analyzing the IO error code and device SMART/Health data. If the result is negative, the target will be marked as faulty, and further I/Os to this target will be rejected and re-routed. Once detected, the faulty target or servers (effectively a set of targets) must be excluded from each pool membership. This process is triggered either manually by the administrator or automatically (see next section for more information). Upon exclusion from the pool map, each target starts the collective rebuild process automatically to restore data redundancy. The rebuild process is designed to operate online while servers continue to process incoming I/O operations from applications. Tools to monitor and manage rebuild are still under development. Rebuild Throttling The rebuild process may consume many resources on each server and can be throttled to reduce the impact on application performance. This current logic relies on CPU cycles on the storage nodes. By default, the rebuild process is configured to consume up to 30% of the CPU cycles, leaving the other 70% for regular I/O operations. During the rebuild process, the user can set the throttle to guarantee the rebuild will not use more resource than the user setting. The user can only set the CPU cycle for now. For example, if the user set the throttle to 50, then the rebuild will at most use 50% of the CPU cycle to do the rebuild job. The default rebuild throttle for CPU cycle is 30. This parameter can be changed via the daos_mgmt_set_params() API call and will be eventually available through the management tools. Software Upgrade Interoperability in DAOS is handled via protocol and schema versioning for persistent data structures. Further instructions on how to manage DAOS software upgrades will be provided in a future revision. Protocol Interoperability Limited protocol interoperability is provided by the DAOS storage stack. Version compatibility checks will be performed to verify that: All targets in the same pool run the same protocol version. Client libraries linked with the application may be up to one protocol version older than the targets. If a protocol version mismatch is detected among storage targets in the same pool, the entire DAOS system will fail to start up and will report failure to the control API. Similarly, the connection from clients running a protocol version incompatible with the targets will return an error. Persistent Schema Compatibility and Update The schema of persistent data structures may evolve from time to time to fix bugs, add new optimizations, or support new features. To that end, the persistent data structures support schema versioning. Upgrading the schema version will not be performed automatically and must be initiated by the administrator. A dedicated upgrade tool will be provided to upgrade the schema version to the latest one. All targets in the same pool must have the same schema version. Version checks are performed at system initialization time to enforce this constraint. To limit the validation matrix, each new DAOS release will be published with a list of supported schema versions. To run with the new DAOS release, administrators will then need to upgrade the DAOS system to one of the supported schema versions. New pool shards will always be formatted with the latest version. This versioning schema only applies to a data structure stored in persistent memory and not to block storage that only stores user data with no metadata. Storage Scrubbing Support for end-to-end data integrity is planned for DAOS v1.2 and background checksum scrubbing for v2.2. Once available, that functionality will be documented here.","title":"System Administration"},{"location":"admin/administration/#daos-system-administration","text":"","title":"DAOS System Administration"},{"location":"admin/administration/#system-monitoring","text":"System monitoring and telemetry data will be provided as part of the control plane and will be documented in a future revision.","title":"System Monitoring"},{"location":"admin/administration/#system-operations","text":"","title":"System Operations"},{"location":"admin/administration/#full-shutdown-and-restart","text":"Details on how to support proper DAOS server shutdown will be provided in a future revision.","title":"Full Shutdown and Restart"},{"location":"admin/administration/#fault-domain-maintenance-and-reintegration","text":"Details on how to drain an individual storage node or fault domain (e.g. rack) in preparation for maintenance activity and how to reintegrate it will be provided in a future revision.","title":"Fault Domain Maintenance and Reintegration"},{"location":"admin/administration/#daos-system-extension","text":"Ability to add new DAOS server instances to a pre-existing DAOS system will be documented in a future revision.","title":"DAOS System Extension"},{"location":"admin/administration/#fault-management","text":"DAOS relies on massively distributed single-ported storage. Each target is thus effectively a single point of failure. DAOS achieves availability and durability of both data and metadata by providing redundancy across targets in different fault domains.","title":"Fault Management"},{"location":"admin/administration/#fault-detection-isolation","text":"DAOS servers are monitored within a DAOS system through a gossip-based protocol called SWIM ^1 that provides accurate, efficient, and scalable server fault detection. Storage attached to each DAOS target is monitored through periodic local health assessment. Whenever a local storage I/O error is returned to the DAOS server, an internal health check procedure will be called automatically. This procedure makes an overall health assessment by analyzing the IO error code and device SMART/Health data. If the result is negative, the target will be marked as faulty, and further I/Os to this target will be rejected and re-routed. Once detected, the faulty target or servers (effectively a set of targets) must be excluded from each pool membership. This process is triggered either manually by the administrator or automatically (see next section for more information). Upon exclusion from the pool map, each target starts the collective rebuild process automatically to restore data redundancy. The rebuild process is designed to operate online while servers continue to process incoming I/O operations from applications. Tools to monitor and manage rebuild are still under development.","title":"Fault Detection &amp; Isolation"},{"location":"admin/administration/#rebuild-throttling","text":"The rebuild process may consume many resources on each server and can be throttled to reduce the impact on application performance. This current logic relies on CPU cycles on the storage nodes. By default, the rebuild process is configured to consume up to 30% of the CPU cycles, leaving the other 70% for regular I/O operations. During the rebuild process, the user can set the throttle to guarantee the rebuild will not use more resource than the user setting. The user can only set the CPU cycle for now. For example, if the user set the throttle to 50, then the rebuild will at most use 50% of the CPU cycle to do the rebuild job. The default rebuild throttle for CPU cycle is 30. This parameter can be changed via the daos_mgmt_set_params() API call and will be eventually available through the management tools.","title":"Rebuild Throttling"},{"location":"admin/administration/#software-upgrade","text":"Interoperability in DAOS is handled via protocol and schema versioning for persistent data structures. Further instructions on how to manage DAOS software upgrades will be provided in a future revision.","title":"Software Upgrade"},{"location":"admin/administration/#protocol-interoperability","text":"Limited protocol interoperability is provided by the DAOS storage stack. Version compatibility checks will be performed to verify that: All targets in the same pool run the same protocol version. Client libraries linked with the application may be up to one protocol version older than the targets. If a protocol version mismatch is detected among storage targets in the same pool, the entire DAOS system will fail to start up and will report failure to the control API. Similarly, the connection from clients running a protocol version incompatible with the targets will return an error.","title":"Protocol Interoperability"},{"location":"admin/administration/#persistent-schema-compatibility-and-update","text":"The schema of persistent data structures may evolve from time to time to fix bugs, add new optimizations, or support new features. To that end, the persistent data structures support schema versioning. Upgrading the schema version will not be performed automatically and must be initiated by the administrator. A dedicated upgrade tool will be provided to upgrade the schema version to the latest one. All targets in the same pool must have the same schema version. Version checks are performed at system initialization time to enforce this constraint. To limit the validation matrix, each new DAOS release will be published with a list of supported schema versions. To run with the new DAOS release, administrators will then need to upgrade the DAOS system to one of the supported schema versions. New pool shards will always be formatted with the latest version. This versioning schema only applies to a data structure stored in persistent memory and not to block storage that only stores user data with no metadata.","title":"Persistent Schema Compatibility and Update"},{"location":"admin/administration/#storage-scrubbing","text":"Support for end-to-end data integrity is planned for DAOS v1.2 and background checksum scrubbing for v2.2. Once available, that functionality will be documented here.","title":"Storage Scrubbing"},{"location":"admin/app_interface_tiering/","text":"Application Interface and Tiering DAOS Container Management DAOS containers are the unit of data management for users. Container Creation/Destroy Containers can be created and destroyed through the daos_cont_create/destroy() functions exported by the DAOS API. A user tool called daos is also provided to manage containers. To create a container: $ daos container create --pool=a171434a-05a5-4671-8fe2-615aa0d05094 --svc=0 Successfully created container 008123fc-6b6c-4768-a88a-a2a5ef34a1a2 The container type (i.e., POSIX or HDF5) can be passed via the --type option. As shown below, the pool UUID, container UUID, and container attributes can be stored in the extended attributes of a POSIX file or directory for convenience. Then subsequent invocations of the daos tools need to reference the path to the POSIX file or directory. $ daos container create --pool=a171434a-05a5-4671-8fe2-615aa0d05094 --svc=0 --path=/tmp/mycontainer --type=POSIX --oclass=large --chunk_size=4K Successfully created container 419b7562-5bb8-453f-bd52-917c8f5d80d1 type POSIX $ daos container query --svc=0 --path=/tmp/mycontainer Pool UUID: a171434a-05a5-4671-8fe2-615aa0d05094 Container UUID: 419b7562-5bb8-453f-bd52-917c8f5d80d1 Number of snapshots: 0 Latest Persistent Snapshot: 0 DAOS Unified Namespace Attributes on path /tmp/mycontainer: Container Type: POSIX Object Class: large Chunk Size: 4096 Container Properties At creation time, a list of container properties can be specified: DAOS_PROP_CO_LABEL is a string that a user can associate with a container. e.g., \"Cat Pics\" or \"ResNet-50 training data\" DAOS_PROP_CO_LAYOUT_TYPE is the container type (POSIX, MPI-IO, HDF5, ...) DAOS_PROP_CO_LAYOUT_VER is a version of the layout that can be used by I/O middleware and application to handle interoperability. DAOS_PROP_CO_CSUM defines whether checksums are enabled or disabled and the checksum type used. DAOS_PROP_CO_REDUN_FAC is the redundancy factor that drives the minimal data protection required for objects stored in the container. e.g., RF1 means no data protection, RF3 only allows 3-way replication or erasure code N+2. DAOS_PROP_CO_REDUN_LVL is the fault domain level that should be used to place data redundancy information (e.g., storage nodes, racks ...). This information will be eventually consumed to determine object placement. DAOS_PROP_CO_SNAPSHOT_MAX is the maximum number of snapshots to retain. When a new snapshot is taken, and the threshold is reached, the oldest snapshot will be automatically deleted. DAOS_PROP_CO_ACL is the list of ACL for the container. DAOS_PROP_CO_COMPRESS and DAOS_PROP_CO_ENCRYPT are reserved for configuring respectively compression and encryption. These features are currently not on the roadmap. While those properties are currently stored persistently with container metadata, many of them are still under development. The ability to modify some of these properties on an existing container will also be provided in a future release. Container Snapshot Similar to container create/destroy, a container can be snapshotted through the DAOS API by calling daos_cont_create_snap(). Additional functions are provided to destroy and list container snapshots. The API also provides the ability to subscribe to container snapshot events and to rollback the content of a container to a previous snapshot, but those operations are not yet fully implemented. This section will be updated once support for container snapshot is supported by the daos tool. Container User Attributes Similar to POSIX extended attributes, users can attach some metadata to each container through the daos_cont_{list/get/set}_attr() API. Container ACLs Support for per-container ACLs is scheduled for DAOS v1.2. Similar to pool ACLs, container ACLs will implement a subset of the NFSv4 ACL standard. This feature will be documented here once available. Native Programming Interface Building against the DAOS library To build application or I/O middleware against the native DAOS API, include the daos.h header file in your program and link with -Ldaos. Examples are available under src/tests. DAOS API Reference libdaos is written in C and uses Doxygen comments that are added to C header files. [TODO] Generate Doxygen document and add a link here. Bindings to Different Languages API bindings to both Python ^1 and Go ^2 languages are available. POSIX Filesystem A regular POSIX namespace can be encapsulated into a DAOS container. This capability is provided by the libdfs library that implements the file and directory abstractions over the native libdaos library. The POSIX emulation can be exposed to applications or I/O frameworks either directly (e.g., for frameworks Spark or TensorFlow, or benchmark like IOR or mdtest that support different a storage backend plugin), or transparently via a FUSE daemon, combined optionally with an interception library to address some of the FUSE performance bottleneck by delivering full OS bypass for POSIX read/write operations. libdfs DFS stands for DAOS File System and is a library that allows a DAOS container to be accessed as a hierarchical POSIX namespace. It supports files, directories, and symbolic links, but not hard links. Access permissions are inherited from the parent pool and not implemented on a per-file or per-directory basis. setuid() and setgid() programs, as well as supplementary groups, are currently not supported. While libdfs can be tested from a single instance (i.e. single process or client node if used through dfuse), special care is required when the same POSIX container is mounted concurrently by multiple processes. Concurrent DFS mounts are not recommended. Support for concurrency control is under development and will be documented here once ready. dfuse A fuse daemon called dfuse is provided to mount a POSIX container in the local filesystem tree. dfuse exposes one mountpoint as a single DFS namespace with a single pool and container and can be mounted by regular use (provided that it is granted access to the pool and container). To mount an existing POSIX container with dfuse, run the following command: $ dfuse -p a171434a-05a5-4671-8fe2-615aa0d05094 -s 0 -c 464e68ca-0a30-4a5f-8829-238e890899d2 -m /tmp/daos -S The UUID after -p and -c should be replaced with respectively the pool and container UUID. -s should be followed by the pool svc rank list and -m is the local directory where the mount point will be setup. When done, the file system can be unmounted via fusermount: $ fusermount -u /tmp/daos libioil An interception library called libioil is under development. This library will work in conjunction with dfuse and allow to intercept POSIX read(2) and write(2) and issue the I/O operations directly from the application context through libdaos and without any application changes. Support for libioil is currently planned for DAOS v1.2. Unified Namespace The DAOS tier can be tightly integrated with the Lustre parallel filesystem in which DAOS containers will be represented through the Lustre namespace. This capability is under development and is scheduled for DAOS v1.2. Current state of work can be summarized as follow : DAOS integration with Lustre uses the Lustre foreign file/dir feature (from LU-11376 and associated patches) each time a DAOS POSIX container is created, using daos utility and its '--path' UNS option, a Lustre foreign file/dir of 'daos' type is being created with a specific LOV/LMV EA content that will allow to store the DAOS pool and containers UUIDs. Lustre Client patch for LU-12682, adds DAOS specific support to the Lustre foreign file/dir feature. It allows for foreign file/dir of daos type to be presented and act as <absolute-prefix>/<pool-uuid>/<container-uuid> a symlink to the Linux Kernel/VFS. the can be specified as the new daos=<absolute-prefix> Lustre Client mount option, or also thru the new llite.*.daos_prefix Lustre dynamic tuneable. And both and are extracted from foreign file/dir LOV/LMV EA. to allow for symlink resolution and transparent access to DAOS concerned container content, it is expected that a DFuse/DFS instance/mount, of DAOS Server root, exists on presenting all served pools/containers as <pool-uuid>/<container-uuid> relative paths. daos foreign support is enabled at mount time with daos= option present, or dynamically thru llite.*.daos_enable setting. HPC I/O Middleware Support Several HPC I/O middleware libraries have been ported to the native API. MPI-IO DAOS has its own MPI-IO ROM ADIO driver located in a MPICH fork on GitHub: https://github.com/daos-stack/mpich This driver has been submitted upstream for integration. To build the MPI-IO driver: export MPI_LIB=\"\" download the mpich repo from above and switch to daos_adio branch ./autogen.sh mkdir build; cd build ../configure --prefix=dir --enable-fortran=all --enable-romio --enable-cxx --enable-g=all --enable-debuginfo --with-file-system=ufs+daos --with-daos=dir --with-cart=dir make -j8; make install Switch the PATH and LD_LIBRARY_PATH to where you want to build your client apps or libs that use MPI to the installed MPICH. Note that the DAOS server will still need to be launched with OMPI's orterun. This is a unique situation where the server uses OMPI, and the clients will be launched with MPICH. Build any client (HDF5, ior, mpi test suites) normally with the mpicc and mpich library installed above (see child pages). To run an example: Launch DAOS server(s) and create a pool as specified in the previous section. This will return a pool uuid \"puuid\" and service rank list \"svcl\" At the client side, the following environment variables need to be set: export PATH=/path/to/mpich/install/bin:$PATH export LD_LIBRARY_PATH=/path/to/mpich/install/lib:$LD_LIBRARY_PATH export MPI_LIB=\"\" export CRT_ATTACH_INFO_PATH=/path/ (whatever was passed to daos_server start -a) export DAOS_SINGLETON_CLI=1 export DAOS_POOL=puuid; export DAOS_SVCL=svcl This is just temporary till we have a better way of passing pool connect info to MPI-IO and other middleware over DAOS. Run the client application or test. Limitations to the current implementation include: Incorrect MPI_File_set_size and MPI_File_get_size - This will be fixed in the future when DAOS correctly supports records enumeration after punch or key query for max/min key and recx. Reading Holes does not return 0, but leaves the buffer untouched No support for MPI file atomicity, preallocate, shared file pointers. HDF5 A prototype version of an HDF5 DAOS connector is available. Please refer to the DAOS VOL connector user guide ^3 for instructions on how to build and use it. Spark Support Spark integration with libdfs is under development and is scheduled for DAOS v1.0 or v1.2. Data Migration Migration to/from a POSIX filesystem A dataset mover tool is under consideration to move a snapshot of a POSIX, MPI-IO or HDF5 container to a POSIX filesystem and vice versa. The copy will be performed at the POSIX or HDF5 level. The resulting HDF5 file over the POSIX filesystem will be accessible through the native HDF5 connector with the POSIX VFD. The first version of the mover tool is currently scheduled for DAOS v1.4. Container Parking The mover tool will also eventually support the ability to serialize and deserialize a DAOS container to a set of POSIX files that can be stored or \"parked\" in an external POSIX filesystem. This transformation is agnostic to the data model and container type and will retain all DAOS internal metadata.","title":"Applications Interface and Tiering"},{"location":"admin/app_interface_tiering/#application-interface-and-tiering","text":"","title":"Application Interface and Tiering"},{"location":"admin/app_interface_tiering/#daos-container-management","text":"DAOS containers are the unit of data management for users.","title":"DAOS Container Management"},{"location":"admin/app_interface_tiering/#container-creationdestroy","text":"Containers can be created and destroyed through the daos_cont_create/destroy() functions exported by the DAOS API. A user tool called daos is also provided to manage containers. To create a container: $ daos container create --pool=a171434a-05a5-4671-8fe2-615aa0d05094 --svc=0 Successfully created container 008123fc-6b6c-4768-a88a-a2a5ef34a1a2 The container type (i.e., POSIX or HDF5) can be passed via the --type option. As shown below, the pool UUID, container UUID, and container attributes can be stored in the extended attributes of a POSIX file or directory for convenience. Then subsequent invocations of the daos tools need to reference the path to the POSIX file or directory. $ daos container create --pool=a171434a-05a5-4671-8fe2-615aa0d05094 --svc=0 --path=/tmp/mycontainer --type=POSIX --oclass=large --chunk_size=4K Successfully created container 419b7562-5bb8-453f-bd52-917c8f5d80d1 type POSIX $ daos container query --svc=0 --path=/tmp/mycontainer Pool UUID: a171434a-05a5-4671-8fe2-615aa0d05094 Container UUID: 419b7562-5bb8-453f-bd52-917c8f5d80d1 Number of snapshots: 0 Latest Persistent Snapshot: 0 DAOS Unified Namespace Attributes on path /tmp/mycontainer: Container Type: POSIX Object Class: large Chunk Size: 4096","title":"Container Creation/Destroy"},{"location":"admin/app_interface_tiering/#container-properties","text":"At creation time, a list of container properties can be specified: DAOS_PROP_CO_LABEL is a string that a user can associate with a container. e.g., \"Cat Pics\" or \"ResNet-50 training data\" DAOS_PROP_CO_LAYOUT_TYPE is the container type (POSIX, MPI-IO, HDF5, ...) DAOS_PROP_CO_LAYOUT_VER is a version of the layout that can be used by I/O middleware and application to handle interoperability. DAOS_PROP_CO_CSUM defines whether checksums are enabled or disabled and the checksum type used. DAOS_PROP_CO_REDUN_FAC is the redundancy factor that drives the minimal data protection required for objects stored in the container. e.g., RF1 means no data protection, RF3 only allows 3-way replication or erasure code N+2. DAOS_PROP_CO_REDUN_LVL is the fault domain level that should be used to place data redundancy information (e.g., storage nodes, racks ...). This information will be eventually consumed to determine object placement. DAOS_PROP_CO_SNAPSHOT_MAX is the maximum number of snapshots to retain. When a new snapshot is taken, and the threshold is reached, the oldest snapshot will be automatically deleted. DAOS_PROP_CO_ACL is the list of ACL for the container. DAOS_PROP_CO_COMPRESS and DAOS_PROP_CO_ENCRYPT are reserved for configuring respectively compression and encryption. These features are currently not on the roadmap. While those properties are currently stored persistently with container metadata, many of them are still under development. The ability to modify some of these properties on an existing container will also be provided in a future release.","title":"Container Properties"},{"location":"admin/app_interface_tiering/#container-snapshot","text":"Similar to container create/destroy, a container can be snapshotted through the DAOS API by calling daos_cont_create_snap(). Additional functions are provided to destroy and list container snapshots. The API also provides the ability to subscribe to container snapshot events and to rollback the content of a container to a previous snapshot, but those operations are not yet fully implemented. This section will be updated once support for container snapshot is supported by the daos tool.","title":"Container Snapshot"},{"location":"admin/app_interface_tiering/#container-user-attributes","text":"Similar to POSIX extended attributes, users can attach some metadata to each container through the daos_cont_{list/get/set}_attr() API.","title":"Container User Attributes"},{"location":"admin/app_interface_tiering/#container-acls","text":"Support for per-container ACLs is scheduled for DAOS v1.2. Similar to pool ACLs, container ACLs will implement a subset of the NFSv4 ACL standard. This feature will be documented here once available.","title":"Container ACLs"},{"location":"admin/app_interface_tiering/#native-programming-interface","text":"","title":"Native Programming Interface"},{"location":"admin/app_interface_tiering/#building-against-the-daos-library","text":"To build application or I/O middleware against the native DAOS API, include the daos.h header file in your program and link with -Ldaos. Examples are available under src/tests.","title":"Building against the DAOS library"},{"location":"admin/app_interface_tiering/#daos-api-reference","text":"libdaos is written in C and uses Doxygen comments that are added to C header files. [TODO] Generate Doxygen document and add a link here.","title":"DAOS API Reference"},{"location":"admin/app_interface_tiering/#bindings-to-different-languages","text":"API bindings to both Python ^1 and Go ^2 languages are available.","title":"Bindings to Different Languages"},{"location":"admin/app_interface_tiering/#posix-filesystem","text":"A regular POSIX namespace can be encapsulated into a DAOS container. This capability is provided by the libdfs library that implements the file and directory abstractions over the native libdaos library. The POSIX emulation can be exposed to applications or I/O frameworks either directly (e.g., for frameworks Spark or TensorFlow, or benchmark like IOR or mdtest that support different a storage backend plugin), or transparently via a FUSE daemon, combined optionally with an interception library to address some of the FUSE performance bottleneck by delivering full OS bypass for POSIX read/write operations.","title":"POSIX Filesystem"},{"location":"admin/app_interface_tiering/#libdfs","text":"DFS stands for DAOS File System and is a library that allows a DAOS container to be accessed as a hierarchical POSIX namespace. It supports files, directories, and symbolic links, but not hard links. Access permissions are inherited from the parent pool and not implemented on a per-file or per-directory basis. setuid() and setgid() programs, as well as supplementary groups, are currently not supported. While libdfs can be tested from a single instance (i.e. single process or client node if used through dfuse), special care is required when the same POSIX container is mounted concurrently by multiple processes. Concurrent DFS mounts are not recommended. Support for concurrency control is under development and will be documented here once ready.","title":"libdfs"},{"location":"admin/app_interface_tiering/#dfuse","text":"A fuse daemon called dfuse is provided to mount a POSIX container in the local filesystem tree. dfuse exposes one mountpoint as a single DFS namespace with a single pool and container and can be mounted by regular use (provided that it is granted access to the pool and container). To mount an existing POSIX container with dfuse, run the following command: $ dfuse -p a171434a-05a5-4671-8fe2-615aa0d05094 -s 0 -c 464e68ca-0a30-4a5f-8829-238e890899d2 -m /tmp/daos -S The UUID after -p and -c should be replaced with respectively the pool and container UUID. -s should be followed by the pool svc rank list and -m is the local directory where the mount point will be setup. When done, the file system can be unmounted via fusermount: $ fusermount -u /tmp/daos","title":"dfuse"},{"location":"admin/app_interface_tiering/#libioil","text":"An interception library called libioil is under development. This library will work in conjunction with dfuse and allow to intercept POSIX read(2) and write(2) and issue the I/O operations directly from the application context through libdaos and without any application changes. Support for libioil is currently planned for DAOS v1.2.","title":"libioil"},{"location":"admin/app_interface_tiering/#unified-namespace","text":"The DAOS tier can be tightly integrated with the Lustre parallel filesystem in which DAOS containers will be represented through the Lustre namespace. This capability is under development and is scheduled for DAOS v1.2. Current state of work can be summarized as follow : DAOS integration with Lustre uses the Lustre foreign file/dir feature (from LU-11376 and associated patches) each time a DAOS POSIX container is created, using daos utility and its '--path' UNS option, a Lustre foreign file/dir of 'daos' type is being created with a specific LOV/LMV EA content that will allow to store the DAOS pool and containers UUIDs. Lustre Client patch for LU-12682, adds DAOS specific support to the Lustre foreign file/dir feature. It allows for foreign file/dir of daos type to be presented and act as <absolute-prefix>/<pool-uuid>/<container-uuid> a symlink to the Linux Kernel/VFS. the can be specified as the new daos=<absolute-prefix> Lustre Client mount option, or also thru the new llite.*.daos_prefix Lustre dynamic tuneable. And both and are extracted from foreign file/dir LOV/LMV EA. to allow for symlink resolution and transparent access to DAOS concerned container content, it is expected that a DFuse/DFS instance/mount, of DAOS Server root, exists on presenting all served pools/containers as <pool-uuid>/<container-uuid> relative paths. daos foreign support is enabled at mount time with daos= option present, or dynamically thru llite.*.daos_enable setting.","title":"Unified Namespace"},{"location":"admin/app_interface_tiering/#hpc-io-middleware-support","text":"Several HPC I/O middleware libraries have been ported to the native API.","title":"HPC I/O Middleware Support"},{"location":"admin/app_interface_tiering/#mpi-io","text":"DAOS has its own MPI-IO ROM ADIO driver located in a MPICH fork on GitHub: https://github.com/daos-stack/mpich This driver has been submitted upstream for integration. To build the MPI-IO driver: export MPI_LIB=\"\" download the mpich repo from above and switch to daos_adio branch ./autogen.sh mkdir build; cd build ../configure --prefix=dir --enable-fortran=all --enable-romio --enable-cxx --enable-g=all --enable-debuginfo --with-file-system=ufs+daos --with-daos=dir --with-cart=dir make -j8; make install Switch the PATH and LD_LIBRARY_PATH to where you want to build your client apps or libs that use MPI to the installed MPICH. Note that the DAOS server will still need to be launched with OMPI's orterun. This is a unique situation where the server uses OMPI, and the clients will be launched with MPICH. Build any client (HDF5, ior, mpi test suites) normally with the mpicc and mpich library installed above (see child pages). To run an example: Launch DAOS server(s) and create a pool as specified in the previous section. This will return a pool uuid \"puuid\" and service rank list \"svcl\" At the client side, the following environment variables need to be set: export PATH=/path/to/mpich/install/bin:$PATH export LD_LIBRARY_PATH=/path/to/mpich/install/lib:$LD_LIBRARY_PATH export MPI_LIB=\"\" export CRT_ATTACH_INFO_PATH=/path/ (whatever was passed to daos_server start -a) export DAOS_SINGLETON_CLI=1 export DAOS_POOL=puuid; export DAOS_SVCL=svcl This is just temporary till we have a better way of passing pool connect info to MPI-IO and other middleware over DAOS. Run the client application or test. Limitations to the current implementation include: Incorrect MPI_File_set_size and MPI_File_get_size - This will be fixed in the future when DAOS correctly supports records enumeration after punch or key query for max/min key and recx. Reading Holes does not return 0, but leaves the buffer untouched No support for MPI file atomicity, preallocate, shared file pointers.","title":"MPI-IO"},{"location":"admin/app_interface_tiering/#hdf5","text":"A prototype version of an HDF5 DAOS connector is available. Please refer to the DAOS VOL connector user guide ^3 for instructions on how to build and use it.","title":"HDF5"},{"location":"admin/app_interface_tiering/#spark-support","text":"Spark integration with libdfs is under development and is scheduled for DAOS v1.0 or v1.2.","title":"Spark Support"},{"location":"admin/app_interface_tiering/#data-migration","text":"","title":"Data Migration"},{"location":"admin/app_interface_tiering/#migration-tofrom-a-posix-filesystem","text":"A dataset mover tool is under consideration to move a snapshot of a POSIX, MPI-IO or HDF5 container to a POSIX filesystem and vice versa. The copy will be performed at the POSIX or HDF5 level. The resulting HDF5 file over the POSIX filesystem will be accessible through the native HDF5 connector with the POSIX VFD. The first version of the mover tool is currently scheduled for DAOS v1.4.","title":"Migration to/from a POSIX filesystem"},{"location":"admin/app_interface_tiering/#container-parking","text":"The mover tool will also eventually support the ability to serialize and deserialize a DAOS container to a set of POSIX files that can be stored or \"parked\" in an external POSIX filesystem. This transformation is agnostic to the data model and container type and will retain all DAOS internal metadata.","title":"Container Parking"},{"location":"admin/architecture/","text":"DAOS Architecture DAOS is an open-source software-defined scale-out object store that provides high bandwidth and high IOPS storage containers to applications and enables next-generation data-centric workflows combining simulation, data analytics, and machine learning. Unlike the traditional storage stacks that were primarily designed for rotating media, DAOS is architected from the ground up to exploit new NVM technologies and is extremely lightweight since it operates End-to-End (E2E) in user space with full OS bypass. DAOS offers a shift away from an I/O model designed for block-based and high-latency storage to one that inherently supports fine-grained data access and unlocks the performance of the next-generation storage technologies. Unlike traditional Burst Buffers, DAOS is a high-performant independent and fault-tolerant storage tier that does not rely on a third-party tier to manage metadata and data resilience. DAOS Features DAOS relies on OFI for low-latency communications and stores data on both storage-class memory and NVMe storage. DAOS presents a native key-array-value storage interface that offers a unified storage model over which domain-specific data models are ported, such as HDF5, MPI-IO, and Apache Arrow. A POSIX I/O emulation layer implementing files and directories over the native DAOS API is also available. DAOS I/O operations are logged and then inserted into a persistent index maintained in SCM. Each I/O is tagged with a particular timestamp called epoch and is associated with a particular version of the dataset. No read-modify-write operations are performed internally. Write operations are non-destructive and not sensitive to alignment. Upon read request, the DAOS service walks through the persistent index and creates a complex scatter-gather Remote Direct Memory Access (RDMA) descriptor to reconstruct the data at the requested version directly in the buffer provided by the application. The SCM storage is memory-mapped directly into the address space of the DAOS service that manages the persistent index via direct load/store. Depending on the I/O characteristics, the DAOS service can decide to store the I/O in either SCM or NVMe storage. As represented in Figure 2\u20111, latency-sensitive I/Os, like application metadata and byte-granular data, will typically be stored in the former, whereas checkpoints and bulk data will be stored in the latter. This approach allows DAOS to deliver the raw NVMe bandwidth for bulk data by streaming the data to NVMe storage and maintaining internal metadata index in SCM. The Persistent Memory Development Kit (PMDK) ^1 allows managing transactional access to SCM and the Storage Performance Development Kit (SPDK) ^2 enables user-space I/O to NVMe devices. Figure 2\u20111. DAOS Storage DAOS aims at delivering: High throughput and IOPS at arbitrary alignment and size Fine-grained I/O operations with true zero-copy I/O to SCM Support for massively distributed NVM storage via scalable collective communications across the storage servers Non-blocking data and metadata operations to allow I/O and computation to overlap Advanced data placement taking into account fault domains Software-managed redundancy supporting both replication and erasure code with an online rebuild End-to-end data integrity Scalable distributed transactions with guaranteed data consistency and automated recovery Dataset snapshot Security framework to manage access control to storage pools Software-defined storage management to provision, configure, modify and monitor storage pools over COTS hardware Native support for Hierarchical Data Format (HDF)5, MPI-IO and POSIX namespace over the DAOS data model Tools for disaster recovery Seamless integration with the Lustre parallel filesystem Mover agent to migrate datasets among DAOS pools and from parallel filesystems to DAOS and vice versa DAOS Components A data center may have hundreds of thousands of compute nodes interconnected via a scalable high-performance fabric, where all, or a subset of the nodes called storage nodes, have direct access to NVM storage. A DAOS installation involves several components that can be either collocated or distributed. DAOS Target, Server and System The DAOS server is a multi-tenant daemon running on a Linux instance (i.e. natively on the physical node or in a VM or container) of each storage node and exporting through the network the locally-attached NVM storage. It listens to a management port, addressed by an IP address and a TCP port number, plus one or more fabric endpoints, addressed by network URIs. The DAOS server is configured through a YAML file and can be integrated with different daemon management or orchestration frameworks (e.g., a systemd script, a Kubernetes service or even via a parallel launcher like pdsh or srun). A DAOS system is identified by a system name and consists of a set of DAOS servers connected to the same fabric. Membership of the DAOS servers is recorded into the system map that assigns a unique integer rank to each server. Two different systems comprise two disjoint sets of servers and do not coordinate with each other. Inside a DAOS server, the storage is statically partitioned across multiple targets to optimize concurrency. To avoid contention, each target has its private storage, own pool of service threads and dedicated network context that can be directly addressed over the fabric independently of the other targets hosted on the same storage node. A target is typically associated with a single-ported SCM module and NVMe SSD attached to a single storage node. Moreover, a target does not implement any internal data protection mechanism against storage media failure. As a result, a target is a single point of failure. A dynamic state is associated with each target and is set to either up and running, or down and not available. A target is the unit of performance. Hardware components associated with the target, such as the backend storage medium, the server, and the network, have limited capability and capacity. The number of targets exported by a DAOS server instance is configurable and depends on the underlying hardware (i.e., the number of SCM modules, CPUs, NVMe SSDs ...). A target is the unit of fault. Storage API, Application Interface and Tools Applications, users, and administrators can interact with a DAOS system through two different client APIs. The management API offers the ability to administrate a DAOS system. It is intended to be integrated with different vendor-specific storage management or open-source orchestration frameworks. A CLI tool is built over the DAOS management API. On the other hand, the DAOS library (i.e., libdaos) implements the DAOS storage model and is primarily targeted at application and I/O middleware developers who want to store datasets in a DAOS system. User utilities are also built over the API to allow users to manage datasets from a CLI. Applications can access datasets stored in DAOS either directly through the native DAOS API or an I/O middleware libraries (e.g. POSIX emulation, MPI-IO, HDF5) or frameworks (e.g., Spark, TensorFlow) already integrated with the native DAOS storage model. Agent The DAOS agent is a daemon residing on the client node that interacts with the DAOS library to authenticate the application process. It is a trusted entity that can sign the DAOS Client credentials using certificates. The agent can support different authentication frameworks and uses a Unix Domain Socket to communicate with the client library. Storage Model A DAOS pool is a storage reservation distributed across a collection of targets. The actual space allocated to the pool on each target is called a pool shard. The total space allocated to a pool is decided at creation time and can be expanded over time by resizing all the pool shards (within the limit of the storage capacity dedicated to each target) or by spanning more targets (i.e., adding more pool shards). A pool offers storage virtualization and is the unit of provisioning and isolation. DAOS pools cannot span across multiple systems. A pool can host multiple transactional object store called DAOS containers. Each container is a private object address space, which can be modified transactional and independently of the other containers stored in the same pool. A container is the unit of snapshot and data management. DAOS objects belonging to a container can be distributed across any target of the pool for both performance and resilience and can be accessed through different APIs to represent structured, semi-structured and unstructured data efficiently. Figure 2\u20112 illustrates the different DAOS abstractions. Figure 2\u20112. Example of four Storage Nodes, eight DAOS Targets, and three DAOS Pools Table 2\u20111 shows the targeted level of scalability for each DAOS abstraction. Table 2\u20111. DAOS Scalability DAOS Concept Component Order of Magnitude Limit System 10 2 Pools (hundreds) Pool 10 2 Containers (hundreds) Container 10 9 Objects (billions) DAOS Pool A Pool is identified by a unique UUID and maintains target memberships in the pool map stored in persistent memory. The pool map not only records the list of active targets, it also contains the storage topology under the form of a tree that is used to identify targets sharing common hardware components. For instance, the first level of the tree can represent targets sharing the same motherboard, and then the second level can represent all motherboards sharing the same rack and finally the third level can represent all racks in the same cage. This framework effectively represents hierarchical fault domains, which are then used to avoid placing redundant data on targets subject to correlated failures. At any point in time, new targets can be added to the pool map, and failed ones can be excluded. Moreover, the pool map is fully versioned, which effectively assigns a unique sequence to each modification of the map, more particularly for failed node removal. A pool shard is a reservation of NVM storage (i.e., SCM optionally combined with a pre-allocated space on NVMe storage) on a specific target. It has a fixed capacity and fails operations when full. Current space usage can be queried at any time and reports the total amount of bytes used by any data type stored in the pool shard. Space consumed on the different type of storage is reported separately. Upon target failure and exclusion from the pool map, data redundancy inside the pool is automatically restored while the pool remains online. Rebuild progress is recorded regularly in special logs in the pool stored in persistent memory to address cascading failures. When new targets are added, data is automatically migrated to the newly added targets to redistribute space usage equally among all the members. This process is known as space rebalancing and uses dedicated persistent logs as well to support interruption and restart. A pool is a set of targets spread across different storage nodes over which data and metadata are distributed to achieve horizontal scalability, and replicated or erasure-coded to ensure durability and availability. When creating a pool, a set of system properties must be defined to configure the different features supported by the pool. In addition, the user can define their own attributes that will be stored persistently. A pool is only accessible to authenticated and authorized applications. Multiple security frameworks could be supported, from NFSv4 access control lists to third party-based authentication (such as Kerberos). Security is enforced when connecting to the pool. Upon successful connection to the pool, a connection context is returned to the application process. A pool stores many different sorts of persistent metadata, such as the pool map, authentication, and authorization information, user attributes, properties, and rebuild logs. Such metadata are critical and require the highest level of resiliency. Therefore, the pool metadata are replicated on a few nodes from distinct high-level fault domains. For very large configurations with hundreds of thousands of storage nodes, only a very small fraction of those nodes (in the order of tens) run the pool metadata service. With a limited number of storage nodes, DAOS can afford to rely on a consensus algorithm to reach agreement and to guarantee consistency in the presence of faults and to avoid split-brain syndrome. DAOS Container A container represents an object address space inside a pool and is identified by a UUID. Applications (i.e., directly or via I/O middleware, domain-specific data format, big data or AI frameworks) store all related datasets into a container which is the unit of storage management for the user. Like pools, containers can store user attributes and a set of properties must be passed at container creation time to configure different features like checksums. Objects in a container are identified by a unique 128-bit object address and may have different schemas for data distribution and redundancy over targets. Dynamic or static striping, replication or erasure code are some parameters required to define the object schema. The object class defines common schema attributes for a set of objects. Each object class is assigned a unique identifier and is associated with a given schema at the pool level. A new object class can be defined at any time with a configurable schema, which is then immutable after creation, or at least until all objects belonging to the class have been destroyed. For convenience, several object classes expected to be the most commonly used will be predefined by default when the pool is created, as shown in Table 2\u20112. Table 2\u20112. Sample of Pre-defined Object Classes Object Class (RW = read/write, RM = read-mostly Redundancy Metadata in OIT, (SC = stripe count, RC = replica count, PC = parity count, TGT = target Small size & RW Replication No (static SCxRC, e.g. 1x4) Small size & RM Erasure code No (static SC+PC, e.g. 4+2) Large size & RW Replication No (static SCxRC over max #targets) Large size & RM Erasure code No (static SCx(SC+PC) w/ max #TGT) Unknown size & RW Replication SCxRC (e.g. 1x4 initially and grows) Unknown size & RM Erasure code SC+PC (e.g. 4+2 initially and grows) A container is the unit of transaction and snapshot. Container metadata (i.e. list of snapshots, container open handles, object class, user attributes, properties, etc.) are stored in persistent memory and maintained by a dedicated container metadata service that either uses the same replicated engine as the parent metadata pool service, or has its own engine. DAOS Object To avoid scaling problems and overhead common to a traditional storage system, DAOS objects are intentionally simple. No default object metadata beyond the type and schema are provided. This means that the system does not maintain time, size, owner, permissions or even track openers. To achieve high availability and horizontal scalability, many object schemas (replication/erasure code, static/dynamic striping, and others) are provided. The schema framework is flexible and easily expandable to allow for new custom schema types in the future. The layout is generated algorithmically on an object open from the object identifier and the pool map. End-to-end integrity is assured by protecting object data with checksums during network transfer and storage. A DAOS object can be accessed through different native interfaces exported by libdaos: multi-level key-array, key-value or array APIs that allows representing efficiently structured, semi-structured or unstructured data.","title":"DAOS Architecture"},{"location":"admin/architecture/#daos-architecture","text":"DAOS is an open-source software-defined scale-out object store that provides high bandwidth and high IOPS storage containers to applications and enables next-generation data-centric workflows combining simulation, data analytics, and machine learning. Unlike the traditional storage stacks that were primarily designed for rotating media, DAOS is architected from the ground up to exploit new NVM technologies and is extremely lightweight since it operates End-to-End (E2E) in user space with full OS bypass. DAOS offers a shift away from an I/O model designed for block-based and high-latency storage to one that inherently supports fine-grained data access and unlocks the performance of the next-generation storage technologies. Unlike traditional Burst Buffers, DAOS is a high-performant independent and fault-tolerant storage tier that does not rely on a third-party tier to manage metadata and data resilience.","title":"DAOS Architecture"},{"location":"admin/architecture/#daos-features","text":"DAOS relies on OFI for low-latency communications and stores data on both storage-class memory and NVMe storage. DAOS presents a native key-array-value storage interface that offers a unified storage model over which domain-specific data models are ported, such as HDF5, MPI-IO, and Apache Arrow. A POSIX I/O emulation layer implementing files and directories over the native DAOS API is also available. DAOS I/O operations are logged and then inserted into a persistent index maintained in SCM. Each I/O is tagged with a particular timestamp called epoch and is associated with a particular version of the dataset. No read-modify-write operations are performed internally. Write operations are non-destructive and not sensitive to alignment. Upon read request, the DAOS service walks through the persistent index and creates a complex scatter-gather Remote Direct Memory Access (RDMA) descriptor to reconstruct the data at the requested version directly in the buffer provided by the application. The SCM storage is memory-mapped directly into the address space of the DAOS service that manages the persistent index via direct load/store. Depending on the I/O characteristics, the DAOS service can decide to store the I/O in either SCM or NVMe storage. As represented in Figure 2\u20111, latency-sensitive I/Os, like application metadata and byte-granular data, will typically be stored in the former, whereas checkpoints and bulk data will be stored in the latter. This approach allows DAOS to deliver the raw NVMe bandwidth for bulk data by streaming the data to NVMe storage and maintaining internal metadata index in SCM. The Persistent Memory Development Kit (PMDK) ^1 allows managing transactional access to SCM and the Storage Performance Development Kit (SPDK) ^2 enables user-space I/O to NVMe devices. Figure 2\u20111. DAOS Storage DAOS aims at delivering: High throughput and IOPS at arbitrary alignment and size Fine-grained I/O operations with true zero-copy I/O to SCM Support for massively distributed NVM storage via scalable collective communications across the storage servers Non-blocking data and metadata operations to allow I/O and computation to overlap Advanced data placement taking into account fault domains Software-managed redundancy supporting both replication and erasure code with an online rebuild End-to-end data integrity Scalable distributed transactions with guaranteed data consistency and automated recovery Dataset snapshot Security framework to manage access control to storage pools Software-defined storage management to provision, configure, modify and monitor storage pools over COTS hardware Native support for Hierarchical Data Format (HDF)5, MPI-IO and POSIX namespace over the DAOS data model Tools for disaster recovery Seamless integration with the Lustre parallel filesystem Mover agent to migrate datasets among DAOS pools and from parallel filesystems to DAOS and vice versa","title":"DAOS Features"},{"location":"admin/architecture/#daos-components","text":"A data center may have hundreds of thousands of compute nodes interconnected via a scalable high-performance fabric, where all, or a subset of the nodes called storage nodes, have direct access to NVM storage. A DAOS installation involves several components that can be either collocated or distributed.","title":"DAOS Components"},{"location":"admin/architecture/#daos-target-server-and-system","text":"The DAOS server is a multi-tenant daemon running on a Linux instance (i.e. natively on the physical node or in a VM or container) of each storage node and exporting through the network the locally-attached NVM storage. It listens to a management port, addressed by an IP address and a TCP port number, plus one or more fabric endpoints, addressed by network URIs. The DAOS server is configured through a YAML file and can be integrated with different daemon management or orchestration frameworks (e.g., a systemd script, a Kubernetes service or even via a parallel launcher like pdsh or srun). A DAOS system is identified by a system name and consists of a set of DAOS servers connected to the same fabric. Membership of the DAOS servers is recorded into the system map that assigns a unique integer rank to each server. Two different systems comprise two disjoint sets of servers and do not coordinate with each other. Inside a DAOS server, the storage is statically partitioned across multiple targets to optimize concurrency. To avoid contention, each target has its private storage, own pool of service threads and dedicated network context that can be directly addressed over the fabric independently of the other targets hosted on the same storage node. A target is typically associated with a single-ported SCM module and NVMe SSD attached to a single storage node. Moreover, a target does not implement any internal data protection mechanism against storage media failure. As a result, a target is a single point of failure. A dynamic state is associated with each target and is set to either up and running, or down and not available. A target is the unit of performance. Hardware components associated with the target, such as the backend storage medium, the server, and the network, have limited capability and capacity. The number of targets exported by a DAOS server instance is configurable and depends on the underlying hardware (i.e., the number of SCM modules, CPUs, NVMe SSDs ...). A target is the unit of fault.","title":"DAOS Target, Server and System"},{"location":"admin/architecture/#storage-api-application-interface-and-tools","text":"Applications, users, and administrators can interact with a DAOS system through two different client APIs. The management API offers the ability to administrate a DAOS system. It is intended to be integrated with different vendor-specific storage management or open-source orchestration frameworks. A CLI tool is built over the DAOS management API. On the other hand, the DAOS library (i.e., libdaos) implements the DAOS storage model and is primarily targeted at application and I/O middleware developers who want to store datasets in a DAOS system. User utilities are also built over the API to allow users to manage datasets from a CLI. Applications can access datasets stored in DAOS either directly through the native DAOS API or an I/O middleware libraries (e.g. POSIX emulation, MPI-IO, HDF5) or frameworks (e.g., Spark, TensorFlow) already integrated with the native DAOS storage model.","title":"Storage API, Application Interface and Tools"},{"location":"admin/architecture/#agent","text":"The DAOS agent is a daemon residing on the client node that interacts with the DAOS library to authenticate the application process. It is a trusted entity that can sign the DAOS Client credentials using certificates. The agent can support different authentication frameworks and uses a Unix Domain Socket to communicate with the client library.","title":"Agent"},{"location":"admin/architecture/#storage-model","text":"A DAOS pool is a storage reservation distributed across a collection of targets. The actual space allocated to the pool on each target is called a pool shard. The total space allocated to a pool is decided at creation time and can be expanded over time by resizing all the pool shards (within the limit of the storage capacity dedicated to each target) or by spanning more targets (i.e., adding more pool shards). A pool offers storage virtualization and is the unit of provisioning and isolation. DAOS pools cannot span across multiple systems. A pool can host multiple transactional object store called DAOS containers. Each container is a private object address space, which can be modified transactional and independently of the other containers stored in the same pool. A container is the unit of snapshot and data management. DAOS objects belonging to a container can be distributed across any target of the pool for both performance and resilience and can be accessed through different APIs to represent structured, semi-structured and unstructured data efficiently. Figure 2\u20112 illustrates the different DAOS abstractions. Figure 2\u20112. Example of four Storage Nodes, eight DAOS Targets, and three DAOS Pools Table 2\u20111 shows the targeted level of scalability for each DAOS abstraction. Table 2\u20111. DAOS Scalability DAOS Concept Component Order of Magnitude Limit System 10 2 Pools (hundreds) Pool 10 2 Containers (hundreds) Container 10 9 Objects (billions)","title":"Storage Model"},{"location":"admin/architecture/#daos-pool","text":"A Pool is identified by a unique UUID and maintains target memberships in the pool map stored in persistent memory. The pool map not only records the list of active targets, it also contains the storage topology under the form of a tree that is used to identify targets sharing common hardware components. For instance, the first level of the tree can represent targets sharing the same motherboard, and then the second level can represent all motherboards sharing the same rack and finally the third level can represent all racks in the same cage. This framework effectively represents hierarchical fault domains, which are then used to avoid placing redundant data on targets subject to correlated failures. At any point in time, new targets can be added to the pool map, and failed ones can be excluded. Moreover, the pool map is fully versioned, which effectively assigns a unique sequence to each modification of the map, more particularly for failed node removal. A pool shard is a reservation of NVM storage (i.e., SCM optionally combined with a pre-allocated space on NVMe storage) on a specific target. It has a fixed capacity and fails operations when full. Current space usage can be queried at any time and reports the total amount of bytes used by any data type stored in the pool shard. Space consumed on the different type of storage is reported separately. Upon target failure and exclusion from the pool map, data redundancy inside the pool is automatically restored while the pool remains online. Rebuild progress is recorded regularly in special logs in the pool stored in persistent memory to address cascading failures. When new targets are added, data is automatically migrated to the newly added targets to redistribute space usage equally among all the members. This process is known as space rebalancing and uses dedicated persistent logs as well to support interruption and restart. A pool is a set of targets spread across different storage nodes over which data and metadata are distributed to achieve horizontal scalability, and replicated or erasure-coded to ensure durability and availability. When creating a pool, a set of system properties must be defined to configure the different features supported by the pool. In addition, the user can define their own attributes that will be stored persistently. A pool is only accessible to authenticated and authorized applications. Multiple security frameworks could be supported, from NFSv4 access control lists to third party-based authentication (such as Kerberos). Security is enforced when connecting to the pool. Upon successful connection to the pool, a connection context is returned to the application process. A pool stores many different sorts of persistent metadata, such as the pool map, authentication, and authorization information, user attributes, properties, and rebuild logs. Such metadata are critical and require the highest level of resiliency. Therefore, the pool metadata are replicated on a few nodes from distinct high-level fault domains. For very large configurations with hundreds of thousands of storage nodes, only a very small fraction of those nodes (in the order of tens) run the pool metadata service. With a limited number of storage nodes, DAOS can afford to rely on a consensus algorithm to reach agreement and to guarantee consistency in the presence of faults and to avoid split-brain syndrome.","title":"DAOS Pool"},{"location":"admin/architecture/#daos-container","text":"A container represents an object address space inside a pool and is identified by a UUID. Applications (i.e., directly or via I/O middleware, domain-specific data format, big data or AI frameworks) store all related datasets into a container which is the unit of storage management for the user. Like pools, containers can store user attributes and a set of properties must be passed at container creation time to configure different features like checksums. Objects in a container are identified by a unique 128-bit object address and may have different schemas for data distribution and redundancy over targets. Dynamic or static striping, replication or erasure code are some parameters required to define the object schema. The object class defines common schema attributes for a set of objects. Each object class is assigned a unique identifier and is associated with a given schema at the pool level. A new object class can be defined at any time with a configurable schema, which is then immutable after creation, or at least until all objects belonging to the class have been destroyed. For convenience, several object classes expected to be the most commonly used will be predefined by default when the pool is created, as shown in Table 2\u20112. Table 2\u20112. Sample of Pre-defined Object Classes Object Class (RW = read/write, RM = read-mostly Redundancy Metadata in OIT, (SC = stripe count, RC = replica count, PC = parity count, TGT = target Small size & RW Replication No (static SCxRC, e.g. 1x4) Small size & RM Erasure code No (static SC+PC, e.g. 4+2) Large size & RW Replication No (static SCxRC over max #targets) Large size & RM Erasure code No (static SCx(SC+PC) w/ max #TGT) Unknown size & RW Replication SCxRC (e.g. 1x4 initially and grows) Unknown size & RM Erasure code SC+PC (e.g. 4+2 initially and grows) A container is the unit of transaction and snapshot. Container metadata (i.e. list of snapshots, container open handles, object class, user attributes, properties, etc.) are stored in persistent memory and maintained by a dedicated container metadata service that either uses the same replicated engine as the parent metadata pool service, or has its own engine.","title":"DAOS Container"},{"location":"admin/architecture/#daos-object","text":"To avoid scaling problems and overhead common to a traditional storage system, DAOS objects are intentionally simple. No default object metadata beyond the type and schema are provided. This means that the system does not maintain time, size, owner, permissions or even track openers. To achieve high availability and horizontal scalability, many object schemas (replication/erasure code, static/dynamic striping, and others) are provided. The schema framework is flexible and easily expandable to allow for new custom schema types in the future. The layout is generated algorithmically on an object open from the object identifier and the pool map. End-to-end integrity is assured by protecting object data with checksums during network transfer and storage. A DAOS object can be accessed through different native interfaces exported by libdaos: multi-level key-array, key-value or array APIs that allows representing efficiently structured, semi-structured or unstructured data.","title":"DAOS Object"},{"location":"admin/deployment/","text":"DAOS System Deployment Preflight Checklist This section covers the preliminary setup required on the compute and storage nodes before deploying DAOS. Time Synchronization The DAOS transaction model relies on timestamps and requires time to be synchronized across all the storage and client nodes. This can be done using NTP or any other equivalent protocol. Runtime Directory Setup DAOS uses a series of Unix Domain Sockets to communicate between its various components. On modern Linux systems, Unix Domain Sockets are typically stored under /run or /var/run (usually a symlink to /run) and are a mounted tmpfs file system. There are several methods for ensuring the necessary directories are setup. A sign that this step may have been missed is when starting daos_server or daos_agent, you may see the message: $ mkdir /var/run/daos_server: permission denied Unable to create socket directory: /var/run/daos_server Non-default Directory By default, daos_server and daos_agent will use the directories /var/run/daos_server and /var/run/daos_agent respectively. To change the default location that daos_server uses for its runtime directory, either uncomment and set the socket_dir configuration value in install/etc/daos_server.yml, or pass the location to daos_server on the command line using the -d flag. For the daos_agent, an alternate location can be passed on the command line using the -runtime_dir flag. Default Directory (non-persistent) Files and directories created in /run and /var/run only survive until the next reboot. However, if reboots are infrequent, an easy solution while still utilizing the default locations is to create the required directories manually. To do this execute the following commands. daos_server: $ mkdir /var/run/daos_server $ chmod 0755 /var/run/daos_server $ chown user:user /var/run/daos_server (where user is the user you will run daos\\_server as) daos_agent: $ mkdir /var/run/daos_agent $ chmod 0755 /var/run/daos_agent $ chown user:user /var/run/daos_agent (where user is the user you will run daos\\_agent as) Default Directory (persistent) If the server hosting daos_server or daos_agent will be rebooted often, systemd provides a persistent mechanism for creating the required directories called tmpfiles.d. This mechanism will be required every time the system is provisioned and requires a reboot to take effect. To tell systemd to create the necessary directories for DAOS: Copy the file utils/systemd/daosfiles.conf to /etc/tmpfiles.d\\ cp utils/systemd/daosfiles.conf /etc/tmpfiles.d Modify the copied file to change the user and group fields (currently daos) to the user daos will be run as Reboot the system, and the directories will be created automatically on all subsequent reboots. Elevated Privileges Several tasks (e.g., storage access, hugepages configuration) performed by the DAOS server require elevated permissions on the storage nodes (requiring certain commands to be run as root or with sudo). Hardware Provisioning Storage Preparation SCM Preparation This section addresses how to verify that Optane DC Persistent Memory (DCPM) is correctly installed on the storage nodes, and how to configure it in interleaved mode to be used by DAOS in AppDirect mode. Instructions for other types of SCM may be covered in the future. Provisioning the SCM occurs by configuring DCPM modules in AppDirect memory regions (interleaved mode) in groups of modules local to a specific socket (NUMA), and resultant nvdimm namespaces are defined by a device identifier (e.g., /dev/pmem0). DCPM can be configured and managed through the ipmctl library and associated tool. The ipmctl command can be run as root and has detailed man pages and help output (use \"ipmctl help\" to display it). The list of NVDIMMs can be displayed as follows: ipmctl show -dimm DimmID Capacity HealthState ActionRequired LockState FWVersion 0x0001 502.5 GiB Healthy 0 Disabled 01.00.00.5127 0x0101 502.5 GiB Healthy 0 Disabled 01.00.00.5127 0x1001 502.5 GiB Healthy 0 Disabled 01.00.00.5127 0x1101 502.5 GiB Healthy 0 Disabled 01.00.00.5127 Moreover, DAOS requires DCPM to be configured in interleaved mode. A storage subcommand (prepare --scm-only) can be used as a \"command mode\" invocation of daos_server and must be run as root. SCM modules will be configured into interleaved regions with memory mode set to \"AppDirect\" mode with one set per socket (each module is assigned to a socket, and reports this via its NUMA rating). sudo daos_server [<app_opts>] storage prepare [--scm-only|-s] [<cmd_opts>] The first time the command is run, the SCM AppDirect regions will be created as resource allocations on any available DCPM modules (one region per NUMA node/socket). The regions are activated after BIOS reads the new resource allocations, and after initial completion the command prints a message to ask for a reboot (the command will not initiate reboot itself). 'sudo daos_server storage prepare --scm-only' should be run for a second time after system reboot to create the pmem kernel devices (/dev/pmemX namespaces created on the new SCM regions). One namespace per region is created, and each namespace may take up to a few minutes to create. Details of the pmem devices will be displayed in JSON format on command completion. Example output from the initial call (with the SCM modules set to default MemoryMode): Memory allocation goals for SCM will be changed and namespaces modified, this will be a destructive operation. ensure namespaces are unmounted and SCM is otherwise unused. Are you sure you want to continue? (yes/no) yes A reboot is required to process new memory allocation goals. Example output from the subsequent call (SCM modules configured to AppDirect mode, and host rebooted): Memory allocation goals for SCM will be changed and namespaces modified. This will be a destructive operation. Ensure namespaces are unmounted and the SCM is otherwise unused. Are you sure you want to continue? (yes/no) yes creating SCM namespace, may take a few minutes... creating SCM namespace, may take a few minutes... Persistent memory kernel devices: [{UUID:5d2f2517-9217-4d7d-9c32-70731c9ac11e Blockdev:pmem1 Dev:namespace1.0 NumaNode:1} {UUID:2bfe6c40-f79a-4b8e-bddf-ba81d4427b9b Blockdev:pmem0 Dev:namespace0.0 NumaNode:0}] sudo daos_server [<app_opts>] storage prepare [--scm-only|-s] --reset [<cmd_opts>] All namespaces are disabled and destroyed. The SCM regions are removed by resetting modules into \"MemoryMode\" through resource allocations. Note that undefined behavior may result if the namespaces/pmem kernel devices are mounted before running reset (as per the printed warning). A subsequent reboot is required for BIOS to read the new resource allocations. Example output when resetting the SCM modules: Memory allocation goals for SCM will be changed and namespaces modified, this will be a destructive operation. ensure namespaces are unmounted and SCM is otherwise unused. Are you sure you want to continue? (yes/no) yes removing SCM namespace, may take a few minutes... removing SCM namespace, may take a few minutes... resetting SCM memory allocations A reboot is required to process new memory allocation goals. NVMe Preparation DAOS supports only NVMe-capable SSDs that are accessed directly from userspace through the SPDK library. NVMe access through SPDK as an unprivileged user can be enabled by running the example command sudo daos_server storage prepare --nvme-only -p 4096 -u bob . This will perform the required setup in order for daos_server to be run by user \"bob\" who will own the hugepage mountpoint directory and vfio groups as needed in SPDK operations. If the target-user is unspecified ( -u short option), the target user will be the issuer of the sudo command (or root if not using sudo). The specification of hugepages ( -p short option) defines the number of huge pages to allocate for use by SPDK. A list of PCI addresses can also be supplied to avoid unbinding all PCI devices from the kernel, using the -w / --pci-whitelist option. The sudo daos_server [<app_opts>] storage prepare [--nvme-only|-n] [<cmd_opts>] command wraps the SPDK setup script to unbind the devices from original kernel drivers and then binds the devices to a UIO driver through which SPDK can communicate. When a PCI address whitelist is not specified, SPDK access to all SSDs will be enabled for the user (either the user executing sudo, the user specified as --target-user, or effective user - in that order of precedence) involving changing the ownership of relevant files in addition to SPDK setup. The devices can then be bound back to the original drivers with the command sudo daos_server [<app_opts>] storage prepare [--nvme-only|-n] --reset [<cmd_opts>] . Storage Detection & Selection While the DAOS server auto-detects all the usable storage, the administrator will still be provided with the ability through the configuration file (see next section) to whitelist or blacklist the storage devices to be (or not) used. This section covers how to manually detect the storage devices potentially usable by DAOS to populate the configuration file when the administrator wants to have finer control over the storage selection. sudo daos_server storage scan can be used to display locally-attached SSDs and Intel Persistent Memory Models usable by DAOS. $ daos_server storage scan [...] NVMe SSD controller and constituent namespaces: PCI Addr:0000:da:00.0 Serial:PHKS7505005Y750BGN Model:INTEL SSDPED1K750GA Fwrev:E2010325 Socket:1 Namespace: id:1 capacity:750 PCI Addr:0000:81:00.0 Serial:PHKS7505007J750BGN Model:INTEL SSDPED1K750GA Fwrev:E2010325 Socket:1 Namespace: id:1 capacity:750 PCI Addr:0000:87:00.0 Serial:CVFT5392000G1P6DGN Model:INTEL SSDPEDMD016T4 Fwrev:8DV10171 Socket:1 Namespace: id:1 capacity:1600 SCM modules: PhysicalID:36 Capacity:539661172736 Location:(socket:0 memctrlr:0 chan:0 pos:1) PhysicalID:40 Capacity:539661172736 Location:(socket:0 memctrlr:0 chan:1 pos:1) PhysicalID:44 Capacity:539661172736 Location:(socket:0 memctrlr:0 chan:2 pos:1) PhysicalID:50 Capacity:539661172736 Location:(socket:0 memctrlr:1 chan:0 pos:1) PhysicalID:52 Capacity:539661172736 Location:(socket:0 memctrlr:1 chan:1 pos:0) PhysicalID:55 Capacity:539661172736 Location:(socket:0 memctrlr:1 chan:2 pos:0) PhysicalID:62 Capacity:539661172736 Location:(socket:1 memctrlr:0 chan:0 pos:1) PhysicalID:66 Capacity:539661172736 Location:(socket:1 memctrlr:0 chan:1 pos:1) PhysicalID:70 Capacity:539661172736 Location:(socket:1 memctrlr:0 chan:2 pos:1) PhysicalID:76 Capacity:539661172736 Location:(socket:1 memctrlr:1 chan:0 pos:1) PhysicalID:78 Capacity:539661172736 Location:(socket:1 memctrlr:1 chan:1 pos:0) PhysicalID:81 Capacity:539661172736 Location:(socket:1 memctrlr:1 chan:2 pos:0) The pciaddr field above is what should be used in the server configuration file to identified NVMe SSDs. Devices with the same NUMA node/socket should be used in the same per-server section of the server configuration file for best performance. Network Interface Detection and Selection To display the supported OFI provider, use the following command: $ fi_info -l psm2: version: 1.7 ofi\\_rxm: version: 1.0 ofi\\_rxd: version: 1.0 verbs: version: 1.0 UDP: version: 1.1 sockets: version: 2.0 tcp: version: 0.1 ofi_perf_hook: version: 1.0 ofi_noop_hook: version: 1.0 shm: version: 1.0 ofi_mrail: version: 1.0 The fi_pingpong test (delivered as part of OFI/libfabric) can be used to verify that the targeted OFI provider works fine: node1$ fi_pingpong -p psm2 node2$ fi_pingpong -p psm2 ${IP_ADDRESS_NODE1} bytes #sent #ack total time MB/sec usec/xfer Mxfers/sec 64 10 =10 1.2k 0.00s 21.69 2.95 0.34 256 10 =10 5k 0.00s 116.36 2.20 0.45 1k 10 =10 20k 0.00s 379.26 2.70 0.37 4k 10 =10 80k 0.00s 1077.89 3.80 0.26 64k 10 =10 1.2m 0.00s 2145.20 30.55 0.03 1m 10 =10 20m 0.00s 8867.45 118.25 0.01 Storage Firmware Upgrade Firmware on an NVMe controller can be updated from an image on local storage (initially installing from a local path on the host that is running daos_server but to be extended to downloading remotely from central storage location). When the controller is selected, and an update firmware task runs, controller data is accessed through an existing linked list through the binding fwupdate call, and a raw command specifying a firmware update with the local image (specified by file path) and slot identifier. The firmware update is followed by a hard reset on the controller. Storage Burn in Burn-in testing can be performed on discovered NVMe controllers. By default, this involves a 15-minute slow burn-in test with a mixed read/write workload issued by fio, but test duration and load strength should be user-configurable. Burn-in should run in the background to allow administrators to use the control-plane for other tasks in the meantime. The fio repo is to be built and needs to be referenced when building the SPDK fio_plugin. The plug-in can then be run by fio to exercise the NVMe device through SPDK. Currently, the output of the burn-in is displayed in the shell, and control is returned to the user after completion. Future iterations may perform this as a background task. Server Configuration This section addresses how to configure the DAOS servers on the storage nodes before starting it. Certificate Generation The DAOS security framework relies on certificates to authenticate administrators. The security infrastructure is currently under development and will be delivered in DAOS v1.0. Initial support for certificates has been added to DAOS and can be disabled either via the command line or in the DAOS server configuration file. Currently, the easiest way to disable certificate support is to pass the -i flag to daos_server. Server Configuration File The daos_server configuration file is parsed when starting the daos_server process. The configuration file location can be specified on the command line ( daos_server -h for usage) or default location ( install/etc/daos_server.yml ). Parameter descriptions are specified in daos_server.yml and example configuration files in the examples directory. Any option supplied to daos_server as a command line option or flag will take precedence over equivalent configuration file parameter. For convenience, active parsed configuration values are written to a temporary file for reference, and the location will be written to the log. Configuration File Options The example configuration file lists the default empty configuration, listing all the options (living documentation of the config file). Live examples are available at https://github.com/daos-stack/daos/tree/master/utils/config The location of this configuration file is determined by first checking for the path specified through the -o option of the daos_server command line. Otherwise, /etc/daos_server.conf is used. Refer to the example configuration file ( daos_server.yml ) for latest information and examples. Server Startup DAOS currently relies on PMIx for server wire-up and application to server connection. As a result, the DAOS servers can only be started via orterun (part of OpenMPI). A new bootstrap procedure is under implementation and will be available for DAOS v1.0. This will remove the dependency on PMIx and will allow the DAOS servers to be started individually (e.g. independently on each storage node via systemd) or collectively (e.g. pdsh, mpirun or as a Kubernetes Pod). Parallel Launcher As stated above, only orterun(1) is currently supported. The list of storage nodes can be specified on the command line via the -H option. The DAOS server and the application can be started separately but must share a URI directory (referred to as shared_dir) to connect. Also, the DAOS server must be started with the --enable-recovery option to support server failure. See the orterun(1) man page for additional options. To start the DAOS server, run: orterun --map-by node --mca btl tcp,self --mca oob tcp -np <num_servers> -H <server_list> --enable-recovery daos_server -a <shared_dir> -o <config_file> The --enable-recovery is required for fault tolerance to guarantee that the fault of one server does not cause the others to be stopped. The shared directory should be accessible by all nodes. The --allow-run-as-root option can be added to the command line to allow the daos_server to run with root privileges on each storage nodes (for example when needing to perform privileged tasks relating to storage format). The content of the configuration file is documented in the next section and a few examples are available . Client processes (i.e. utilities, applications, ...) should have the following environment variables set to connect to the DAOS servers: export DAOS_SINGLETON_CLI=1 export CRT_ATTACH_INFO_PATH=/path/to/shared_dir Systemd Integration Systemd support for daos_server is still experimental as it will start the daos_server and daos_io_server components in PMIXless mode, which is still in development. DAOS Server can be started as a systemd service. The DAOS Server unit file is installed in the correct location when installing from RPMs. If you wish to use systemd with a development build, you must copy the service file from utils/systemd to /usr/lib/systemd/system. Once the file is copied modify the ExecStart line to point to your in tree daos_server binary. Once the service file is installed you can start daos_server with the following commands: $ systemctl enable daos-server $ systemctl start daos-server To check the component status use: $ systemctl status daos-server If DAOS Server failed to start, check the logs with: $ journalctl --unit daos-server Kubernetes Pod DAOS service integration with Kubernetes is planned and will be supported in a future DAOS version. Service Monitoring On start-up, the daos_server will create and initialize the following components: gRPC server to handle requests over client API dRPC server to handle requests from IO servers over the UNIX domain socket storage subsystems for handling interactions with NVM devices SPDK environment using a shared memory segment identifier, causing the process to act as a primary in multi-process mode. From there, the main process can respond to requests over the client API for information through the SPDK interface. The daos_shell is a transitory tool used to exercise the management api and can be used to verify that the DAOS servers are up and running. It is to be run as a standard, unprivileged user as follows: $ daos_shell -l storagenode1:10001,storagenode2:10001 storage scan \"storagenode\" should be replaced with the actual hostname of each storage node. This command will show whether the DAOS server is properly running and initialized on each storage node. A more comprehensive and user-friendly tool built over the management API is under development. A first version will be available for DAOS v1.0. Storage Formatting When 'daos_server' is started for the first time (and no SCM directory exists), it enters \"maintenance mode\" and waits for a daos_shell storage format call to be issued from the management tool. This remote call will trigger the formatting of the locally attached storage on the host for use with DAOS using the parameters defined in the server config file. daos_shell -i -l <host:port>[,...] storage format will normally be run on a login node specifying a hostlist ( -l <host:port>[,...] ) of storage nodes with SCM/DCPM modules and NVMe SSDs installed and prepared. SCM Format When the command is run, the pmem kernel devices created on SCM/DCPM regions are formatted and mounted based on the parameters provided in the server config file. scm_mount specifies the location of the mountpoint to create. scm_class can be set to ram to use a tmpfs in the situation that no SCM/DCPM is available (scm_size dictates the size of tmpfs in GB), when set to dcpm the device specified under scm_list will be mounted at scm_mount path. NVMe Format When the command is run, NVMe SSDs are formatted and set up to be used by DAOS based on the parameters provided in the server config file. bdev_class can be set to nvme to use actual NVMe devices with SPDK for DAOS storage. Other bdev_class values can be used for emulation of NVMe storage as specified in the server config file. bdev_list identifies devices to use with a list of PCI addresses (this can be populated after viewing results from storage scan command). After the format command is run, the path specified by the server configuration file scm_mount parameter should be mounted and should contain a file named daos_nvme.conf . The file should describe the devices with PCI addresses as listed in the bdev_list parameter of the server config file. The presence and contents of the file indicate that the specified NVMe SSDs have been configured correctly for use with DAOS. The contents of the NVMe SSDs listed in the server configuration file bdev_list parameter will be reset on format. Server Format Before the format command is run, no superblock file should exist under the path specified by scm_mount parameter in the server configuration file. After the storage format command is run, the path specified by the server configuration file scm_mount parameter should be mounted and should contain a file named superblock indicating that the server has been formatted. When starting, daos_server will skip maintenance mode and attempt to start IO services if the superblock is found in scm_mount . Basic Workflow Control plane server ( daos_server ) instances will listen for requests from the management tool ( daos_shell ), enabling users to perform provisioning operations on network and storage hardware remotely on storage nodes (from for example a login node). When daos_server instances have been started on each storage node for the first time, calling daos_shell -l <host:port>,... storage format -f formats persistent storage on the server node (skipping confirmation) on devices specified in the server configuration file, then writes the superblock and starts the data plane. Typically an administrator will perform the following tasks: Prepare NVMe and SCM Storage sudo daos_server [<app_opts>] storage prepare [<cmd_opts>] NVMe details SCM details Scan Storage sudo daos_server [<app_opts>] storage scan [<cmd_opts>] details Add device identifiers to Server config file vim <daos>/utils/config/examples/daos_server_sockets.yml details just specify NVMe PCI addresses with bdev_list for now Start DAOS control plane orterun -np 2 -H boro-44,boro-45 --enable-recovery daos_server -a shared_dir -o <daos>/utils/config/examples/daos_server_sockets.yml start details Provision Storage firmware update details burn-in testing details Amend Server config file (adjust based on the results of storage provisioning, requires a subsequent restart of daos_server ) vim <daos>/utils/config/examples/daos_server_sockets.yml details populate the scm_* and bdev_* parameters as used in format (below) Format Storage (from any node) When daos_server is started for the first time (and no SCM directory exists), daos_server enters \"maintenance mode\" and waits for a daos_shell storage format call to be issued from the management tool. This remote call will trigger the formatting of the locally attached storage on the host for use with DAOS using the parameters defined in the server config file. daos_shell -i -l <host:port>,... storage format -f management tool details SCM specific details NVMe specific details Example output $ daos_shell -i -l <hostname>:10001 -i storage format -f Active connections: [<hostname):10001] This is a destructive operation and storage devices specified in the server config file will be erased. Please be patient as it may take several minutes. NVMe storage format results: <hostname>:10001: pci-address 0000:da:00.0: status CTRL_SUCCESS pci-address 0000:81:00.0: status CTRL_SUCCESS SCM storage format results: <hostname>:10001: mntpoint /mnt/daos: status CTRL_SUCCESS Agent Configuration This section addresses how to configure the DAOS agents on the storage nodes before starting it. Agent Certificate Generation The DAOS security framework relies on certificates to authenticate administrators. The security infrastructure is currently under development and will be delivered in DAOS v1.0. Initial support for certificates has been added to DAOS and can be disabled either via the command line or in the DAOS Agent configuration file. Currently, the easiest way to disable certificate support is to pass the -i flag to daos_agent. Agent Configuration File The daos_agent configuration file is parsed when starting the daos_agent process. The configuration file location can be specified on the command line ( daos_agent -h for usage) or default location ( install/etc/daos_agent.yml ). Parameter descriptions are specified in daos_agent.yml . Any option supplied to daos_agent as a command line option or flag will take precedence over equivalent configuration file parameter. For convenience, active parsed config values are written to a temporary file for reference, and the location will be written to the log. The following section lists the format, options, defaults, and descriptions available in the configuration file. Configuration File Options The example configuration file lists the default empty configuration listing all the options (living documentation of the config file). Live examples are available at https://github.com/daos-stack/daos/tree/master/utils/config The location of this configuration file is determined by first checking for the path specified through the -o option of the daos_agent command line. Otherwise, /etc/daos_agent.conf is used. Refer to the example configuration file ( daos_server.yml ) for latest information and examples. Agent Startup DAOS Agent is a standalone application to be run on each compute node. It can be configured to use secure communications (default) or can be allowed to communicate with the control plane over unencrypted channels. The following example shows daos_agent being configured to operate in insecure mode due to incomplete integration of certificate support as of the 0.6 release. To start the DAOS Agent from the command line, run: $ daos_agent -i Alternatively, the DAOS Agent can be started as a systemd service. The DAOS Agent unit file is installed in the correct location when installing from RPMs. If you wish to use systemd with a development build, you must copy the service file from utils/systemd to /usr/lib/systemd/system. Once the file is copied modify the ExecStart line to point to your in tree daos_agent binary. Once the service file is installed, you can start daos_agent with the following commands: $ systemctl enable daos-agent $ systemctl start daos-agent To check the component status use: $ systemctl status daos-agent If DAOS Agent failed to start check the logs with: $ journalctl --unit daos-agent System Validation To validate that the DAOS system is properly installed, the daos_test suite can be executed. Ensure the DAOS Agent is configured and running before running daos_test and that the DAOS_SINGLETON_CLI and CRT_ATTACH_INFO_PATH environment variables are properly set as described here . orterun -np <num_clients> --hostfile <hostfile> ./daos_test daos_test requires at least 8GB of SCM (or DRAM with tmpfs) storage on each storage node.","title":"System Deployment"},{"location":"admin/deployment/#daos-system-deployment","text":"","title":"DAOS System Deployment"},{"location":"admin/deployment/#preflight-checklist","text":"This section covers the preliminary setup required on the compute and storage nodes before deploying DAOS.","title":"Preflight Checklist"},{"location":"admin/deployment/#time-synchronization","text":"The DAOS transaction model relies on timestamps and requires time to be synchronized across all the storage and client nodes. This can be done using NTP or any other equivalent protocol.","title":"Time Synchronization"},{"location":"admin/deployment/#runtime-directory-setup","text":"DAOS uses a series of Unix Domain Sockets to communicate between its various components. On modern Linux systems, Unix Domain Sockets are typically stored under /run or /var/run (usually a symlink to /run) and are a mounted tmpfs file system. There are several methods for ensuring the necessary directories are setup. A sign that this step may have been missed is when starting daos_server or daos_agent, you may see the message: $ mkdir /var/run/daos_server: permission denied Unable to create socket directory: /var/run/daos_server","title":"Runtime Directory Setup"},{"location":"admin/deployment/#non-default-directory","text":"By default, daos_server and daos_agent will use the directories /var/run/daos_server and /var/run/daos_agent respectively. To change the default location that daos_server uses for its runtime directory, either uncomment and set the socket_dir configuration value in install/etc/daos_server.yml, or pass the location to daos_server on the command line using the -d flag. For the daos_agent, an alternate location can be passed on the command line using the -runtime_dir flag.","title":"Non-default Directory"},{"location":"admin/deployment/#default-directory-non-persistent","text":"Files and directories created in /run and /var/run only survive until the next reboot. However, if reboots are infrequent, an easy solution while still utilizing the default locations is to create the required directories manually. To do this execute the following commands. daos_server: $ mkdir /var/run/daos_server $ chmod 0755 /var/run/daos_server $ chown user:user /var/run/daos_server (where user is the user you will run daos\\_server as) daos_agent: $ mkdir /var/run/daos_agent $ chmod 0755 /var/run/daos_agent $ chown user:user /var/run/daos_agent (where user is the user you will run daos\\_agent as)","title":"Default Directory (non-persistent)"},{"location":"admin/deployment/#default-directory-persistent","text":"If the server hosting daos_server or daos_agent will be rebooted often, systemd provides a persistent mechanism for creating the required directories called tmpfiles.d. This mechanism will be required every time the system is provisioned and requires a reboot to take effect. To tell systemd to create the necessary directories for DAOS: Copy the file utils/systemd/daosfiles.conf to /etc/tmpfiles.d\\ cp utils/systemd/daosfiles.conf /etc/tmpfiles.d Modify the copied file to change the user and group fields (currently daos) to the user daos will be run as Reboot the system, and the directories will be created automatically on all subsequent reboots.","title":"Default Directory (persistent)"},{"location":"admin/deployment/#elevated-privileges","text":"Several tasks (e.g., storage access, hugepages configuration) performed by the DAOS server require elevated permissions on the storage nodes (requiring certain commands to be run as root or with sudo).","title":"Elevated Privileges"},{"location":"admin/deployment/#hardware-provisioning","text":"","title":"Hardware Provisioning"},{"location":"admin/deployment/#storage-preparation","text":"","title":"Storage Preparation"},{"location":"admin/deployment/#scm-preparation","text":"This section addresses how to verify that Optane DC Persistent Memory (DCPM) is correctly installed on the storage nodes, and how to configure it in interleaved mode to be used by DAOS in AppDirect mode. Instructions for other types of SCM may be covered in the future. Provisioning the SCM occurs by configuring DCPM modules in AppDirect memory regions (interleaved mode) in groups of modules local to a specific socket (NUMA), and resultant nvdimm namespaces are defined by a device identifier (e.g., /dev/pmem0). DCPM can be configured and managed through the ipmctl library and associated tool. The ipmctl command can be run as root and has detailed man pages and help output (use \"ipmctl help\" to display it). The list of NVDIMMs can be displayed as follows: ipmctl show -dimm DimmID Capacity HealthState ActionRequired LockState FWVersion 0x0001 502.5 GiB Healthy 0 Disabled 01.00.00.5127 0x0101 502.5 GiB Healthy 0 Disabled 01.00.00.5127 0x1001 502.5 GiB Healthy 0 Disabled 01.00.00.5127 0x1101 502.5 GiB Healthy 0 Disabled 01.00.00.5127 Moreover, DAOS requires DCPM to be configured in interleaved mode. A storage subcommand (prepare --scm-only) can be used as a \"command mode\" invocation of daos_server and must be run as root. SCM modules will be configured into interleaved regions with memory mode set to \"AppDirect\" mode with one set per socket (each module is assigned to a socket, and reports this via its NUMA rating). sudo daos_server [<app_opts>] storage prepare [--scm-only|-s] [<cmd_opts>] The first time the command is run, the SCM AppDirect regions will be created as resource allocations on any available DCPM modules (one region per NUMA node/socket). The regions are activated after BIOS reads the new resource allocations, and after initial completion the command prints a message to ask for a reboot (the command will not initiate reboot itself). 'sudo daos_server storage prepare --scm-only' should be run for a second time after system reboot to create the pmem kernel devices (/dev/pmemX namespaces created on the new SCM regions). One namespace per region is created, and each namespace may take up to a few minutes to create. Details of the pmem devices will be displayed in JSON format on command completion. Example output from the initial call (with the SCM modules set to default MemoryMode): Memory allocation goals for SCM will be changed and namespaces modified, this will be a destructive operation. ensure namespaces are unmounted and SCM is otherwise unused. Are you sure you want to continue? (yes/no) yes A reboot is required to process new memory allocation goals. Example output from the subsequent call (SCM modules configured to AppDirect mode, and host rebooted): Memory allocation goals for SCM will be changed and namespaces modified. This will be a destructive operation. Ensure namespaces are unmounted and the SCM is otherwise unused. Are you sure you want to continue? (yes/no) yes creating SCM namespace, may take a few minutes... creating SCM namespace, may take a few minutes... Persistent memory kernel devices: [{UUID:5d2f2517-9217-4d7d-9c32-70731c9ac11e Blockdev:pmem1 Dev:namespace1.0 NumaNode:1} {UUID:2bfe6c40-f79a-4b8e-bddf-ba81d4427b9b Blockdev:pmem0 Dev:namespace0.0 NumaNode:0}] sudo daos_server [<app_opts>] storage prepare [--scm-only|-s] --reset [<cmd_opts>] All namespaces are disabled and destroyed. The SCM regions are removed by resetting modules into \"MemoryMode\" through resource allocations. Note that undefined behavior may result if the namespaces/pmem kernel devices are mounted before running reset (as per the printed warning). A subsequent reboot is required for BIOS to read the new resource allocations. Example output when resetting the SCM modules: Memory allocation goals for SCM will be changed and namespaces modified, this will be a destructive operation. ensure namespaces are unmounted and SCM is otherwise unused. Are you sure you want to continue? (yes/no) yes removing SCM namespace, may take a few minutes... removing SCM namespace, may take a few minutes... resetting SCM memory allocations A reboot is required to process new memory allocation goals.","title":"SCM Preparation"},{"location":"admin/deployment/#nvme-preparation","text":"DAOS supports only NVMe-capable SSDs that are accessed directly from userspace through the SPDK library. NVMe access through SPDK as an unprivileged user can be enabled by running the example command sudo daos_server storage prepare --nvme-only -p 4096 -u bob . This will perform the required setup in order for daos_server to be run by user \"bob\" who will own the hugepage mountpoint directory and vfio groups as needed in SPDK operations. If the target-user is unspecified ( -u short option), the target user will be the issuer of the sudo command (or root if not using sudo). The specification of hugepages ( -p short option) defines the number of huge pages to allocate for use by SPDK. A list of PCI addresses can also be supplied to avoid unbinding all PCI devices from the kernel, using the -w / --pci-whitelist option. The sudo daos_server [<app_opts>] storage prepare [--nvme-only|-n] [<cmd_opts>] command wraps the SPDK setup script to unbind the devices from original kernel drivers and then binds the devices to a UIO driver through which SPDK can communicate. When a PCI address whitelist is not specified, SPDK access to all SSDs will be enabled for the user (either the user executing sudo, the user specified as --target-user, or effective user - in that order of precedence) involving changing the ownership of relevant files in addition to SPDK setup. The devices can then be bound back to the original drivers with the command sudo daos_server [<app_opts>] storage prepare [--nvme-only|-n] --reset [<cmd_opts>] .","title":"NVMe Preparation"},{"location":"admin/deployment/#storage-detection-selection","text":"While the DAOS server auto-detects all the usable storage, the administrator will still be provided with the ability through the configuration file (see next section) to whitelist or blacklist the storage devices to be (or not) used. This section covers how to manually detect the storage devices potentially usable by DAOS to populate the configuration file when the administrator wants to have finer control over the storage selection. sudo daos_server storage scan can be used to display locally-attached SSDs and Intel Persistent Memory Models usable by DAOS. $ daos_server storage scan [...] NVMe SSD controller and constituent namespaces: PCI Addr:0000:da:00.0 Serial:PHKS7505005Y750BGN Model:INTEL SSDPED1K750GA Fwrev:E2010325 Socket:1 Namespace: id:1 capacity:750 PCI Addr:0000:81:00.0 Serial:PHKS7505007J750BGN Model:INTEL SSDPED1K750GA Fwrev:E2010325 Socket:1 Namespace: id:1 capacity:750 PCI Addr:0000:87:00.0 Serial:CVFT5392000G1P6DGN Model:INTEL SSDPEDMD016T4 Fwrev:8DV10171 Socket:1 Namespace: id:1 capacity:1600 SCM modules: PhysicalID:36 Capacity:539661172736 Location:(socket:0 memctrlr:0 chan:0 pos:1) PhysicalID:40 Capacity:539661172736 Location:(socket:0 memctrlr:0 chan:1 pos:1) PhysicalID:44 Capacity:539661172736 Location:(socket:0 memctrlr:0 chan:2 pos:1) PhysicalID:50 Capacity:539661172736 Location:(socket:0 memctrlr:1 chan:0 pos:1) PhysicalID:52 Capacity:539661172736 Location:(socket:0 memctrlr:1 chan:1 pos:0) PhysicalID:55 Capacity:539661172736 Location:(socket:0 memctrlr:1 chan:2 pos:0) PhysicalID:62 Capacity:539661172736 Location:(socket:1 memctrlr:0 chan:0 pos:1) PhysicalID:66 Capacity:539661172736 Location:(socket:1 memctrlr:0 chan:1 pos:1) PhysicalID:70 Capacity:539661172736 Location:(socket:1 memctrlr:0 chan:2 pos:1) PhysicalID:76 Capacity:539661172736 Location:(socket:1 memctrlr:1 chan:0 pos:1) PhysicalID:78 Capacity:539661172736 Location:(socket:1 memctrlr:1 chan:1 pos:0) PhysicalID:81 Capacity:539661172736 Location:(socket:1 memctrlr:1 chan:2 pos:0) The pciaddr field above is what should be used in the server configuration file to identified NVMe SSDs. Devices with the same NUMA node/socket should be used in the same per-server section of the server configuration file for best performance.","title":"Storage Detection &amp; Selection"},{"location":"admin/deployment/#network-interface-detection-and-selection","text":"To display the supported OFI provider, use the following command: $ fi_info -l psm2: version: 1.7 ofi\\_rxm: version: 1.0 ofi\\_rxd: version: 1.0 verbs: version: 1.0 UDP: version: 1.1 sockets: version: 2.0 tcp: version: 0.1 ofi_perf_hook: version: 1.0 ofi_noop_hook: version: 1.0 shm: version: 1.0 ofi_mrail: version: 1.0 The fi_pingpong test (delivered as part of OFI/libfabric) can be used to verify that the targeted OFI provider works fine: node1$ fi_pingpong -p psm2 node2$ fi_pingpong -p psm2 ${IP_ADDRESS_NODE1} bytes #sent #ack total time MB/sec usec/xfer Mxfers/sec 64 10 =10 1.2k 0.00s 21.69 2.95 0.34 256 10 =10 5k 0.00s 116.36 2.20 0.45 1k 10 =10 20k 0.00s 379.26 2.70 0.37 4k 10 =10 80k 0.00s 1077.89 3.80 0.26 64k 10 =10 1.2m 0.00s 2145.20 30.55 0.03 1m 10 =10 20m 0.00s 8867.45 118.25 0.01","title":"Network Interface Detection and Selection"},{"location":"admin/deployment/#storage-firmware-upgrade","text":"Firmware on an NVMe controller can be updated from an image on local storage (initially installing from a local path on the host that is running daos_server but to be extended to downloading remotely from central storage location). When the controller is selected, and an update firmware task runs, controller data is accessed through an existing linked list through the binding fwupdate call, and a raw command specifying a firmware update with the local image (specified by file path) and slot identifier. The firmware update is followed by a hard reset on the controller.","title":"Storage Firmware Upgrade"},{"location":"admin/deployment/#storage-burn-in","text":"Burn-in testing can be performed on discovered NVMe controllers. By default, this involves a 15-minute slow burn-in test with a mixed read/write workload issued by fio, but test duration and load strength should be user-configurable. Burn-in should run in the background to allow administrators to use the control-plane for other tasks in the meantime. The fio repo is to be built and needs to be referenced when building the SPDK fio_plugin. The plug-in can then be run by fio to exercise the NVMe device through SPDK. Currently, the output of the burn-in is displayed in the shell, and control is returned to the user after completion. Future iterations may perform this as a background task.","title":"Storage Burn in"},{"location":"admin/deployment/#server-configuration","text":"This section addresses how to configure the DAOS servers on the storage nodes before starting it.","title":"Server Configuration"},{"location":"admin/deployment/#certificate-generation","text":"The DAOS security framework relies on certificates to authenticate administrators. The security infrastructure is currently under development and will be delivered in DAOS v1.0. Initial support for certificates has been added to DAOS and can be disabled either via the command line or in the DAOS server configuration file. Currently, the easiest way to disable certificate support is to pass the -i flag to daos_server.","title":"Certificate Generation"},{"location":"admin/deployment/#server-configuration-file","text":"The daos_server configuration file is parsed when starting the daos_server process. The configuration file location can be specified on the command line ( daos_server -h for usage) or default location ( install/etc/daos_server.yml ). Parameter descriptions are specified in daos_server.yml and example configuration files in the examples directory. Any option supplied to daos_server as a command line option or flag will take precedence over equivalent configuration file parameter. For convenience, active parsed configuration values are written to a temporary file for reference, and the location will be written to the log.","title":"Server Configuration File"},{"location":"admin/deployment/#configuration-file-options","text":"The example configuration file lists the default empty configuration, listing all the options (living documentation of the config file). Live examples are available at https://github.com/daos-stack/daos/tree/master/utils/config The location of this configuration file is determined by first checking for the path specified through the -o option of the daos_server command line. Otherwise, /etc/daos_server.conf is used. Refer to the example configuration file ( daos_server.yml ) for latest information and examples.","title":"Configuration File Options"},{"location":"admin/deployment/#server-startup","text":"DAOS currently relies on PMIx for server wire-up and application to server connection. As a result, the DAOS servers can only be started via orterun (part of OpenMPI). A new bootstrap procedure is under implementation and will be available for DAOS v1.0. This will remove the dependency on PMIx and will allow the DAOS servers to be started individually (e.g. independently on each storage node via systemd) or collectively (e.g. pdsh, mpirun or as a Kubernetes Pod).","title":"Server Startup"},{"location":"admin/deployment/#parallel-launcher","text":"As stated above, only orterun(1) is currently supported. The list of storage nodes can be specified on the command line via the -H option. The DAOS server and the application can be started separately but must share a URI directory (referred to as shared_dir) to connect. Also, the DAOS server must be started with the --enable-recovery option to support server failure. See the orterun(1) man page for additional options. To start the DAOS server, run: orterun --map-by node --mca btl tcp,self --mca oob tcp -np <num_servers> -H <server_list> --enable-recovery daos_server -a <shared_dir> -o <config_file> The --enable-recovery is required for fault tolerance to guarantee that the fault of one server does not cause the others to be stopped. The shared directory should be accessible by all nodes. The --allow-run-as-root option can be added to the command line to allow the daos_server to run with root privileges on each storage nodes (for example when needing to perform privileged tasks relating to storage format). The content of the configuration file is documented in the next section and a few examples are available . Client processes (i.e. utilities, applications, ...) should have the following environment variables set to connect to the DAOS servers: export DAOS_SINGLETON_CLI=1 export CRT_ATTACH_INFO_PATH=/path/to/shared_dir","title":"Parallel Launcher"},{"location":"admin/deployment/#systemd-integration","text":"Systemd support for daos_server is still experimental as it will start the daos_server and daos_io_server components in PMIXless mode, which is still in development. DAOS Server can be started as a systemd service. The DAOS Server unit file is installed in the correct location when installing from RPMs. If you wish to use systemd with a development build, you must copy the service file from utils/systemd to /usr/lib/systemd/system. Once the file is copied modify the ExecStart line to point to your in tree daos_server binary. Once the service file is installed you can start daos_server with the following commands: $ systemctl enable daos-server $ systemctl start daos-server To check the component status use: $ systemctl status daos-server If DAOS Server failed to start, check the logs with: $ journalctl --unit daos-server","title":"Systemd Integration"},{"location":"admin/deployment/#kubernetes-pod","text":"DAOS service integration with Kubernetes is planned and will be supported in a future DAOS version.","title":"Kubernetes Pod"},{"location":"admin/deployment/#service-monitoring","text":"On start-up, the daos_server will create and initialize the following components: gRPC server to handle requests over client API dRPC server to handle requests from IO servers over the UNIX domain socket storage subsystems for handling interactions with NVM devices SPDK environment using a shared memory segment identifier, causing the process to act as a primary in multi-process mode. From there, the main process can respond to requests over the client API for information through the SPDK interface. The daos_shell is a transitory tool used to exercise the management api and can be used to verify that the DAOS servers are up and running. It is to be run as a standard, unprivileged user as follows: $ daos_shell -l storagenode1:10001,storagenode2:10001 storage scan \"storagenode\" should be replaced with the actual hostname of each storage node. This command will show whether the DAOS server is properly running and initialized on each storage node. A more comprehensive and user-friendly tool built over the management API is under development. A first version will be available for DAOS v1.0.","title":"Service Monitoring"},{"location":"admin/deployment/#storage-formatting","text":"When 'daos_server' is started for the first time (and no SCM directory exists), it enters \"maintenance mode\" and waits for a daos_shell storage format call to be issued from the management tool. This remote call will trigger the formatting of the locally attached storage on the host for use with DAOS using the parameters defined in the server config file. daos_shell -i -l <host:port>[,...] storage format will normally be run on a login node specifying a hostlist ( -l <host:port>[,...] ) of storage nodes with SCM/DCPM modules and NVMe SSDs installed and prepared.","title":"Storage Formatting"},{"location":"admin/deployment/#scm-format","text":"When the command is run, the pmem kernel devices created on SCM/DCPM regions are formatted and mounted based on the parameters provided in the server config file. scm_mount specifies the location of the mountpoint to create. scm_class can be set to ram to use a tmpfs in the situation that no SCM/DCPM is available (scm_size dictates the size of tmpfs in GB), when set to dcpm the device specified under scm_list will be mounted at scm_mount path.","title":"SCM Format"},{"location":"admin/deployment/#nvme-format","text":"When the command is run, NVMe SSDs are formatted and set up to be used by DAOS based on the parameters provided in the server config file. bdev_class can be set to nvme to use actual NVMe devices with SPDK for DAOS storage. Other bdev_class values can be used for emulation of NVMe storage as specified in the server config file. bdev_list identifies devices to use with a list of PCI addresses (this can be populated after viewing results from storage scan command). After the format command is run, the path specified by the server configuration file scm_mount parameter should be mounted and should contain a file named daos_nvme.conf . The file should describe the devices with PCI addresses as listed in the bdev_list parameter of the server config file. The presence and contents of the file indicate that the specified NVMe SSDs have been configured correctly for use with DAOS. The contents of the NVMe SSDs listed in the server configuration file bdev_list parameter will be reset on format.","title":"NVMe Format"},{"location":"admin/deployment/#server-format","text":"Before the format command is run, no superblock file should exist under the path specified by scm_mount parameter in the server configuration file. After the storage format command is run, the path specified by the server configuration file scm_mount parameter should be mounted and should contain a file named superblock indicating that the server has been formatted. When starting, daos_server will skip maintenance mode and attempt to start IO services if the superblock is found in scm_mount .","title":"Server Format"},{"location":"admin/deployment/#basic-workflow","text":"Control plane server ( daos_server ) instances will listen for requests from the management tool ( daos_shell ), enabling users to perform provisioning operations on network and storage hardware remotely on storage nodes (from for example a login node). When daos_server instances have been started on each storage node for the first time, calling daos_shell -l <host:port>,... storage format -f formats persistent storage on the server node (skipping confirmation) on devices specified in the server configuration file, then writes the superblock and starts the data plane. Typically an administrator will perform the following tasks: Prepare NVMe and SCM Storage sudo daos_server [<app_opts>] storage prepare [<cmd_opts>] NVMe details SCM details Scan Storage sudo daos_server [<app_opts>] storage scan [<cmd_opts>] details Add device identifiers to Server config file vim <daos>/utils/config/examples/daos_server_sockets.yml details just specify NVMe PCI addresses with bdev_list for now Start DAOS control plane orterun -np 2 -H boro-44,boro-45 --enable-recovery daos_server -a shared_dir -o <daos>/utils/config/examples/daos_server_sockets.yml start details Provision Storage firmware update details burn-in testing details Amend Server config file (adjust based on the results of storage provisioning, requires a subsequent restart of daos_server ) vim <daos>/utils/config/examples/daos_server_sockets.yml details populate the scm_* and bdev_* parameters as used in format (below) Format Storage (from any node) When daos_server is started for the first time (and no SCM directory exists), daos_server enters \"maintenance mode\" and waits for a daos_shell storage format call to be issued from the management tool. This remote call will trigger the formatting of the locally attached storage on the host for use with DAOS using the parameters defined in the server config file. daos_shell -i -l <host:port>,... storage format -f management tool details SCM specific details NVMe specific details Example output $ daos_shell -i -l <hostname>:10001 -i storage format -f Active connections: [<hostname):10001] This is a destructive operation and storage devices specified in the server config file will be erased. Please be patient as it may take several minutes. NVMe storage format results: <hostname>:10001: pci-address 0000:da:00.0: status CTRL_SUCCESS pci-address 0000:81:00.0: status CTRL_SUCCESS SCM storage format results: <hostname>:10001: mntpoint /mnt/daos: status CTRL_SUCCESS","title":"Basic Workflow"},{"location":"admin/deployment/#agent-configuration","text":"This section addresses how to configure the DAOS agents on the storage nodes before starting it.","title":"Agent Configuration"},{"location":"admin/deployment/#agent-certificate-generation","text":"The DAOS security framework relies on certificates to authenticate administrators. The security infrastructure is currently under development and will be delivered in DAOS v1.0. Initial support for certificates has been added to DAOS and can be disabled either via the command line or in the DAOS Agent configuration file. Currently, the easiest way to disable certificate support is to pass the -i flag to daos_agent.","title":"Agent Certificate Generation"},{"location":"admin/deployment/#agent-configuration-file","text":"The daos_agent configuration file is parsed when starting the daos_agent process. The configuration file location can be specified on the command line ( daos_agent -h for usage) or default location ( install/etc/daos_agent.yml ). Parameter descriptions are specified in daos_agent.yml . Any option supplied to daos_agent as a command line option or flag will take precedence over equivalent configuration file parameter. For convenience, active parsed config values are written to a temporary file for reference, and the location will be written to the log. The following section lists the format, options, defaults, and descriptions available in the configuration file.","title":"Agent Configuration File"},{"location":"admin/deployment/#configuration-file-options_1","text":"The example configuration file lists the default empty configuration listing all the options (living documentation of the config file). Live examples are available at https://github.com/daos-stack/daos/tree/master/utils/config The location of this configuration file is determined by first checking for the path specified through the -o option of the daos_agent command line. Otherwise, /etc/daos_agent.conf is used. Refer to the example configuration file ( daos_server.yml ) for latest information and examples.","title":"Configuration File Options"},{"location":"admin/deployment/#agent-startup","text":"DAOS Agent is a standalone application to be run on each compute node. It can be configured to use secure communications (default) or can be allowed to communicate with the control plane over unencrypted channels. The following example shows daos_agent being configured to operate in insecure mode due to incomplete integration of certificate support as of the 0.6 release. To start the DAOS Agent from the command line, run: $ daos_agent -i Alternatively, the DAOS Agent can be started as a systemd service. The DAOS Agent unit file is installed in the correct location when installing from RPMs. If you wish to use systemd with a development build, you must copy the service file from utils/systemd to /usr/lib/systemd/system. Once the file is copied modify the ExecStart line to point to your in tree daos_agent binary. Once the service file is installed, you can start daos_agent with the following commands: $ systemctl enable daos-agent $ systemctl start daos-agent To check the component status use: $ systemctl status daos-agent If DAOS Agent failed to start check the logs with: $ journalctl --unit daos-agent","title":"Agent Startup"},{"location":"admin/deployment/#system-validation","text":"To validate that the DAOS system is properly installed, the daos_test suite can be executed. Ensure the DAOS Agent is configured and running before running daos_test and that the DAOS_SINGLETON_CLI and CRT_ATTACH_INFO_PATH environment variables are properly set as described here . orterun -np <num_clients> --hostfile <hostfile> ./daos_test daos_test requires at least 8GB of SCM (or DRAM with tmpfs) storage on each storage node.","title":"System Validation"},{"location":"admin/env_variables/","text":"DAOS Environment Variables This section lists the environment variables used by DAOS. Many of them are used for development purposes only and may be removed or changed in the future. The description of each variable follows the following format: Short description Type The default behavior if not set. A longer description if necessary This table defines a type: Type Values BOOL 0 means false; any other value means true BOOL2 no means false; any other value means true BOOL3 set to empty, or any value means true; unset means false INTEGER Non-negative decimal integer STRING String Common environment variables Environment variables in this section apply to both the server-side and the client-side. DAOS\\_IO\\_BYPASS Server environment variables Environment variables in this section only apply to the server-side. Variable Description VOS_CHECKSUM Checksum algorithm used by VOS. STRING. Default to disabling checksums. The following checksum algorithms are supported: crc64 and crc32. VOS_MEM_CLASS Memory class used by VOS. STRING. Default to persistent memory. If the value is set to DRAM, all data is stored in volatile memory; otherwise, all data is stored in persistent memory. RDB_ELECTION_TIMEOUT Raft election timeout used by RDBs in milliseconds. INTEGER. Default to 7000 ms. RDB_REQUEST_TIMEOUT Raft request timeout used by RDBs in milliseconds. INTEGER. Default to 3000 ms. DAOS_REBUILD Determines whether to start rebuilds when excluding targets. BOOL2. Default to true. DAOS_MD_CAP Size of a metadata pmem pool/file in MBs. INTEGER. Default to 128 MB. DAOS_START_POOL_SVC Determines whether to start existing pool services when starting a daos_server. BOOL. Default to true. DAOS_IMPLICIT_PURGE Whether to aggregate unreferenced epochs. BOOL. Default to false. DAOS_PURGE_CREDITS The number of credits for probing object trees when aggregating unreferenced epochs. INTEGER. Default to 1000. Client Environment variables in this section only apply to the client-side. Variable Description DAOS_SINGLETON_CLI Determines whether to run in the singleton mode, in which the client does not need to be launched by orterun. BOOL. Default to false. Debug System (Client & Server) Variable Description D_LOG_FILE DAOS debug logs (both server and client) are written to /tmp/daos.log by default. The debug location can be modified by setting this environment variable (\"D_LOG_FILE=/tmp/daos_server\"). DD_SUBSYS Used to specify which subsystems to enable. DD_SUBSYS can be set to individual subsystems for finer-grained debugging (\"DD_SUBSYS=vos\"), multiple facilities (\"DD_SUBSYS=eio,mgmt,misc,mem\"), or all facilities (\"DD_SUBSYS=all\") which is also the default setting. If a facility is not enabled, then only ERR messages or more severe messages will print. DD_STDERR Used to specify the priority level to output to stderr. Options in decreasing priority level order: FATAL, CRIT, ERR, WARN, NOTE, INFO, DEBUG. By default, all CRIT and more severe DAOS messages will log to stderr (\"DD_STDERR=CRIT\"), and the default for CaRT/GURT is FATAL. D_LOG_MASK Used to specify what type/level of logging will be present for either all of the registered subsystems or a select few. Options in decreasing priority level order: FATAL, CRIT, ERR, WARN, NOTE, INFO, DEBUG. DEBUG option is used to enable all logging (debug messages as well as all higher priority level messages). Note that if D_LOG_MASK is not set, it will default to logging all messages excluding debug (\"D_LOG_MASK=INFO\"). EX: \"D_LOG_MASK=DEBUG\" This will set the logging level for all facilities to DEBUG, meaning that all debug messages, as well as higher priority messages will be logged (INFO, NOTE, WARN, ERR, CRIT, FATAL) EX: \"D_LOG_MASK=DEBUG,MEM=ERR,RPC=ERR\" This will set the logging level to DEBUG for all facilities except MEM & RPC (which will now only log ERR and higher priority level messages, skipping all DEBUG, INFO, NOTE & WARN messages) DD_MASK Used to enable different debug streams for finer-grained debug messages, essentially allowing the user to specify an area of interest to debug (possibly involving many different subsystems) as opposed to parsing through many lines of generic DEBUG messages. All debug streams will be enabled by default (\"DD_MASK=all\"). Single debug masks can be set (\"DD_MASK=trace\") or multiple masks (\"DD_MASK=trace,test,mgmt\"). Note that since these debug streams are strictly related to the debug log messages, DD_LOG_MASK must be set to DEBUG. Priority messages higher than DEBUG will still be logged for all facilities unless otherwise specified by D_LOG_MASK (not affected by enabling debug masks).","title":"Environment Variables"},{"location":"admin/env_variables/#daos-environment-variables","text":"This section lists the environment variables used by DAOS. Many of them are used for development purposes only and may be removed or changed in the future. The description of each variable follows the following format: Short description Type The default behavior if not set. A longer description if necessary This table defines a type: Type Values BOOL 0 means false; any other value means true BOOL2 no means false; any other value means true BOOL3 set to empty, or any value means true; unset means false INTEGER Non-negative decimal integer STRING String","title":"DAOS Environment Variables"},{"location":"admin/env_variables/#common-environment-variables","text":"Environment variables in this section apply to both the server-side and the client-side. DAOS\\_IO\\_BYPASS","title":"Common environment variables"},{"location":"admin/env_variables/#server-environment-variables","text":"Environment variables in this section only apply to the server-side. Variable Description VOS_CHECKSUM Checksum algorithm used by VOS. STRING. Default to disabling checksums. The following checksum algorithms are supported: crc64 and crc32. VOS_MEM_CLASS Memory class used by VOS. STRING. Default to persistent memory. If the value is set to DRAM, all data is stored in volatile memory; otherwise, all data is stored in persistent memory. RDB_ELECTION_TIMEOUT Raft election timeout used by RDBs in milliseconds. INTEGER. Default to 7000 ms. RDB_REQUEST_TIMEOUT Raft request timeout used by RDBs in milliseconds. INTEGER. Default to 3000 ms. DAOS_REBUILD Determines whether to start rebuilds when excluding targets. BOOL2. Default to true. DAOS_MD_CAP Size of a metadata pmem pool/file in MBs. INTEGER. Default to 128 MB. DAOS_START_POOL_SVC Determines whether to start existing pool services when starting a daos_server. BOOL. Default to true. DAOS_IMPLICIT_PURGE Whether to aggregate unreferenced epochs. BOOL. Default to false. DAOS_PURGE_CREDITS The number of credits for probing object trees when aggregating unreferenced epochs. INTEGER. Default to 1000.","title":"Server environment variables"},{"location":"admin/env_variables/#client","text":"Environment variables in this section only apply to the client-side. Variable Description DAOS_SINGLETON_CLI Determines whether to run in the singleton mode, in which the client does not need to be launched by orterun. BOOL. Default to false.","title":"Client"},{"location":"admin/env_variables/#debug-system-client-server","text":"Variable Description D_LOG_FILE DAOS debug logs (both server and client) are written to /tmp/daos.log by default. The debug location can be modified by setting this environment variable (\"D_LOG_FILE=/tmp/daos_server\"). DD_SUBSYS Used to specify which subsystems to enable. DD_SUBSYS can be set to individual subsystems for finer-grained debugging (\"DD_SUBSYS=vos\"), multiple facilities (\"DD_SUBSYS=eio,mgmt,misc,mem\"), or all facilities (\"DD_SUBSYS=all\") which is also the default setting. If a facility is not enabled, then only ERR messages or more severe messages will print. DD_STDERR Used to specify the priority level to output to stderr. Options in decreasing priority level order: FATAL, CRIT, ERR, WARN, NOTE, INFO, DEBUG. By default, all CRIT and more severe DAOS messages will log to stderr (\"DD_STDERR=CRIT\"), and the default for CaRT/GURT is FATAL. D_LOG_MASK Used to specify what type/level of logging will be present for either all of the registered subsystems or a select few. Options in decreasing priority level order: FATAL, CRIT, ERR, WARN, NOTE, INFO, DEBUG. DEBUG option is used to enable all logging (debug messages as well as all higher priority level messages). Note that if D_LOG_MASK is not set, it will default to logging all messages excluding debug (\"D_LOG_MASK=INFO\"). EX: \"D_LOG_MASK=DEBUG\" This will set the logging level for all facilities to DEBUG, meaning that all debug messages, as well as higher priority messages will be logged (INFO, NOTE, WARN, ERR, CRIT, FATAL) EX: \"D_LOG_MASK=DEBUG,MEM=ERR,RPC=ERR\" This will set the logging level to DEBUG for all facilities except MEM & RPC (which will now only log ERR and higher priority level messages, skipping all DEBUG, INFO, NOTE & WARN messages) DD_MASK Used to enable different debug streams for finer-grained debug messages, essentially allowing the user to specify an area of interest to debug (possibly involving many different subsystems) as opposed to parsing through many lines of generic DEBUG messages. All debug streams will be enabled by default (\"DD_MASK=all\"). Single debug masks can be set (\"DD_MASK=trace\") or multiple masks (\"DD_MASK=trace,test,mgmt\"). Note that since these debug streams are strictly related to the debug log messages, DD_LOG_MASK must be set to DEBUG. Priority messages higher than DEBUG will still be logged for all facilities unless otherwise specified by D_LOG_MASK (not affected by enabling debug masks).","title":"Debug System (Client &amp; Server)"},{"location":"admin/hardware/","text":"Hardware Requirements The purpose of this section is to describe processor, storage, and network requirements to deploy a DAOS system. Deployment Options As illustrated in the figure below, a DAOS system can be deployed in two different ways: Pooled Storage Model : The DAOS servers can run on dedicated storage nodes in separate racks. This is a traditional pool model where storage is uniformly accessed by all compute nodes. In order to minimize the number of I/O racks and to optimize floor space, this approach usually requires high-density storage servers. Disaggregated Storage Model : In the disaggregated model, the storage nodes are integrated into compute racks and can be either dedicated or shared (e.g., in a hyper-converged infrastructure) nodes. The DAOS servers are thus massively distributed and storage access is non-uniform and must take locality into account. While DAOS is mostly deployed following the pooled model, active research is conducted to efficiently support the disaggregated model as well. Processor Requirements DAOS requires a 64-bit processor architecture and is primarily developed on Intel 64 architecture. The DAOS software and the libraries it depends on (e.g., ISA-L, SPDK, PMDK, and DPDK) can take advantage of Intel\u00ae SSE and AVX extensions. DAOS is also regularly tested on 64-bit ARM processors configured in Little Endian mode. The same build instructions that are used for x86-64 are applicable for ARM builds as well. DAOS and its dependencies will make the necessary adjustments automatically in their respective build systems for ARM platforms. Network Requirements The DAOS network layer relies on libfabrics and supports OFI providers for Ethernet/sockets, InfiniBand/verbs, RoCE, Cray\u2019s GNI, and the Intel Omni-Path Architecture. An RDMA-capable fabric is preferred for better performance. DAOS can support multiple rails by binding different instances of the DAOS server to individual network cards. An additional out-of-band network connecting the nodes in the DAOS service cluster is required for DAOS administration. Management traffic uses IP over Fabric. Storage Requirements DAOS requires each storage node to have direct access to storage-class memory (SCM). While DAOS is primarily tested and tuned for Optane DC Persistent Memory, the DAOS software stack is built over the Persistent Memory Development Kit (PMDK) and the DAX feature of the Linux and Windows operating systems as described in the SNIA NVM Programming Model ^1 . As a result, the open-source DAOS software stack should be able to run transparently over any storage-class memory supported by PMDK. The storage node can be optionally equipped with NVMe (non-volatile memory express) SSDs to provide capacity. HDDs, as well as SATA and SAS SSDs, are not supported by DAOS. Both NVMe 3D-NAND and Optane SSDs are supported. Optane SSDs are preferred for DAOS installation that targets a very high IOPS rate. NVMe-oF devices are also supported by the userspace storage stack, but have never been tested. The minimal recommended ratio between SCM and SSDs capacity is 6% to guarantee that DAOS has enough space in SCM to store internal metadata (e.g., pool metadata, SSD block allocation tracking). For testing purposes, SCM can be emulated with DRAM by mounting a tmpfs filesystem, and NVMe SSDs can be also emulated with DRAM or a loopback file. CPU Affinity On recent Xeon platforms, PCIe slots have a natural affinity to one CPU. Although globally accessible from any of the system cores, NVMe SSDs and network interface cards connected through the PCIe bus may provide different performance characteristics (e.g., higher latency, lower bandwidth) to each CPU. Accessing \u201cremote\u201d PCIe devices may involve traffic over the UPI (Ultra Path Interconnect) link that might become a point of congestion. Similarly, persistent memory is non-uniformly accessible (NUMA), and CPU affinity must be respected for maximal performance. Therefore, when running in a multi-socket and multi-rail environment, the DAOS service must be able to detect the CPU to PCIe device and persistent memory affinity and minimize as much as possible non-local access. This can be achieved by spawning one instance of the I/O server per CPU, then accessing only local persistent memory and PCI devices from that server instance. The control plane is responsible for detecting the storage and network affinity and starting the I/O servers accordingly. Fault Domains DAOS relies on single-ported storage massively distributed across different storage nodes. Each storage node is thus a single point of failure. DAOS achieves fault tolerance by providing data redundancy across storage nodes in different fault domains. DAOS assumes that fault domains are hierarchical and do not overlap. For instance, the first level of a fault domain could be the racks and the second one the storage nodes. For efficient placement and optimal data resilience, more fault domains are better. As a result, it is preferable to distribute storage nodes across as many racks as possible.","title":"Hardware Requirements"},{"location":"admin/hardware/#hardware-requirements","text":"The purpose of this section is to describe processor, storage, and network requirements to deploy a DAOS system.","title":"Hardware Requirements"},{"location":"admin/hardware/#deployment-options","text":"As illustrated in the figure below, a DAOS system can be deployed in two different ways: Pooled Storage Model : The DAOS servers can run on dedicated storage nodes in separate racks. This is a traditional pool model where storage is uniformly accessed by all compute nodes. In order to minimize the number of I/O racks and to optimize floor space, this approach usually requires high-density storage servers. Disaggregated Storage Model : In the disaggregated model, the storage nodes are integrated into compute racks and can be either dedicated or shared (e.g., in a hyper-converged infrastructure) nodes. The DAOS servers are thus massively distributed and storage access is non-uniform and must take locality into account. While DAOS is mostly deployed following the pooled model, active research is conducted to efficiently support the disaggregated model as well.","title":"Deployment Options"},{"location":"admin/hardware/#processor-requirements","text":"DAOS requires a 64-bit processor architecture and is primarily developed on Intel 64 architecture. The DAOS software and the libraries it depends on (e.g., ISA-L, SPDK, PMDK, and DPDK) can take advantage of Intel\u00ae SSE and AVX extensions. DAOS is also regularly tested on 64-bit ARM processors configured in Little Endian mode. The same build instructions that are used for x86-64 are applicable for ARM builds as well. DAOS and its dependencies will make the necessary adjustments automatically in their respective build systems for ARM platforms.","title":"Processor Requirements"},{"location":"admin/hardware/#network-requirements","text":"The DAOS network layer relies on libfabrics and supports OFI providers for Ethernet/sockets, InfiniBand/verbs, RoCE, Cray\u2019s GNI, and the Intel Omni-Path Architecture. An RDMA-capable fabric is preferred for better performance. DAOS can support multiple rails by binding different instances of the DAOS server to individual network cards. An additional out-of-band network connecting the nodes in the DAOS service cluster is required for DAOS administration. Management traffic uses IP over Fabric.","title":"Network Requirements"},{"location":"admin/hardware/#storage-requirements","text":"DAOS requires each storage node to have direct access to storage-class memory (SCM). While DAOS is primarily tested and tuned for Optane DC Persistent Memory, the DAOS software stack is built over the Persistent Memory Development Kit (PMDK) and the DAX feature of the Linux and Windows operating systems as described in the SNIA NVM Programming Model ^1 . As a result, the open-source DAOS software stack should be able to run transparently over any storage-class memory supported by PMDK. The storage node can be optionally equipped with NVMe (non-volatile memory express) SSDs to provide capacity. HDDs, as well as SATA and SAS SSDs, are not supported by DAOS. Both NVMe 3D-NAND and Optane SSDs are supported. Optane SSDs are preferred for DAOS installation that targets a very high IOPS rate. NVMe-oF devices are also supported by the userspace storage stack, but have never been tested. The minimal recommended ratio between SCM and SSDs capacity is 6% to guarantee that DAOS has enough space in SCM to store internal metadata (e.g., pool metadata, SSD block allocation tracking). For testing purposes, SCM can be emulated with DRAM by mounting a tmpfs filesystem, and NVMe SSDs can be also emulated with DRAM or a loopback file.","title":"Storage Requirements"},{"location":"admin/hardware/#cpu-affinity","text":"On recent Xeon platforms, PCIe slots have a natural affinity to one CPU. Although globally accessible from any of the system cores, NVMe SSDs and network interface cards connected through the PCIe bus may provide different performance characteristics (e.g., higher latency, lower bandwidth) to each CPU. Accessing \u201cremote\u201d PCIe devices may involve traffic over the UPI (Ultra Path Interconnect) link that might become a point of congestion. Similarly, persistent memory is non-uniformly accessible (NUMA), and CPU affinity must be respected for maximal performance. Therefore, when running in a multi-socket and multi-rail environment, the DAOS service must be able to detect the CPU to PCIe device and persistent memory affinity and minimize as much as possible non-local access. This can be achieved by spawning one instance of the I/O server per CPU, then accessing only local persistent memory and PCI devices from that server instance. The control plane is responsible for detecting the storage and network affinity and starting the I/O servers accordingly.","title":"CPU Affinity"},{"location":"admin/hardware/#fault-domains","text":"DAOS relies on single-ported storage massively distributed across different storage nodes. Each storage node is thus a single point of failure. DAOS achieves fault tolerance by providing data redundancy across storage nodes in different fault domains. DAOS assumes that fault domains are hierarchical and do not overlap. For instance, the first level of a fault domain could be the racks and the second one the storage nodes. For efficient placement and optimal data resilience, more fault domains are better. As a result, it is preferable to distribute storage nodes across as many racks as possible.","title":"Fault Domains"},{"location":"admin/installation/","text":"DAOS Software Installation DAOS runs on both Intel 64 and ARM64 platforms and has been successfully tested on CentOS 7, OpenSUSE 42.2 and Ubuntu 18.04 distributions. Software Dependencies DAOS requires a C99-capable compiler, a Go compiler, and the scons build tool. Moreover, the DAOS stack leverages the following open source projects: CaRT for high-performance communication leveraging advanced network capabilities. gRPC provides an secured out-of-band channel for DAOS administration. PMDK for persistent memory programming. SPDK for userspace NVMe device access and management. FIO for flexible testing of Linux I/O subsystems, specifically enabling validation of userspace NVMe device performance through fio-spdk plugin. ISA-L for checksum and erasure code computation. Argobots for thread management. The DAOS build system can be configured to download and build any missing dependencies automatically. Distribution Packages DAOS RPM and deb packaging is under development and will be available for DAOS v1.0. Integration with the Spack package manager is also under consideration. DAOS from Scratch The following instructions have been verified with CentOS. Installations on other Linux distributions might be similar with some variations. Developers of DAOS may want to review the additional sections below before beginning, for suggestions related specifically to development. Contact us in our forum for further help with any issues. Build Prerequisites To build DAOS and its dependencies, several software packages must be installed on the system. This includes scons, libuuid, cmocka, ipmctl, and several other packages usually available on all the Linux distributions. Moreover, a Go version of at least 1.10 is required. A exhaustive list of packages for each supported Linux distribution is maintained in the Docker files: CentOS OpenSUSE Ubuntu The command lines to install the required packages can be extracted from the Docker files by removing the \"RUN\" command which is specific to Docker. Check the docker directory for different Linux distribution versions. DAOS Source Code To check out the DAOS source code, run the following command: $ git clone https://github.com/daos-stack/daos.git This command clones the DAOS git repository (path referred as ${daospath} below). Then initialize the submodules with: $ cd ${daospath} $ git submodule init $ git submodule update Building DAOS & Dependencies If all the software dependencies listed previously are already satisfied, then type the following command in the top source directory to build the DAOS stack: $ scons --config=force install If you are a developer of DAOS, we recommend following the instructions in the DAOS for Development section. Otherwise, the missing dependencies can be built automatically by invoking scons with the following parameters: $ scons --config=force --build-deps=yes install By default, DAOS and its dependencies are installed under ${daospath}/install. The installation path can be modified by adding the PREFIX= option to the above command line (e.g., PREFIX=/usr/local). Environment setup Once built, the environment must be modified to search for binaries and header files in the installation path. This step is not required if standard locations (e.g. /bin, /sbin, /usr/lib, ...) are used. CPATH=${daospath}/install/include/:$CPATH PATH=${daospath}/install/bin/:${daospath}/install/sbin:$PATH export CPATH PATH If using bash, PATH can be set up for you after a build by sourcing the script scons_local/utils/setup_local.sh from the daos root. This script utilizes a file generated by the build to determine the location of daos and its dependencies. If required, ${daospath}/install must be replaced with the alternative path specified through PREFIX. DAOS in Docker This section describes how to build and run the DAOS service in a Docker container. A minimum of 5GB of DRAM and 16GB of disk space will be required. Building from GitHub To build the Docker image directly from GitHub, run the following command: $ docker build -t daos -f Dockerfile.centos.7 github.com/daos-stack/daos#:utils/docker This creates a CentOS 7 image, fetches the latest DAOS version from GitHub, builds it, and installs it in the image. For Ubuntu and other Linux distributions, replace Dockerfile.centos.7 with Dockerfile.ubuntu.18.04 and the appropriate version of interest. Once the image created, one can start start a container that will eventually run the DAOS service: $ docker run -it -d --privileged --name server \\ -v /tmp/uri:/tmp/uri \\ -v /dev/hugepages:/dev/hugepages \\ daos If Docker is being run on a non-Linux system (e.g., OSX), the export of /dev/hugepages should be removed since it is not supported. Building from a Local Tree To build from a local tree stored on the host, a volume must be created to share the source tree with the Docker container. To do so, execute the following command to create a docker image without checking out the DAOS source tree: $ docker build -t daos -f utils/docker/Dockerfile.centos.7 --build-arg NOBUILD=1 . Then create a container that can access the local DAOS source tree: $ docker run -it -d --privileged --name server \\ -v ${daospath}:/home/daos/daos:Z \\ -v /tmp/uri:/tmp/uri \\ -v /dev/hugepages:/dev/hugepages \\ daos ${daospath} should be replaced with the full path to your DAOS source tree. As mentioned above, the export of /dev/hugepages should be removed if the host is not a Linux system. Then execute the following command to build and install DAOS in the container: $ docker exec server scons --build-deps=yes install PREFIX=/usr Running DAOS Service in Docker First, SPDK should be initialized in this newly created container. This can be done by running the following command: $ docker exec server daos_server storage prepare -n -f Note that this command reports that /dev/hugepages is not accessible on OSX. This still allows running the DAOS service despite the error. The DAOS service can then be started as follows: $ docker exec server mkdir /var/run/daos_server $ docker exec server orterun -allow-run-as-root -H localhost -np 1 \\ daos_server start \\ -a /tmp/uri \\ -o /home/daos/daos/utils/config/examples/daos_server_local.yml The daos_server_local.yml configuration file sets up a simple local DAOS system with a single server instance running in the container. By default, it uses 4GB of DRAM to emulate persistent memory and 16GB of bulk storage under /tmp. The storage size can be changed in the yaml file if necessariy. Once started, the DAOS server waits for the administrator to format the system. This can be triggered in a different shell, using the following command: $ docker exec server daos_shell -i storage format -f Upon successful completion of the format, the storage engine is started, and pools can be created using the daos admin tool (see next section). Troubleshooting running DAOS in a Docker container A common problem is that the UIO driver is not loaded, resolve using the following commands: $ ls /sys/bus/pci/drivers/uio_pci_generic ls: cannot access /sys/bus/pci/drivers/uio_pci_generic: No such file or director $ sudo modprobe uio_pci_generic $ ls /sys/bus/pci/drivers/uio_pci_generic 0000:00:04.0 0000:00:04.3 0000:00:04.6 0000:5f:00.0 0000:80:04.2 0000:80:04.5 0000:81:00.0 module uevent 0000:00:04.1 0000:00:04.4 0000:00:04.7 0000:80:04.0 0000:80:04.3 0000:80:04.6 0000:da:00.0 new_id unbind 0000:00:04.2 0000:00:04.5 0000:5e:00.0 0000:80:04.1 0000:80:04.4 0000:80:04.7 bind remove_id $ sudo docker run -it -d --privileged --name server -v /tmp/uri:/tmp/uri -v /dev/hugepages:/dev/hugepages daos d60a2424d38bed55f8638b3a043dfc28b213edc0e4f6624e75abfcd1dd287309 $ sudo docker exec server daos_server storage prepare -n -f Preparing locally-attached NVMe storage... $ sudo docker exec server daos_server storage scan ... DAOS for Development This section covers specific instructions to create a developer-friendly environment to contribute to the DAOS development. This includes how to regenerate the protobuf files or add new Go package dependencies, which is only required for development purposes. Building DAOS for Development For development, it is recommended to build and install each dependency in a unique subdirectory. The DAOS build system supports this through the TARGET_PREFIX variable. Once the submodules have been initialized and updated, run the following commands: $ scons PREFIX=${daos_prefix_path} TARGET_PREFIX=${daos_prefix_path}/opt install --build-deps=yes --config=force Installing the components into seperate directories allow upgrading the components individually by replacing --build-deps=yes with --update-prereq={component_name}. This requires a change to the environment configuration from before. For automated environment setup, source scons_local/utils/setup_local.sh. ARGOBOTS=${daos_prefix_path}/opt/argobots CART=${daos_prefix_path}/opt/cart HWLOC=${daos_prefix_path}/opt/hwloc MERCURY=${daos_prefix_path}/opt/mercury PMDK=${daos_prefix_path}/opt/pmdk OMPI=${daos_prefix_path}/opt/ompi OPA=${daos_prefix_path}/opt/openpa PMIX=${daos_prefix_path}/opt/pmix FIO=${daos_prefix_path}/opt/fio SPDK=${daos_prefix_path}/opt/spdk PATH=$CART/bin/:$OMPI/bin/:${daos_prefix_path}/bin/:$PATH With this approach, DAOS would get built using the prebuilt dependencies in ${daos_prefix_path}/opt, and required options are saved for future compilations. So, after the first time, during development, only \"scons --config=force\" and \"scons --config=force install\" would suffice for compiling changes to DAOS source code. If you wish to compile DAOS with clang rather than gcc, set COMPILER=clang on the scons command line. This option is also saved for future compilations. Go dependencies Developers contributing Go code may need to change the external dependencies located in the src/control/vendor directory. The DAOS codebase uses dep to manage these dependencies. On EL7 and later: $ yum install yum-plugin-copr $ yum copr enable hnakamur/golang-dep $ yum install golang-dep On Fedora 27 and later: $ dnf install dep On Ubuntu 18.04 and later: $ apt-get install go-dep For OSes that don't supply a package: Ensure that you have a personal GOPATH (see \"go env GOPATH\", referred to as \"$GOPATH\" in this document) and a GOBIN ($GOPATH/bin) set up and included in your PATH: $ mkdir -p $GOPATH/bin $ export PATH=$GOPATH/bin:$PATH Then follow the installation instructions on Github . To update the vendor directory using dep after changing Gopkg.toml, make sure DAOS is cloned into \"$GOPATH/src/github.com/daos-stack/daos\" Then: $ cd $GOPATH/src/github.com/daos-stack/daos/src/control $ dep ensure Protobuf Compiler The DAOS control plane infrastructure uses protobuf as the data serialization format for its RPC requests. The DAOS proto files use protobuf 3 syntax, which is not supported by the platform protobuf compiler in all cases. Not all developers will need to build the proto files into the various source files. However, if changes are made to the proto files, the corresponding C and Go source files will need to be regenerated with a protobuf 3.* or higher compiler. The recommended installation method is to clone the git repositories, check out the tagged releases noted below, and install from source. Later versions may work, but are not guaranteed. Protocol Buffers v3.5.1. Installation instructions . Protobuf-C v1.3.1. Installation instructions . gRPC plugin: protoc-gen-go v1.2.0. Must match the proto version in src/control/Gopkg.toml. Install the specific version using GIT_TAG instructions here . Generate the Go file using the gRPC plugin. You can designate the directory location: $ protoc myfile.proto --go_out=plugins=grpc:<go_file_dir> Generate the C files using Protobuf-C. As the header and source files in DAOS are typically kept in separate locations, you will need to move them manually to their destination directories: $ protoc-c myfile.proto --c_out=. $ mv myfile.pb-c.h <c_file_include_dir> $ mv myfile.pb-c.c <c_file_src_dir>","title":"Software Installation"},{"location":"admin/installation/#daos-software-installation","text":"DAOS runs on both Intel 64 and ARM64 platforms and has been successfully tested on CentOS 7, OpenSUSE 42.2 and Ubuntu 18.04 distributions.","title":"DAOS Software Installation"},{"location":"admin/installation/#software-dependencies","text":"DAOS requires a C99-capable compiler, a Go compiler, and the scons build tool. Moreover, the DAOS stack leverages the following open source projects: CaRT for high-performance communication leveraging advanced network capabilities. gRPC provides an secured out-of-band channel for DAOS administration. PMDK for persistent memory programming. SPDK for userspace NVMe device access and management. FIO for flexible testing of Linux I/O subsystems, specifically enabling validation of userspace NVMe device performance through fio-spdk plugin. ISA-L for checksum and erasure code computation. Argobots for thread management. The DAOS build system can be configured to download and build any missing dependencies automatically.","title":"Software Dependencies"},{"location":"admin/installation/#distribution-packages","text":"DAOS RPM and deb packaging is under development and will be available for DAOS v1.0. Integration with the Spack package manager is also under consideration.","title":"Distribution Packages"},{"location":"admin/installation/#daos-from-scratch","text":"The following instructions have been verified with CentOS. Installations on other Linux distributions might be similar with some variations. Developers of DAOS may want to review the additional sections below before beginning, for suggestions related specifically to development. Contact us in our forum for further help with any issues.","title":"DAOS from Scratch"},{"location":"admin/installation/#build-prerequisites","text":"To build DAOS and its dependencies, several software packages must be installed on the system. This includes scons, libuuid, cmocka, ipmctl, and several other packages usually available on all the Linux distributions. Moreover, a Go version of at least 1.10 is required. A exhaustive list of packages for each supported Linux distribution is maintained in the Docker files: CentOS OpenSUSE Ubuntu The command lines to install the required packages can be extracted from the Docker files by removing the \"RUN\" command which is specific to Docker. Check the docker directory for different Linux distribution versions.","title":"Build Prerequisites"},{"location":"admin/installation/#daos-source-code","text":"To check out the DAOS source code, run the following command: $ git clone https://github.com/daos-stack/daos.git This command clones the DAOS git repository (path referred as ${daospath} below). Then initialize the submodules with: $ cd ${daospath} $ git submodule init $ git submodule update","title":"DAOS Source Code"},{"location":"admin/installation/#building-daos-dependencies","text":"If all the software dependencies listed previously are already satisfied, then type the following command in the top source directory to build the DAOS stack: $ scons --config=force install If you are a developer of DAOS, we recommend following the instructions in the DAOS for Development section. Otherwise, the missing dependencies can be built automatically by invoking scons with the following parameters: $ scons --config=force --build-deps=yes install By default, DAOS and its dependencies are installed under ${daospath}/install. The installation path can be modified by adding the PREFIX= option to the above command line (e.g., PREFIX=/usr/local).","title":"Building DAOS &amp; Dependencies"},{"location":"admin/installation/#environment-setup","text":"Once built, the environment must be modified to search for binaries and header files in the installation path. This step is not required if standard locations (e.g. /bin, /sbin, /usr/lib, ...) are used. CPATH=${daospath}/install/include/:$CPATH PATH=${daospath}/install/bin/:${daospath}/install/sbin:$PATH export CPATH PATH If using bash, PATH can be set up for you after a build by sourcing the script scons_local/utils/setup_local.sh from the daos root. This script utilizes a file generated by the build to determine the location of daos and its dependencies. If required, ${daospath}/install must be replaced with the alternative path specified through PREFIX.","title":"Environment setup"},{"location":"admin/installation/#daos-in-docker","text":"This section describes how to build and run the DAOS service in a Docker container. A minimum of 5GB of DRAM and 16GB of disk space will be required.","title":"DAOS in Docker"},{"location":"admin/installation/#building-from-github","text":"To build the Docker image directly from GitHub, run the following command: $ docker build -t daos -f Dockerfile.centos.7 github.com/daos-stack/daos#:utils/docker This creates a CentOS 7 image, fetches the latest DAOS version from GitHub, builds it, and installs it in the image. For Ubuntu and other Linux distributions, replace Dockerfile.centos.7 with Dockerfile.ubuntu.18.04 and the appropriate version of interest. Once the image created, one can start start a container that will eventually run the DAOS service: $ docker run -it -d --privileged --name server \\ -v /tmp/uri:/tmp/uri \\ -v /dev/hugepages:/dev/hugepages \\ daos If Docker is being run on a non-Linux system (e.g., OSX), the export of /dev/hugepages should be removed since it is not supported.","title":"Building from GitHub"},{"location":"admin/installation/#building-from-a-local-tree","text":"To build from a local tree stored on the host, a volume must be created to share the source tree with the Docker container. To do so, execute the following command to create a docker image without checking out the DAOS source tree: $ docker build -t daos -f utils/docker/Dockerfile.centos.7 --build-arg NOBUILD=1 . Then create a container that can access the local DAOS source tree: $ docker run -it -d --privileged --name server \\ -v ${daospath}:/home/daos/daos:Z \\ -v /tmp/uri:/tmp/uri \\ -v /dev/hugepages:/dev/hugepages \\ daos ${daospath} should be replaced with the full path to your DAOS source tree. As mentioned above, the export of /dev/hugepages should be removed if the host is not a Linux system. Then execute the following command to build and install DAOS in the container: $ docker exec server scons --build-deps=yes install PREFIX=/usr","title":"Building from a Local Tree"},{"location":"admin/installation/#running-daos-service-in-docker","text":"First, SPDK should be initialized in this newly created container. This can be done by running the following command: $ docker exec server daos_server storage prepare -n -f Note that this command reports that /dev/hugepages is not accessible on OSX. This still allows running the DAOS service despite the error. The DAOS service can then be started as follows: $ docker exec server mkdir /var/run/daos_server $ docker exec server orterun -allow-run-as-root -H localhost -np 1 \\ daos_server start \\ -a /tmp/uri \\ -o /home/daos/daos/utils/config/examples/daos_server_local.yml The daos_server_local.yml configuration file sets up a simple local DAOS system with a single server instance running in the container. By default, it uses 4GB of DRAM to emulate persistent memory and 16GB of bulk storage under /tmp. The storage size can be changed in the yaml file if necessariy. Once started, the DAOS server waits for the administrator to format the system. This can be triggered in a different shell, using the following command: $ docker exec server daos_shell -i storage format -f Upon successful completion of the format, the storage engine is started, and pools can be created using the daos admin tool (see next section).","title":"Running DAOS Service in Docker"},{"location":"admin/installation/#troubleshooting-running-daos-in-a-docker-container","text":"A common problem is that the UIO driver is not loaded, resolve using the following commands: $ ls /sys/bus/pci/drivers/uio_pci_generic ls: cannot access /sys/bus/pci/drivers/uio_pci_generic: No such file or director $ sudo modprobe uio_pci_generic $ ls /sys/bus/pci/drivers/uio_pci_generic 0000:00:04.0 0000:00:04.3 0000:00:04.6 0000:5f:00.0 0000:80:04.2 0000:80:04.5 0000:81:00.0 module uevent 0000:00:04.1 0000:00:04.4 0000:00:04.7 0000:80:04.0 0000:80:04.3 0000:80:04.6 0000:da:00.0 new_id unbind 0000:00:04.2 0000:00:04.5 0000:5e:00.0 0000:80:04.1 0000:80:04.4 0000:80:04.7 bind remove_id $ sudo docker run -it -d --privileged --name server -v /tmp/uri:/tmp/uri -v /dev/hugepages:/dev/hugepages daos d60a2424d38bed55f8638b3a043dfc28b213edc0e4f6624e75abfcd1dd287309 $ sudo docker exec server daos_server storage prepare -n -f Preparing locally-attached NVMe storage... $ sudo docker exec server daos_server storage scan ...","title":"Troubleshooting running DAOS in a Docker container"},{"location":"admin/installation/#daos-for-development","text":"This section covers specific instructions to create a developer-friendly environment to contribute to the DAOS development. This includes how to regenerate the protobuf files or add new Go package dependencies, which is only required for development purposes.","title":"DAOS for Development"},{"location":"admin/installation/#building-daos-for-development","text":"For development, it is recommended to build and install each dependency in a unique subdirectory. The DAOS build system supports this through the TARGET_PREFIX variable. Once the submodules have been initialized and updated, run the following commands: $ scons PREFIX=${daos_prefix_path} TARGET_PREFIX=${daos_prefix_path}/opt install --build-deps=yes --config=force Installing the components into seperate directories allow upgrading the components individually by replacing --build-deps=yes with --update-prereq={component_name}. This requires a change to the environment configuration from before. For automated environment setup, source scons_local/utils/setup_local.sh. ARGOBOTS=${daos_prefix_path}/opt/argobots CART=${daos_prefix_path}/opt/cart HWLOC=${daos_prefix_path}/opt/hwloc MERCURY=${daos_prefix_path}/opt/mercury PMDK=${daos_prefix_path}/opt/pmdk OMPI=${daos_prefix_path}/opt/ompi OPA=${daos_prefix_path}/opt/openpa PMIX=${daos_prefix_path}/opt/pmix FIO=${daos_prefix_path}/opt/fio SPDK=${daos_prefix_path}/opt/spdk PATH=$CART/bin/:$OMPI/bin/:${daos_prefix_path}/bin/:$PATH With this approach, DAOS would get built using the prebuilt dependencies in ${daos_prefix_path}/opt, and required options are saved for future compilations. So, after the first time, during development, only \"scons --config=force\" and \"scons --config=force install\" would suffice for compiling changes to DAOS source code. If you wish to compile DAOS with clang rather than gcc, set COMPILER=clang on the scons command line. This option is also saved for future compilations.","title":"Building DAOS for Development"},{"location":"admin/installation/#go-dependencies","text":"Developers contributing Go code may need to change the external dependencies located in the src/control/vendor directory. The DAOS codebase uses dep to manage these dependencies. On EL7 and later: $ yum install yum-plugin-copr $ yum copr enable hnakamur/golang-dep $ yum install golang-dep On Fedora 27 and later: $ dnf install dep On Ubuntu 18.04 and later: $ apt-get install go-dep For OSes that don't supply a package: Ensure that you have a personal GOPATH (see \"go env GOPATH\", referred to as \"$GOPATH\" in this document) and a GOBIN ($GOPATH/bin) set up and included in your PATH: $ mkdir -p $GOPATH/bin $ export PATH=$GOPATH/bin:$PATH Then follow the installation instructions on Github . To update the vendor directory using dep after changing Gopkg.toml, make sure DAOS is cloned into \"$GOPATH/src/github.com/daos-stack/daos\" Then: $ cd $GOPATH/src/github.com/daos-stack/daos/src/control $ dep ensure","title":"Go dependencies"},{"location":"admin/installation/#protobuf-compiler","text":"The DAOS control plane infrastructure uses protobuf as the data serialization format for its RPC requests. The DAOS proto files use protobuf 3 syntax, which is not supported by the platform protobuf compiler in all cases. Not all developers will need to build the proto files into the various source files. However, if changes are made to the proto files, the corresponding C and Go source files will need to be regenerated with a protobuf 3.* or higher compiler. The recommended installation method is to clone the git repositories, check out the tagged releases noted below, and install from source. Later versions may work, but are not guaranteed. Protocol Buffers v3.5.1. Installation instructions . Protobuf-C v1.3.1. Installation instructions . gRPC plugin: protoc-gen-go v1.2.0. Must match the proto version in src/control/Gopkg.toml. Install the specific version using GIT_TAG instructions here . Generate the Go file using the gRPC plugin. You can designate the directory location: $ protoc myfile.proto --go_out=plugins=grpc:<go_file_dir> Generate the C files using Protobuf-C. As the header and source files in DAOS are typically kept in separate locations, you will need to move them manually to their destination directories: $ protoc-c myfile.proto --c_out=. $ mv myfile.pb-c.h <c_file_include_dir> $ mv myfile.pb-c.c <c_file_src_dir>","title":"Protobuf Compiler"},{"location":"admin/intro/","text":"Introduction The Distributed Asynchronous Object Storage (DAOS) is an open-source object store designed from the ground up for massively distributed Non Volatile Memory (NVM). DAOS takes advantage of next-generation NVM technology, like Storage Class Memory (SCM) and NVM express (NVMe), while presenting a key-value storage interface on top of commodity hardware that provides features, such as, transactional non-blocking I/O, advanced data protection with self-healing, end-to-end data integrity, fine-grained data control, and elastic storage, to optimize performance and cost. This administration guide version is associated with DAOS v0.7. Additional Documentation Refer to the following documentation for architecture and description: Document Location DAOS Internals https://github.com/daos-stack/daos/blob/master/src/README.md DAOS Storage Model https://github.com/daos-stack/daos/blob/master/doc/storage_model.md Community Roadmap https://wiki.hpdd.intel.com/display/DC/Roadmap","title":"Introduction"},{"location":"admin/intro/#introduction","text":"The Distributed Asynchronous Object Storage (DAOS) is an open-source object store designed from the ground up for massively distributed Non Volatile Memory (NVM). DAOS takes advantage of next-generation NVM technology, like Storage Class Memory (SCM) and NVM express (NVMe), while presenting a key-value storage interface on top of commodity hardware that provides features, such as, transactional non-blocking I/O, advanced data protection with self-healing, end-to-end data integrity, fine-grained data control, and elastic storage, to optimize performance and cost. This administration guide version is associated with DAOS v0.7.","title":"Introduction"},{"location":"admin/intro/#additional-documentation","text":"Refer to the following documentation for architecture and description: Document Location DAOS Internals https://github.com/daos-stack/daos/blob/master/src/README.md DAOS Storage Model https://github.com/daos-stack/daos/blob/master/doc/storage_model.md Community Roadmap https://wiki.hpdd.intel.com/display/DC/Roadmap","title":"Additional Documentation"},{"location":"admin/performance_tuning/","text":"DAOS Performance Tuning This section will be expanded in a future revision. Network Performance Similar to the Lustre Network stack, the DAOS CART layer can validate and benchmark network communications in the same context as an application and using the same networks/tuning options as regular DAOS. The CART selftest can run against the DAOS servers in a production environment in a non-destructive manner. CART selftest supports different message sizes, bulk transfers, multiple targets, and the following test scenarios: Selftest client to servers where selftest issues RPCs directly to a list of servers Cross-servers where selftest sends instructions to the different servers that will issue cross-server RPCs. This model supports a many to many communication model. Instructions on how to run CART selftest will be provided in the next revision of this document. Benchmarking DAOS DAOS can be benchmarked with both IOR and mdtest through the following backends: native MPI-IO plugin combined with the ROMIO DAOS ADIO driver native HDF5 plugin combined with the HDF5 DAOS connector (under development) native POSIX plugin over dfuse and interception library (under development) a custom DFS plugin integrating mdtest & IOR directly with libfs without requiring FUSE or an interception library a custom DAOS plugin integrating IOR directly with the native DAOS array API.","title":"Performance Tuning"},{"location":"admin/performance_tuning/#daos-performance-tuning","text":"This section will be expanded in a future revision.","title":"DAOS Performance Tuning"},{"location":"admin/performance_tuning/#network-performance","text":"Similar to the Lustre Network stack, the DAOS CART layer can validate and benchmark network communications in the same context as an application and using the same networks/tuning options as regular DAOS. The CART selftest can run against the DAOS servers in a production environment in a non-destructive manner. CART selftest supports different message sizes, bulk transfers, multiple targets, and the following test scenarios: Selftest client to servers where selftest issues RPCs directly to a list of servers Cross-servers where selftest sends instructions to the different servers that will issue cross-server RPCs. This model supports a many to many communication model. Instructions on how to run CART selftest will be provided in the next revision of this document.","title":"Network Performance"},{"location":"admin/performance_tuning/#benchmarking-daos","text":"DAOS can be benchmarked with both IOR and mdtest through the following backends: native MPI-IO plugin combined with the ROMIO DAOS ADIO driver native HDF5 plugin combined with the HDF5 DAOS connector (under development) native POSIX plugin over dfuse and interception library (under development) a custom DFS plugin integrating mdtest & IOR directly with libfs without requiring FUSE or an interception library a custom DAOS plugin integrating IOR directly with the native DAOS array API.","title":"Benchmarking DAOS"},{"location":"admin/pool_operations/","text":"DAOS Pool Operations A DAOS pool is a storage reservation that can span any storage nodes and is managed by the administrator. The amount of space allocated to a pool is decided at creation time and can eventually be expanded through the management interface. Pool Creation/Destroy A DAOS pool can be created and destroyed through the DAOS management API (see daos_mgmt.h). DAOS also provides a utility called dmg to manage storage pools from the command line. To create a pool: $ dmg create --size=xxG --nvme=yyT This command creates a pool distributed across the DAOS servers with a target size on each server with xxGB of SCM and yyTB of NVMe storage. The UUID allocated to the newly created pool is printed to stdout (referred as ${puuid}) as well as the rank where the pool service is located (referred as ${svcl}). The typical output of this command is as follows: $ dmg create --size=xxG --nvme=yyT 4056fb6d-9fca-4f2d-af8a-cfd57d92a92d 1:2 This created a pool with UUID 4056fb6d-9fca-4f2d-af8a-cfd57d92a92d with two pool service replica on rank 1 and 2. To destroy a pool: $ dmg destroy --pool=${puuid} Pool Properties At creation time, a list of pool properties can be specified through the API (not supported by the tool yet): DAOS_PROP_CO_LABEL is a string that the administrator can associate with a pool. e.g., project A, project B, IO500 test pool DAOS_PROP_PO_ACL is the access control list (ACL) associated with the pool DAOS_PROP_PO_SPACE_RB is the space to be reserved on each target for rebuild purpose. DAOS_PROP_PO_SELF_HEAL defines whether the pool wants automatically-trigger, or manually-triggered self-healing. DAOS_PROP_PO_RECLAIM is used to tune the space reclaim strategy based on time interval, batched commits or snapshot creation. While those pool properties are currently stored persistently with pool metadata, many of them are still under development. Moreover, the ability to modify some of those properties on an existing pool will also be provided in a future release. Pool ACLs Support for per-pool Access Control Lists (ACLs) is under development and is scheduled for DAOS v1.0. DAOS ACLs will implement a subset of the NFSv4 ACL standard. This feature will be documented here once available. The pool query operation retrieves information (i.e., the number of targets, space usage, rebuild status, property list, and more) about a created pool. It is integrated into the dmg utility. To query a pool: $ dmg query --svc=${svcl} --pool=${puuid} Below is the output for a pool created with SCM space only. pool=47293abe-aa6f-4147-97f6-42a9f796d64a Pool 47293abe-aa6f-4147-97f6-42a9f796d64a, ntarget=64, disabled=8 Pool space info: - Target(VOS) count:56 - SCM: Total size: 30064771072 Free: 30044570496, min:530139584, max:536869696, mean:536510187 - NVMe: Total size: 0 Free: 0, min:0, max:0, mean:0 Rebuild done, 10 objs, 1026 recs The total and free sizes are the sum across all the targets whereas min/max/mean gives information about individual targets. A min value close to 0 means that one target is running out of space. The example below shows a rebuild in progress and NVMe space allocated. pool=95886b8b-7eb8-454d-845c-fc0ae0ba5671 Pool 95886b8b-7eb8-454d-845c-fc0ae0ba5671, ntarget=64, disabled=8 Pool space info: - Target(VOS) count:56 - SCM: Total size: 30064771072 Free: 29885237632, min:493096384, max:536869696, mean:533664957 - NVMe: Total size: 60129542144 Free: 29885237632, min:493096384, max:536869696, mean:533664957 Rebuild busy, 75 objs, 9722 recs Additional status and telemetry data are planned to be exported through the management API and tool and will be documented here once available. Pool Modifications Target Exclusion and Self-Healing To exclude a target from a pool: $ dmg exclude --svc=${svcl} --pool=${puuid} --target=${rank} Pool Extension Target Addition & Space Rebalancing Support for online target addition and automatic space rebalancing is planned for DAOS v1.4 and will be documented here once available. Pool Shard Resize Support for quiescent pool shard resize is currently not supported and is under consideration. Pool Catastrophic Recovery A DAOS pool is instantiated on each target by a set of pmemobj files managed by PMDK and SPDK blobs on SSDs. Tools to verify and repair this persistent data is scheduled for DAOS v2.4 and will be documented here once available. Meanwhile, PMDK provides a recovery tool (i.e., pmempool check) to verify and possibly repair a pmemobj file. As discussed in the previous section, the rebuild status can be consulted via the pool query and will be expanded with more information.","title":"Pool Operations"},{"location":"admin/pool_operations/#daos-pool-operations","text":"A DAOS pool is a storage reservation that can span any storage nodes and is managed by the administrator. The amount of space allocated to a pool is decided at creation time and can eventually be expanded through the management interface.","title":"DAOS Pool Operations"},{"location":"admin/pool_operations/#pool-creationdestroy","text":"A DAOS pool can be created and destroyed through the DAOS management API (see daos_mgmt.h). DAOS also provides a utility called dmg to manage storage pools from the command line. To create a pool: $ dmg create --size=xxG --nvme=yyT This command creates a pool distributed across the DAOS servers with a target size on each server with xxGB of SCM and yyTB of NVMe storage. The UUID allocated to the newly created pool is printed to stdout (referred as ${puuid}) as well as the rank where the pool service is located (referred as ${svcl}). The typical output of this command is as follows: $ dmg create --size=xxG --nvme=yyT 4056fb6d-9fca-4f2d-af8a-cfd57d92a92d 1:2 This created a pool with UUID 4056fb6d-9fca-4f2d-af8a-cfd57d92a92d with two pool service replica on rank 1 and 2. To destroy a pool: $ dmg destroy --pool=${puuid}","title":"Pool Creation/Destroy"},{"location":"admin/pool_operations/#pool-properties","text":"At creation time, a list of pool properties can be specified through the API (not supported by the tool yet): DAOS_PROP_CO_LABEL is a string that the administrator can associate with a pool. e.g., project A, project B, IO500 test pool DAOS_PROP_PO_ACL is the access control list (ACL) associated with the pool DAOS_PROP_PO_SPACE_RB is the space to be reserved on each target for rebuild purpose. DAOS_PROP_PO_SELF_HEAL defines whether the pool wants automatically-trigger, or manually-triggered self-healing. DAOS_PROP_PO_RECLAIM is used to tune the space reclaim strategy based on time interval, batched commits or snapshot creation. While those pool properties are currently stored persistently with pool metadata, many of them are still under development. Moreover, the ability to modify some of those properties on an existing pool will also be provided in a future release.","title":"Pool Properties"},{"location":"admin/pool_operations/#pool-acls","text":"Support for per-pool Access Control Lists (ACLs) is under development and is scheduled for DAOS v1.0. DAOS ACLs will implement a subset of the NFSv4 ACL standard. This feature will be documented here once available. The pool query operation retrieves information (i.e., the number of targets, space usage, rebuild status, property list, and more) about a created pool. It is integrated into the dmg utility. To query a pool: $ dmg query --svc=${svcl} --pool=${puuid} Below is the output for a pool created with SCM space only. pool=47293abe-aa6f-4147-97f6-42a9f796d64a Pool 47293abe-aa6f-4147-97f6-42a9f796d64a, ntarget=64, disabled=8 Pool space info: - Target(VOS) count:56 - SCM: Total size: 30064771072 Free: 30044570496, min:530139584, max:536869696, mean:536510187 - NVMe: Total size: 0 Free: 0, min:0, max:0, mean:0 Rebuild done, 10 objs, 1026 recs The total and free sizes are the sum across all the targets whereas min/max/mean gives information about individual targets. A min value close to 0 means that one target is running out of space. The example below shows a rebuild in progress and NVMe space allocated. pool=95886b8b-7eb8-454d-845c-fc0ae0ba5671 Pool 95886b8b-7eb8-454d-845c-fc0ae0ba5671, ntarget=64, disabled=8 Pool space info: - Target(VOS) count:56 - SCM: Total size: 30064771072 Free: 29885237632, min:493096384, max:536869696, mean:533664957 - NVMe: Total size: 60129542144 Free: 29885237632, min:493096384, max:536869696, mean:533664957 Rebuild busy, 75 objs, 9722 recs Additional status and telemetry data are planned to be exported through the management API and tool and will be documented here once available.","title":"Pool ACLs"},{"location":"admin/pool_operations/#pool-modifications","text":"","title":"Pool Modifications"},{"location":"admin/pool_operations/#target-exclusion-and-self-healing","text":"To exclude a target from a pool: $ dmg exclude --svc=${svcl} --pool=${puuid} --target=${rank}","title":"Target Exclusion and Self-Healing"},{"location":"admin/pool_operations/#pool-extension","text":"","title":"Pool Extension"},{"location":"admin/pool_operations/#target-addition-space-rebalancing","text":"Support for online target addition and automatic space rebalancing is planned for DAOS v1.4 and will be documented here once available.","title":"Target Addition &amp; Space Rebalancing"},{"location":"admin/pool_operations/#pool-shard-resize","text":"Support for quiescent pool shard resize is currently not supported and is under consideration.","title":"Pool Shard Resize"},{"location":"admin/pool_operations/#pool-catastrophic-recovery","text":"A DAOS pool is instantiated on each target by a set of pmemobj files managed by PMDK and SPDK blobs on SSDs. Tools to verify and repair this persistent data is scheduled for DAOS v2.4 and will be documented here once available. Meanwhile, PMDK provides a recovery tool (i.e., pmempool check) to verify and possibly repair a pmemobj file. As discussed in the previous section, the rebuild status can be consulted via the pool query and will be expanded with more information.","title":"Pool Catastrophic Recovery"},{"location":"admin/troubleshooting/","text":"DAOS Troubleshooting DAOS Errors DAOS error numbering starts at 1000. The most common errors are documented in the table below. DAOS Error Value Description DER_NO_PERM 1001 No permission DER_NO_HDL 1002 Invalid handle DER_INVAL 1003 Invalid parameters DER_NOSPACE 1007 No space left on storage target DER_NOSYS 1010 Function not implemented DER_IO 2001 Generic I/O error DER_ENOENT 2003 Entry not found DER_KEY2BIG 2012 Key is too large DER_IO_INVAL 2014 IO buffers can't match object extents When an operation fails, DAOS returns a negative DER error. For a full list of errors, please check https://github.com/daos-stack/cart/blob/master/src/include/gurt/errno.h (DER_ERR_GURT_BASE is equal to 1000 and DER_ERR_DAOS_BASE is equal to 2000). The function d_errstr() is provided in the API to convert an error number to an error message. Debugging System DAOS uses the debug system defined in CaRT but more specifically the GURT library. Log files for both client and server are written to \"/tmp/daos.log\" unless otherwise set by D_LOG_FILE. Registered Subsystems/Facilities The debug logging system includes a series of subsystems or facilities which define groups for related log messages (defined per source file). There are common facilities which are defined in GURT, as well as other facilities that can be defined on a per-project basis (such as those for CaRT and DAOS). DD_SUBSYS can be used to set which subsystems to enable logging. By default all subsystems are enabled (\"DD_SUBSYS=all\"). DAOS Facilities: common, tree, vos, client, server, rdb, pool, container, object, placement, rebuild, tier, mgmt, bio, tests Common Facilities (GURT): MISC, MEM CaRT Facilities: RPC, BULK, CORPC, GRP, LM, HG, PMIX, ST, IV Priority Logging All macros that output logs have a priority level, shown in descending order below. D_FATAL(fmt, ...) FATAL D_CRIT(fmt, ...) CRIT D_ERROR(fmt, ...) ERR D_WARN(fmt, ...) WARN D_NOTE(fmt, ...) NOTE D_INFO(fmt, ...) INFO D_DEBUG(mask, fmt, ...) DEBUG The priority level that outputs to stderr is set with DD_STDERR. By default in DAOS (specific to the project), this is set to CRIT (\"DD_STDERR=CRIT\") meaning that all CRIT and more severe log messages will dump to stderr. However, this is separate from the priority of logging to \"/tmp/daos.log\". The priority level of logging can be set with D_LOG_MASK, which by default is set to INFO (\"D_LOG_MASK=INFO\"), which will result in all messages excluding DEBUG messages being logged. D_LOG_MASK can also be used to specify the level of logging on a per-subsystem basis as well (\"D_LOG_MASK=DEBUG,MEM=ERR\"). Debug Masks/Streams: DEBUG messages account for a majority of the log messages, and finer-granularity might be desired. Mask bits are set as the first argument passed in D_DEBUG(mask, ...). To accomplish this, DD_MASK can be set to enable different debug streams. Similar to facilities, there are common debug streams defined in GURT, as well as other streams that can be defined on a per-project basis (CaRT and DAOS). All debug streams are enabled by default (\"DD_MASK=all\"). DAOS Debug Masks: md = metadata operations pl = placement operations mgmt = pool management epc = epoch system df = durable format rebuild = rebuild process daos_default = (group mask) io, md, pl, and rebuild operations Common Debug Masks (GURT): any = generic messages, no classification trace = function trace, tree/hash/lru operations mem = memory operations net = network operations io = object I/Otest = test programs Common Use Cases Generic setup for all messages (default settings) $ D_LOG_MASK=DEBUG $ DD_SUBSYS=all $ DD_MASK=all Disable all logs for performance tuning $ D_LOG_MASK=ERR -> will only log error messages from all facilities $ D_LOG_MASK=FATAL -> will only log system fatal messages Disable a noisy debug logging subsystem $ D_LOG_MASK=DEBUG,MEM=ERR -> disables MEM facility by restricting all logs from that facility to ERROR or higher priority only Enable a subset of facilities of interest $ DD_SUBSYS=rpc,tests $ D_LOG_MASK=DEBUG -> required to see logs for RPC and TESTS less severe than INFO (the majority of log messages) Fine-tune the debug messages by setting a debug mask $ D_LOG_MASK=DEBUG $ DD_MASK=mgmt -> only logs DEBUG messages related to pool management Refer to the DAOS Environment Variables document for more information about the debug system environment. Common DAOS Problems This section to be updated in a future revision. Bug Report Bugs should be reported through our issue tracker ^1 with a test case to reproduce the issue (when applicable) and debug logs.","title":"Troubleshooting"},{"location":"admin/troubleshooting/#daos-troubleshooting","text":"","title":"DAOS Troubleshooting"},{"location":"admin/troubleshooting/#daos-errors","text":"DAOS error numbering starts at 1000. The most common errors are documented in the table below. DAOS Error Value Description DER_NO_PERM 1001 No permission DER_NO_HDL 1002 Invalid handle DER_INVAL 1003 Invalid parameters DER_NOSPACE 1007 No space left on storage target DER_NOSYS 1010 Function not implemented DER_IO 2001 Generic I/O error DER_ENOENT 2003 Entry not found DER_KEY2BIG 2012 Key is too large DER_IO_INVAL 2014 IO buffers can't match object extents When an operation fails, DAOS returns a negative DER error. For a full list of errors, please check https://github.com/daos-stack/cart/blob/master/src/include/gurt/errno.h (DER_ERR_GURT_BASE is equal to 1000 and DER_ERR_DAOS_BASE is equal to 2000). The function d_errstr() is provided in the API to convert an error number to an error message.","title":"DAOS Errors"},{"location":"admin/troubleshooting/#debugging-system","text":"DAOS uses the debug system defined in CaRT but more specifically the GURT library. Log files for both client and server are written to \"/tmp/daos.log\" unless otherwise set by D_LOG_FILE.","title":"Debugging System"},{"location":"admin/troubleshooting/#registered-subsystemsfacilities","text":"The debug logging system includes a series of subsystems or facilities which define groups for related log messages (defined per source file). There are common facilities which are defined in GURT, as well as other facilities that can be defined on a per-project basis (such as those for CaRT and DAOS). DD_SUBSYS can be used to set which subsystems to enable logging. By default all subsystems are enabled (\"DD_SUBSYS=all\"). DAOS Facilities: common, tree, vos, client, server, rdb, pool, container, object, placement, rebuild, tier, mgmt, bio, tests Common Facilities (GURT): MISC, MEM CaRT Facilities: RPC, BULK, CORPC, GRP, LM, HG, PMIX, ST, IV","title":"Registered Subsystems/Facilities"},{"location":"admin/troubleshooting/#priority-logging","text":"All macros that output logs have a priority level, shown in descending order below. D_FATAL(fmt, ...) FATAL D_CRIT(fmt, ...) CRIT D_ERROR(fmt, ...) ERR D_WARN(fmt, ...) WARN D_NOTE(fmt, ...) NOTE D_INFO(fmt, ...) INFO D_DEBUG(mask, fmt, ...) DEBUG The priority level that outputs to stderr is set with DD_STDERR. By default in DAOS (specific to the project), this is set to CRIT (\"DD_STDERR=CRIT\") meaning that all CRIT and more severe log messages will dump to stderr. However, this is separate from the priority of logging to \"/tmp/daos.log\". The priority level of logging can be set with D_LOG_MASK, which by default is set to INFO (\"D_LOG_MASK=INFO\"), which will result in all messages excluding DEBUG messages being logged. D_LOG_MASK can also be used to specify the level of logging on a per-subsystem basis as well (\"D_LOG_MASK=DEBUG,MEM=ERR\").","title":"Priority Logging"},{"location":"admin/troubleshooting/#debug-masksstreams","text":"DEBUG messages account for a majority of the log messages, and finer-granularity might be desired. Mask bits are set as the first argument passed in D_DEBUG(mask, ...). To accomplish this, DD_MASK can be set to enable different debug streams. Similar to facilities, there are common debug streams defined in GURT, as well as other streams that can be defined on a per-project basis (CaRT and DAOS). All debug streams are enabled by default (\"DD_MASK=all\"). DAOS Debug Masks: md = metadata operations pl = placement operations mgmt = pool management epc = epoch system df = durable format rebuild = rebuild process daos_default = (group mask) io, md, pl, and rebuild operations Common Debug Masks (GURT): any = generic messages, no classification trace = function trace, tree/hash/lru operations mem = memory operations net = network operations io = object I/Otest = test programs","title":"Debug Masks/Streams:"},{"location":"admin/troubleshooting/#common-use-cases","text":"Generic setup for all messages (default settings) $ D_LOG_MASK=DEBUG $ DD_SUBSYS=all $ DD_MASK=all Disable all logs for performance tuning $ D_LOG_MASK=ERR -> will only log error messages from all facilities $ D_LOG_MASK=FATAL -> will only log system fatal messages Disable a noisy debug logging subsystem $ D_LOG_MASK=DEBUG,MEM=ERR -> disables MEM facility by restricting all logs from that facility to ERROR or higher priority only Enable a subset of facilities of interest $ DD_SUBSYS=rpc,tests $ D_LOG_MASK=DEBUG -> required to see logs for RPC and TESTS less severe than INFO (the majority of log messages) Fine-tune the debug messages by setting a debug mask $ D_LOG_MASK=DEBUG $ DD_MASK=mgmt -> only logs DEBUG messages related to pool management Refer to the DAOS Environment Variables document for more information about the debug system environment.","title":"Common Use Cases"},{"location":"admin/troubleshooting/#common-daos-problems","text":"This section to be updated in a future revision.","title":"Common DAOS Problems"},{"location":"admin/troubleshooting/#bug-report","text":"Bugs should be reported through our issue tracker ^1 with a test case to reproduce the issue (when applicable) and debug logs.","title":"Bug Report"},{"location":"admin/utilities_examples/","text":"DAOS Utilities & Usage Examples This section to be updated in a future revision.","title":"Utilities and Usage Examples"},{"location":"admin/utilities_examples/#daos-utilities-usage-examples","text":"This section to be updated in a future revision.","title":"DAOS Utilities &amp; Usage Examples"},{"location":"overview/fault/","text":"Fault Model DAOS relies on massively distributed single-ported storage. Each target is thus effectively a single point of failure. DAOS achieves availability and durability of both data and metadata by providing redundancy across targets in different fault domains. DAOS internal pool and container metadata are replicated via a robust consensus algorithm. DAOS objects are then safely replicated or erasure-coded by transparently leveraging the DAOS distributed transaction mechanisms internally. The purpose of this section is to provide details on how DAOS achieves fault tolerance and guarantees object resilience. Hierarchical Fault Domains A fault domain is a set of servers sharing the same point of failure and which are thus likely to fail altogether. DAOS assumes that fault domains are hierarchical and do not overlap. The actual hierarchy and fault domain membership must be supplied by an external database used by DAOS to generate the pool map. Pool metadata are replicated on several nodes from different high-level fault domains for high availability, whereas object data is replicated or erasure-coded over a variable number of fault domains depending on the selected object class. Fault Detection DAOS servers are monitored within a DAOS system through a gossip-based protocol called SWIM that provides accurate, efficient, and scalable server fault detection. Storage attached to each DAOS target is monitored through periodic local health assessment. Whenever a local storage I/O error is returned to the DAOS server, an internal health check procedure will be called automatically. This procedure will make an overall health assessment by analyzing the IO error code and device SMART/Health data. If the result is negative, the target will be marked as faulty, and further I/Os to this target will be rejected and re-routed. Fault Isolation Once detected, the faulty target or servers (effectivelly a set of targets) must be excluded from the pool map. This process is triggered either manually by the administrator or automatically. Upon exclusion, the new version of the pool map is eagerly pushed to all storage targets. At this point, the pool enters a degraded mode that might require extra processing on access (e.g. reconstructing data out of erasure code). Consequently, DAOS client and storage nodes retry RPC indefinitely until they find an alternative replacement target from the new pool map. At this point, all outstanding communications with the evicted target are aborted, and no further messages should be sent to the target until it is explicitly reintegrated (possibly only after maintenance action). All storage targets are promptly notified of pool map changes by the pool service. This is not the case for client nodes, which are lazily informed of pool map invalidation each time they communicate with servers. To do so, clients pack in every RPC their current pool map version. Servers reply not only with the current pool map version. Consequently, when a DAOS client experiences RPC timeout, it regularly communicates with the other DAOS target to guarantee that its pool map is always current. Clients will then eventually be informed of the target exclusion and enter into degraded mode. This mechanism guarantees global node eviction and that all nodes eventually share the same view of target aliveness. Fault Recovery Upon exclusion from the pool map, each target starts the rebuild process automatically to restore data redundancy. First, each target creates a list of local objects impacted by the target exclusion. This is done by scanning a local object table maintained by the underlying storage layer. Then for each impacted object, the location of the new object shard is determined and redundancy of the object restored for the whole history (i.e., snapshots). Once all impacted objects have been rebuilt, the pool map is updated a second time to report the target as failed out. This marks the end of collective rebuild process and the exit from degraded mode for this particular fault. At this point, the pool has fully recovered from the fault and client nodes can now read from the rebuilt object shards. This rebuild process is executed online while applications continue accessing and updating objects.","title":"Fault Model"},{"location":"overview/fault/#fault-model","text":"DAOS relies on massively distributed single-ported storage. Each target is thus effectively a single point of failure. DAOS achieves availability and durability of both data and metadata by providing redundancy across targets in different fault domains. DAOS internal pool and container metadata are replicated via a robust consensus algorithm. DAOS objects are then safely replicated or erasure-coded by transparently leveraging the DAOS distributed transaction mechanisms internally. The purpose of this section is to provide details on how DAOS achieves fault tolerance and guarantees object resilience.","title":"Fault Model"},{"location":"overview/fault/#hierarchical-fault-domains","text":"A fault domain is a set of servers sharing the same point of failure and which are thus likely to fail altogether. DAOS assumes that fault domains are hierarchical and do not overlap. The actual hierarchy and fault domain membership must be supplied by an external database used by DAOS to generate the pool map. Pool metadata are replicated on several nodes from different high-level fault domains for high availability, whereas object data is replicated or erasure-coded over a variable number of fault domains depending on the selected object class.","title":"Hierarchical Fault Domains"},{"location":"overview/fault/#fault-detection","text":"DAOS servers are monitored within a DAOS system through a gossip-based protocol called SWIM that provides accurate, efficient, and scalable server fault detection. Storage attached to each DAOS target is monitored through periodic local health assessment. Whenever a local storage I/O error is returned to the DAOS server, an internal health check procedure will be called automatically. This procedure will make an overall health assessment by analyzing the IO error code and device SMART/Health data. If the result is negative, the target will be marked as faulty, and further I/Os to this target will be rejected and re-routed.","title":"Fault Detection"},{"location":"overview/fault/#fault-isolation","text":"Once detected, the faulty target or servers (effectivelly a set of targets) must be excluded from the pool map. This process is triggered either manually by the administrator or automatically. Upon exclusion, the new version of the pool map is eagerly pushed to all storage targets. At this point, the pool enters a degraded mode that might require extra processing on access (e.g. reconstructing data out of erasure code). Consequently, DAOS client and storage nodes retry RPC indefinitely until they find an alternative replacement target from the new pool map. At this point, all outstanding communications with the evicted target are aborted, and no further messages should be sent to the target until it is explicitly reintegrated (possibly only after maintenance action). All storage targets are promptly notified of pool map changes by the pool service. This is not the case for client nodes, which are lazily informed of pool map invalidation each time they communicate with servers. To do so, clients pack in every RPC their current pool map version. Servers reply not only with the current pool map version. Consequently, when a DAOS client experiences RPC timeout, it regularly communicates with the other DAOS target to guarantee that its pool map is always current. Clients will then eventually be informed of the target exclusion and enter into degraded mode. This mechanism guarantees global node eviction and that all nodes eventually share the same view of target aliveness.","title":"Fault Isolation"},{"location":"overview/fault/#fault-recovery","text":"Upon exclusion from the pool map, each target starts the rebuild process automatically to restore data redundancy. First, each target creates a list of local objects impacted by the target exclusion. This is done by scanning a local object table maintained by the underlying storage layer. Then for each impacted object, the location of the new object shard is determined and redundancy of the object restored for the whole history (i.e., snapshots). Once all impacted objects have been rebuilt, the pool map is updated a second time to report the target as failed out. This marks the end of collective rebuild process and the exit from degraded mode for this particular fault. At this point, the pool has fully recovered from the fault and client nodes can now read from the rebuilt object shards. This rebuild process is executed online while applications continue accessing and updating objects.","title":"Fault Recovery"},{"location":"overview/security/","text":"Security Model DAOS uses a flexible security model that seperates authentication from authorization. It is designed to have very minimal impact on the I/O path. Authentication The DAOS security model is designed to support different authentication methods. By default, a local agent runs on the client node and authenticats the user process through AUTH_SYS. Authentication can be handle by a third party service like munge or Kerberos. Authorization DAOS supports a subset of the NFSv4 ACLs for both pools and containers through the properties API.","title":"Security Model"},{"location":"overview/security/#security-model","text":"DAOS uses a flexible security model that seperates authentication from authorization. It is designed to have very minimal impact on the I/O path.","title":"Security Model"},{"location":"overview/security/#authentication","text":"The DAOS security model is designed to support different authentication methods. By default, a local agent runs on the client node and authenticats the user process through AUTH_SYS. Authentication can be handle by a third party service like munge or Kerberos.","title":"Authentication"},{"location":"overview/security/#authorization","text":"DAOS supports a subset of the NFSv4 ACLs for both pools and containers through the properties API.","title":"Authorization"},{"location":"overview/storage/","text":"Storage Model We consider a data center with hundreds of thousands of compute nodes interconnected via a scalable high-performance fabric (i.e., Ethernet, RoCE or Infiniband), where all or a subset of the nodes, called storage nodes, have direct access to byte-addressable storage-class memory (SCM) and, optionally, block-based NVMe storage. The DAOS server is a multi-tenant daemon running on a Linux instance (i.e., natively on the physical node or in a VM or container) of each storage node and exporting through the network the locally-attached storage. Inside a DAOS server, the storage is statically partitioned across multiple targets to optimize concurrency. To avoid contention, each target has its private storage, own pool of service threads and dedicated network context that can be directly addressed over the fabric independently of the other targets hosted on the same storage node. The number of targets exported by a DAOS server instance is configurable and depends on the underlying hardware (i.e., number of SCM modules, CPUs, NVMe SSDs, ...). A target is the unit of fault. All DAOS servers connected to the same fabric are grouped to form a DAOS system, identified by a system name. Membership of the DAOS servers is recorded into the system map that assigns a unique integer rank to each server. Two different systems comprise two disjoint sets of servers and do not coordinate with each other. The figure below represents the fundamental abstractions of the DAOS storage model. A DAOS pool is a storage reservation distributed across a collection of targets. The actual space allocated to the pool on each target is called a pool shard. The total space allocated to a pool is decided at creation time and can be expanded over time by resizing all the pool shards (within the limit of the storage capacity dedicated to each target) or by spanning more targets (i.e., adding more pool shards). A pool offers storage virtualization and is the unit of provisioning and isolation. DAOS pools cannot span across multiple systems. A pool can host multiple transactional object store called DAOS containers. Each container is a private object address space, which can be modified transactionally and independently of the other containers stored in the same pool. A container is the unit of snapshot and data management. DAOS objects belonging to a container can be distributed across any target of the pool for both performance and resilience and can be accessed through different APIs to represent structured, semi-structured and unstructured data efficiently The table below shows the targeted level of scalability for each DAOS concept. DAOS Concept Order of Magnitude System 10 5 Servers (hundreds of thousands) and 10 2 Pools (hundreds) Server 10 1 Targets (tens) Pool 10 2 Containers (hundreds) Container 10 9 Objects (billions) DAOS Target A target is typically associated with a single-ported SCM module and NVMe SSD attached to a single storage node. Moreover, a target does not implement any internal data protection mechanism against storage media failure. As a result, a target is a single point of failure. A dynamic state is associated with each target and is set to either up and running, or down and not available. A target is the unit of performance. Hardware components associated with the target, such as the backend storage medium, the server, and the network, have limited capability and capacity. Target performance parameters such as bandwidth and latency are exported to the upper layers. DAOS Pool A pool is identified by a unique UUID and maintains target memberships in a persistent versioned list called the pool map. The membership is definitive and consistent, and membership changes are sequentially numbered. The pool map not only records the list of active targets, it also contains the storage topology under the form of a tree that is used to identify targets sharing common hardware components. For instance, the first level of the tree can represent targets sharing the same motherboard, and then the second level can represent all motherboards sharing the same rack and finally the third level can represent all racks in the same cage. This framework effectively represents hierarchical fault domains, which are then used to avoid placing redundant data on targets subject to correlated failures. At any point in time, new targets can be added to the pool map, and failed ones can be excluded. Moreover, the pool map is fully versioned, which effectively assigns a unique sequence to each modification of the map, more particularly for failed node removal. A pool shard is a reservation of persistent memory optionally combined with a pre-allocated space on NVMe storage on a specific target. It has a fixed capacity and fails operations when full. Current space usage can be queried at any time and reports the total amount of bytes used by any data type stored in the pool shard. Upon target failure and exclusion from the pool map, data redundancy inside the pool is automatically restored online. This self-healing process is known as rebuild. Rebuild progress is recorded regularly in special logs in the pool stored in persistent memory to address cascading failures. When new targets are added, data is automatically migrated to the newly added targets to redistribute space usage equally among all the members. This process is known as space rebalancing and uses dedicated persistent logs as well to support interruption and restart. A pool is a set of targets spread across different storage nodes over which data and metadata are distributed to achieve horizontal scalability, and replicated or erasure-coded to ensure durability and availability. When creating a pool, a set of system properties must be defined to configure the different features supported by the pool. Also, user can define their attributes that will be stored persistently. A pool is only accessible to authenticated and authorized applications. Multiple security frameworks could be supported, from NFSv4 access control lists to third party-based authentication (such as Kerberos). Security is enforced when connecting to the pool. Upon successful connection to the pool, a connection context is returned to the application process. As detailed previously, a pool stores many different sorts of persistent metadata, such as the pool map, authentication, and authorization information, user attributes, properties and rebuild logs. Such metadata are critical and require the highest level of resiliency. Therefore, the pool metadata are replicated on a few nodes from distinct high-level fault domains. For very large configurations with hundreds of thousands of storage nodes, only a very small fraction of those nodes (in the order of tens) run the pool metadata service. With a limited number of storage nodes, DAOS can afford to rely on a consensus algorithm to reach agreement and to guarantee consistency in the presence of faults and to avoid split-brain syndrome. To access a pool, a user process should connect to this pool and pass the security checks. Once granted, a pool connection can be shared (via local2global() and global2local() operations) with any or all of its peer application processes (similar to the openg() POSIX extension). This collective connect mechanism allows avoiding metadata request storm when a massively distributed job is run on the datacenter. A pool connection is then revoked when the original process that issued the connection request disconnects from the pool. DAOS Container A container represents an object address space inside a pool and is identified by a UUID. The diagram below represents how the user (i.e., I/O middleware, domain-specific data format, big data or AI frameworks ...) could use the container concept to store related datasets. Like pools, containers can store user attributes, and a set of properties must be passed at container creation time to configure different features like checksums. To access a container, an application must first connect to the pool and then open the container. If the application is authorized to access the container, a container handle is returned. This includes capabilities that authorize any process in the application to access the container and its contents. The opening process may share this handle with any or all of its peers. Their capabilities are revoked either on container close. Objects in a container may have different schemas for data distribution and redundancy over targets. Dynamic or static striping, replication, or erasure code are some parameters required to define the object schema. The object class defines common schema attributes for a set of objects. Each object class is assigned a unique identifier and is associated with a given schema at the pool level. A new object class can be defined at any time with a configurable schema, which is then immutable after creation, or at least until all objects belonging to the class have been destroyed. For convenience, several object classes expected to be the most commonly used will be predefined by default when the pool is created, as shown the table below table below. Sample of Pre-defined Object Classes Object Class (RW = read/write, RM = read-mostly Redundancy Layout (SC = stripe count, RC = replica count, PC = parity count, TGT = target Small size & RW Replication static SCxRC, e.g. 1x4 Small size & RM Erasure code static SC+PC, e.g. 4+2 Large size & RW Replication static SCxRC over max #targets) Large size & RM Erasure code static SCx(SC+PC) w/ max #TGT) Unknown size & RW Replication SCxRC, e.g. 1x4 initially and grows Unknown size & RM Erasure code SC+PC, e.g. 4+2 initially and grows As shown below, each object is identified in the container by a unique 128-bit object address. The high 32 bits of the object address is reserved for DAOS to encode internal metadata such as the object class. The remaining 96 bits are managed by the user and should be unique inside the container. Those bits can be used by upper layers of the stack to encode their metadata as long as unicity is guaranteed. A per-container 64-bit scalable object ID allocator is provided in the DAOS API. The object ID to be stored by the application is the full 128-bit address which is for single use only and can be associated with only a single object schema. DAOS Object ID Structure <---------------------------------- 128 bits ----------------------------------> -------------------------------------------------------------------------------- |DAOS Internal Bits| Unique User Bits | -------------------------------------------------------------------------------- <---- 32 bits ----><------------------------- 96 bits -------------------------> A container is the basic unit of transaction and versioning. All object operations are implicitly tagged by the DAOS library with a timestamp called an epoch. The DAOS transaction API allows combining multiple object updates into a single atomic transaction with multi-version concurrency control based on epoch ordering. All the versioned updates may periodically be aggregated to reclaim space utilized by overlapping writes and to reduce metadata complexity. A snapshot is a permanent reference that can be placed on a specific epoch to prevent aggregation. Container metadata (i.e., list of snapshots, container open handles, object class, user attributes, properties, and others) are stored in persistent memory and maintained by a dedicated container metadata service that either uses the same replicated engine as the parent metadata pool service or has its own engine. This is configurable when creating a container. Like a pool, access to a container is controlled by the container handle. To acquire a valid handle, an application process must open the container and pass the security checks. This container handle may then be shared with other peer application processes via the container local2global() and global2local() operations. DAOS Object To avoid scaling problems and overhead common to a traditional storage system, DAOS objects are intentionally simple. No default object metadata beyond the type and schema are provided. This means that the system does not maintain time, size, owner, permissions or even track openers. To achieve high availability and horizontal scalability, many object schemas (replication/erasure code, static/dynamic striping, and others) are provided. The schema framework is flexible and easily expandable to allow for new custom schema types in the future. The layout is generated algorithmically on object open from the object identifier and the pool map. End-to-end integrity is assured by protecting object data with checksums during network transfer and storage. A DAOS object can be accessed through different APIs: Multi-level key-array API is the native object interface with locality feature. The key is split into a distribution (i.e., dkey) and an attribute (i.e., akey) key. Both the dkey and akey can be of variable length and type (i.e. a string, an integer or even a complex data structure). All entries under the same dkey are guaranteed to be collocated on the same target. The value associated with akey can be either a single variable-length value that cannot be partially overwritten or an array of fixed-length values. Both the akeys and dkeys support enumeration. Key-value API provides a simple key and variable-length value interface. It supports the traditional put, get, remove and list operations. Array API implements a one-dimensional array of fixed-size elements addressed by a 64-bit offset. A DAOS array supports arbitrary extent read, write and punch operations.","title":"Storage Model"},{"location":"overview/storage/#storage-model","text":"We consider a data center with hundreds of thousands of compute nodes interconnected via a scalable high-performance fabric (i.e., Ethernet, RoCE or Infiniband), where all or a subset of the nodes, called storage nodes, have direct access to byte-addressable storage-class memory (SCM) and, optionally, block-based NVMe storage. The DAOS server is a multi-tenant daemon running on a Linux instance (i.e., natively on the physical node or in a VM or container) of each storage node and exporting through the network the locally-attached storage. Inside a DAOS server, the storage is statically partitioned across multiple targets to optimize concurrency. To avoid contention, each target has its private storage, own pool of service threads and dedicated network context that can be directly addressed over the fabric independently of the other targets hosted on the same storage node. The number of targets exported by a DAOS server instance is configurable and depends on the underlying hardware (i.e., number of SCM modules, CPUs, NVMe SSDs, ...). A target is the unit of fault. All DAOS servers connected to the same fabric are grouped to form a DAOS system, identified by a system name. Membership of the DAOS servers is recorded into the system map that assigns a unique integer rank to each server. Two different systems comprise two disjoint sets of servers and do not coordinate with each other. The figure below represents the fundamental abstractions of the DAOS storage model. A DAOS pool is a storage reservation distributed across a collection of targets. The actual space allocated to the pool on each target is called a pool shard. The total space allocated to a pool is decided at creation time and can be expanded over time by resizing all the pool shards (within the limit of the storage capacity dedicated to each target) or by spanning more targets (i.e., adding more pool shards). A pool offers storage virtualization and is the unit of provisioning and isolation. DAOS pools cannot span across multiple systems. A pool can host multiple transactional object store called DAOS containers. Each container is a private object address space, which can be modified transactionally and independently of the other containers stored in the same pool. A container is the unit of snapshot and data management. DAOS objects belonging to a container can be distributed across any target of the pool for both performance and resilience and can be accessed through different APIs to represent structured, semi-structured and unstructured data efficiently The table below shows the targeted level of scalability for each DAOS concept. DAOS Concept Order of Magnitude System 10 5 Servers (hundreds of thousands) and 10 2 Pools (hundreds) Server 10 1 Targets (tens) Pool 10 2 Containers (hundreds) Container 10 9 Objects (billions)","title":"Storage Model"},{"location":"overview/storage/#daos-target","text":"A target is typically associated with a single-ported SCM module and NVMe SSD attached to a single storage node. Moreover, a target does not implement any internal data protection mechanism against storage media failure. As a result, a target is a single point of failure. A dynamic state is associated with each target and is set to either up and running, or down and not available. A target is the unit of performance. Hardware components associated with the target, such as the backend storage medium, the server, and the network, have limited capability and capacity. Target performance parameters such as bandwidth and latency are exported to the upper layers.","title":"DAOS Target"},{"location":"overview/storage/#daos-pool","text":"A pool is identified by a unique UUID and maintains target memberships in a persistent versioned list called the pool map. The membership is definitive and consistent, and membership changes are sequentially numbered. The pool map not only records the list of active targets, it also contains the storage topology under the form of a tree that is used to identify targets sharing common hardware components. For instance, the first level of the tree can represent targets sharing the same motherboard, and then the second level can represent all motherboards sharing the same rack and finally the third level can represent all racks in the same cage. This framework effectively represents hierarchical fault domains, which are then used to avoid placing redundant data on targets subject to correlated failures. At any point in time, new targets can be added to the pool map, and failed ones can be excluded. Moreover, the pool map is fully versioned, which effectively assigns a unique sequence to each modification of the map, more particularly for failed node removal. A pool shard is a reservation of persistent memory optionally combined with a pre-allocated space on NVMe storage on a specific target. It has a fixed capacity and fails operations when full. Current space usage can be queried at any time and reports the total amount of bytes used by any data type stored in the pool shard. Upon target failure and exclusion from the pool map, data redundancy inside the pool is automatically restored online. This self-healing process is known as rebuild. Rebuild progress is recorded regularly in special logs in the pool stored in persistent memory to address cascading failures. When new targets are added, data is automatically migrated to the newly added targets to redistribute space usage equally among all the members. This process is known as space rebalancing and uses dedicated persistent logs as well to support interruption and restart. A pool is a set of targets spread across different storage nodes over which data and metadata are distributed to achieve horizontal scalability, and replicated or erasure-coded to ensure durability and availability. When creating a pool, a set of system properties must be defined to configure the different features supported by the pool. Also, user can define their attributes that will be stored persistently. A pool is only accessible to authenticated and authorized applications. Multiple security frameworks could be supported, from NFSv4 access control lists to third party-based authentication (such as Kerberos). Security is enforced when connecting to the pool. Upon successful connection to the pool, a connection context is returned to the application process. As detailed previously, a pool stores many different sorts of persistent metadata, such as the pool map, authentication, and authorization information, user attributes, properties and rebuild logs. Such metadata are critical and require the highest level of resiliency. Therefore, the pool metadata are replicated on a few nodes from distinct high-level fault domains. For very large configurations with hundreds of thousands of storage nodes, only a very small fraction of those nodes (in the order of tens) run the pool metadata service. With a limited number of storage nodes, DAOS can afford to rely on a consensus algorithm to reach agreement and to guarantee consistency in the presence of faults and to avoid split-brain syndrome. To access a pool, a user process should connect to this pool and pass the security checks. Once granted, a pool connection can be shared (via local2global() and global2local() operations) with any or all of its peer application processes (similar to the openg() POSIX extension). This collective connect mechanism allows avoiding metadata request storm when a massively distributed job is run on the datacenter. A pool connection is then revoked when the original process that issued the connection request disconnects from the pool.","title":"DAOS Pool"},{"location":"overview/storage/#daos-container","text":"A container represents an object address space inside a pool and is identified by a UUID. The diagram below represents how the user (i.e., I/O middleware, domain-specific data format, big data or AI frameworks ...) could use the container concept to store related datasets. Like pools, containers can store user attributes, and a set of properties must be passed at container creation time to configure different features like checksums. To access a container, an application must first connect to the pool and then open the container. If the application is authorized to access the container, a container handle is returned. This includes capabilities that authorize any process in the application to access the container and its contents. The opening process may share this handle with any or all of its peers. Their capabilities are revoked either on container close. Objects in a container may have different schemas for data distribution and redundancy over targets. Dynamic or static striping, replication, or erasure code are some parameters required to define the object schema. The object class defines common schema attributes for a set of objects. Each object class is assigned a unique identifier and is associated with a given schema at the pool level. A new object class can be defined at any time with a configurable schema, which is then immutable after creation, or at least until all objects belonging to the class have been destroyed. For convenience, several object classes expected to be the most commonly used will be predefined by default when the pool is created, as shown the table below table below. Sample of Pre-defined Object Classes Object Class (RW = read/write, RM = read-mostly Redundancy Layout (SC = stripe count, RC = replica count, PC = parity count, TGT = target Small size & RW Replication static SCxRC, e.g. 1x4 Small size & RM Erasure code static SC+PC, e.g. 4+2 Large size & RW Replication static SCxRC over max #targets) Large size & RM Erasure code static SCx(SC+PC) w/ max #TGT) Unknown size & RW Replication SCxRC, e.g. 1x4 initially and grows Unknown size & RM Erasure code SC+PC, e.g. 4+2 initially and grows As shown below, each object is identified in the container by a unique 128-bit object address. The high 32 bits of the object address is reserved for DAOS to encode internal metadata such as the object class. The remaining 96 bits are managed by the user and should be unique inside the container. Those bits can be used by upper layers of the stack to encode their metadata as long as unicity is guaranteed. A per-container 64-bit scalable object ID allocator is provided in the DAOS API. The object ID to be stored by the application is the full 128-bit address which is for single use only and can be associated with only a single object schema. DAOS Object ID Structure <---------------------------------- 128 bits ----------------------------------> -------------------------------------------------------------------------------- |DAOS Internal Bits| Unique User Bits | -------------------------------------------------------------------------------- <---- 32 bits ----><------------------------- 96 bits -------------------------> A container is the basic unit of transaction and versioning. All object operations are implicitly tagged by the DAOS library with a timestamp called an epoch. The DAOS transaction API allows combining multiple object updates into a single atomic transaction with multi-version concurrency control based on epoch ordering. All the versioned updates may periodically be aggregated to reclaim space utilized by overlapping writes and to reduce metadata complexity. A snapshot is a permanent reference that can be placed on a specific epoch to prevent aggregation. Container metadata (i.e., list of snapshots, container open handles, object class, user attributes, properties, and others) are stored in persistent memory and maintained by a dedicated container metadata service that either uses the same replicated engine as the parent metadata pool service or has its own engine. This is configurable when creating a container. Like a pool, access to a container is controlled by the container handle. To acquire a valid handle, an application process must open the container and pass the security checks. This container handle may then be shared with other peer application processes via the container local2global() and global2local() operations.","title":"DAOS Container"},{"location":"overview/storage/#daos-object","text":"To avoid scaling problems and overhead common to a traditional storage system, DAOS objects are intentionally simple. No default object metadata beyond the type and schema are provided. This means that the system does not maintain time, size, owner, permissions or even track openers. To achieve high availability and horizontal scalability, many object schemas (replication/erasure code, static/dynamic striping, and others) are provided. The schema framework is flexible and easily expandable to allow for new custom schema types in the future. The layout is generated algorithmically on object open from the object identifier and the pool map. End-to-end integrity is assured by protecting object data with checksums during network transfer and storage. A DAOS object can be accessed through different APIs: Multi-level key-array API is the native object interface with locality feature. The key is split into a distribution (i.e., dkey) and an attribute (i.e., akey) key. Both the dkey and akey can be of variable length and type (i.e. a string, an integer or even a complex data structure). All entries under the same dkey are guaranteed to be collocated on the same target. The value associated with akey can be either a single variable-length value that cannot be partially overwritten or an array of fixed-length values. Both the akeys and dkeys support enumeration. Key-value API provides a simple key and variable-length value interface. It supports the traditional put, get, remove and list operations. Array API implements a one-dimensional array of fixed-size elements addressed by a 64-bit offset. A DAOS array supports arbitrary extent read, write and punch operations.","title":"DAOS Object"},{"location":"overview/terminology/","text":"Terminology Acronym Expansion ABT Argobots ACLs Access Control Lists BIO Blob I/O CART Collective and RPC Transport CGO Go tools that enable creation of Go packages that call C code CN Compute Node COTS Commercial off-the-shelf CPU Central Processing Unit Daemon A process offering system-level resources. DAOS Distributed Asynchronous Object Storage DCPM Intel Optane DC Persistent Memory DPDK Data Plane Development Kit dRPC DAOS Remote Procedure Call gRPC gRPC Remote Procedure Calls GURT Gurt Useful Routines and Types HLC Hybrid Logical Clock HLD High-level Design ISA-L Intel Storage Acceleration Library I/O Input/Output KV store Key-Value store libfabric A user-space library that exports the Open Fabrics Interface Mercury A user-space RPC library that can use libfabrics as a transport MTBF Mean Time Between Failures OFI Open Fabrics Interface NVM Non-Volatile Memory NVMe Non-Volatile Memory express OFI OpenFabrics Interfaces OS Operating System PM/PMEM Persistent Memory PMDK Persistent Memory Devevelopment Kit PMIx Process Management Interface for Exascale RAFT Raft is a consensus algorithm used to distribute state transitions among DAOS server nodes. RAS Reliability, Availability & Serviceability RDB Replicated Database, containing pool metadata and maintained across DAOS servers using the Raft algorithm. RDMA/RMA Remote (Direct) Memory Access RPC Remote Procedure Call SCM Storage-Class Memory SWIM Scalable Weakly-consistent Infection-style process group Membership SPDK Storage Performance Development Kit SSD Solid State Drive SWIM Scalable Weakly-consistent Infection-style process group Membership protocol ULT User Level Thread UPI Intel Ultra Path Interconnect URT A common library of Gurt Useful Routines and Types provided with CaRT. UUID Universal Unique Identifier RDG Redundancy Group VOS Versioning Object Store","title":"Terminology"},{"location":"overview/terminology/#terminology","text":"Acronym Expansion ABT Argobots ACLs Access Control Lists BIO Blob I/O CART Collective and RPC Transport CGO Go tools that enable creation of Go packages that call C code CN Compute Node COTS Commercial off-the-shelf CPU Central Processing Unit Daemon A process offering system-level resources. DAOS Distributed Asynchronous Object Storage DCPM Intel Optane DC Persistent Memory DPDK Data Plane Development Kit dRPC DAOS Remote Procedure Call gRPC gRPC Remote Procedure Calls GURT Gurt Useful Routines and Types HLC Hybrid Logical Clock HLD High-level Design ISA-L Intel Storage Acceleration Library I/O Input/Output KV store Key-Value store libfabric A user-space library that exports the Open Fabrics Interface Mercury A user-space RPC library that can use libfabrics as a transport MTBF Mean Time Between Failures OFI Open Fabrics Interface NVM Non-Volatile Memory NVMe Non-Volatile Memory express OFI OpenFabrics Interfaces OS Operating System PM/PMEM Persistent Memory PMDK Persistent Memory Devevelopment Kit PMIx Process Management Interface for Exascale RAFT Raft is a consensus algorithm used to distribute state transitions among DAOS server nodes. RAS Reliability, Availability & Serviceability RDB Replicated Database, containing pool metadata and maintained across DAOS servers using the Raft algorithm. RDMA/RMA Remote (Direct) Memory Access RPC Remote Procedure Call SCM Storage-Class Memory SWIM Scalable Weakly-consistent Infection-style process group Membership SPDK Storage Performance Development Kit SSD Solid State Drive SWIM Scalable Weakly-consistent Infection-style process group Membership protocol ULT User Level Thread UPI Intel Ultra Path Interconnect URT A common library of Gurt Useful Routines and Types provided with CaRT. UUID Universal Unique Identifier RDG Redundancy Group VOS Versioning Object Store","title":"Terminology"},{"location":"overview/transaction/","text":"Transaction Model The DAOS API supports distributed transactions that allow any update operations against objects belonging to the same container to be combined into a single ACID transaction. Distributed consistency is provided via a lockless optimistic concurrency control mechanism based on multi-version timestamp ordering. DAOS transactions are serializable and can be used on an ad-hoc basis for parts of the datasets that need it. The DAOS versioning mechanism allows creating persistent container snapshots which provide point-in-time distributed consistent views of a container which can be used to build producer-consumer pipeline. Epoch & Timestamp Ordering Each DAOS I/O operation is tagged with a timestamp called epoch. An epoch is a 64-bit integer that integrates both logical and physical clocks (see HLC paper ). The DAOS API provides helper functions to convert an epoch to traditional POSIX time (i.e., struct timespec, see clock_gettime(3)). Container Snapshot As shown in the figure below, the content of a container can be snapshot at any time. DAOS snapshots are very lightweight and are tagged with the epoch associated with the time when the snapshot was created. Once successfully created, a snapshot remains readable until it is explicitly destroyed. The content of a container can be rolled back to a particular snapshot. The container snapshot feature allows supporting native producer/consumer pipeline as represented in the diagram below. The producer will generate a snapshot once a consistent version of the dataset has been successfully written. The consumer applications may subscribe to container snapshot events so that new updates can be processed as the producer commits them. The immutability of the snapshots guarantees that the consumer sees consistent data, even while the producer continues with new updates. Both the producer and consumer indeed operate on different versions of the container and do not need any serialization. Once the producer generates a new version of the dataset, the consumer may query the differences between the two snapshots and process only the incremental changes. Distributed Transactions Unlike POSIX, the DAOS API does not impose any worst-case concurrency control mechanism to address conflicting I/O operations. Instead, individual I/O operations are tagged with a different epoch and applied in epoch order, regardless of execution order. This baseline model delivers the maximum scalability and performance to data models and applications that do not generate conflicting I/O workload. Typical examples are collective MPI-IO operations, POSIX file read/write or HDF5 dataset read/write. For parts of the data model that require conflict serialization, DAOS provides distributed serializable transaction based on multi-version concurrency control. Transactions are typically needed when different user process can overwrite the value associated with a dkey/akey pair. Examples are a SQL database over DAOS or a consistent POSIX namespace accessed concurrently by uncoordinated clients. All I/O operations (include reads) submitted in the context of the same operation will use the same epoch. The DAOS transaction mechanism automatically detects the traditional read/write, write/read and write/write conflicts and aborts one of the conflicting transactions that have to be restarted by the user (i.e., transaction fails to commit with -DER_RESTART). In the initial implementation, the transaction API has the following limitations that will be addressed in future DAOS versions: no support for the array API transactional object update and key-value put operations are not visible via object fetch/list and key-value get/list operations executed in the context of the same transaction.","title":"Transaction Model"},{"location":"overview/transaction/#transaction-model","text":"The DAOS API supports distributed transactions that allow any update operations against objects belonging to the same container to be combined into a single ACID transaction. Distributed consistency is provided via a lockless optimistic concurrency control mechanism based on multi-version timestamp ordering. DAOS transactions are serializable and can be used on an ad-hoc basis for parts of the datasets that need it. The DAOS versioning mechanism allows creating persistent container snapshots which provide point-in-time distributed consistent views of a container which can be used to build producer-consumer pipeline.","title":"Transaction Model"},{"location":"overview/transaction/#epoch-timestamp-ordering","text":"Each DAOS I/O operation is tagged with a timestamp called epoch. An epoch is a 64-bit integer that integrates both logical and physical clocks (see HLC paper ). The DAOS API provides helper functions to convert an epoch to traditional POSIX time (i.e., struct timespec, see clock_gettime(3)).","title":"Epoch &amp; Timestamp Ordering"},{"location":"overview/transaction/#container-snapshot","text":"As shown in the figure below, the content of a container can be snapshot at any time. DAOS snapshots are very lightweight and are tagged with the epoch associated with the time when the snapshot was created. Once successfully created, a snapshot remains readable until it is explicitly destroyed. The content of a container can be rolled back to a particular snapshot. The container snapshot feature allows supporting native producer/consumer pipeline as represented in the diagram below. The producer will generate a snapshot once a consistent version of the dataset has been successfully written. The consumer applications may subscribe to container snapshot events so that new updates can be processed as the producer commits them. The immutability of the snapshots guarantees that the consumer sees consistent data, even while the producer continues with new updates. Both the producer and consumer indeed operate on different versions of the container and do not need any serialization. Once the producer generates a new version of the dataset, the consumer may query the differences between the two snapshots and process only the incremental changes.","title":"Container Snapshot"},{"location":"overview/transaction/#distributed-transactions","text":"Unlike POSIX, the DAOS API does not impose any worst-case concurrency control mechanism to address conflicting I/O operations. Instead, individual I/O operations are tagged with a different epoch and applied in epoch order, regardless of execution order. This baseline model delivers the maximum scalability and performance to data models and applications that do not generate conflicting I/O workload. Typical examples are collective MPI-IO operations, POSIX file read/write or HDF5 dataset read/write. For parts of the data model that require conflict serialization, DAOS provides distributed serializable transaction based on multi-version concurrency control. Transactions are typically needed when different user process can overwrite the value associated with a dkey/akey pair. Examples are a SQL database over DAOS or a consistent POSIX namespace accessed concurrently by uncoordinated clients. All I/O operations (include reads) submitted in the context of the same operation will use the same epoch. The DAOS transaction mechanism automatically detects the traditional read/write, write/read and write/write conflicts and aborts one of the conflicting transactions that have to be restarted by the user (i.e., transaction fails to commit with -DER_RESTART). In the initial implementation, the transaction API has the following limitations that will be addressed in future DAOS versions: no support for the array API transactional object update and key-value put operations are not visible via object fetch/list and key-value get/list operations executed in the context of the same transaction.","title":"Distributed Transactions"},{"location":"overview/use_cases/","text":"Use Cases This section provides a non-exhaustive list of use cases presenting how the DAOS storage model and stack could be used on a real HPC cluster. This document contains the following sections: Storage Management and Workflow Integration Workflow Execution Bulk Synchronous Checkpoint Producer/Consumer Concurrent Producers Storage Node Failure and Resilvering Storage Management & Workflow Integration In this section, we consider two different cluster configurations: Cluster A: All or a majority of the compute nodes have local persistent memory. In other words, each compute node is also a storage node. Cluster B: Storage nodes are dedicated to storage and disseminated across the fabric. They are not used for computation and thus do not run any application code. At boot time, each storage node starts the DAOS server that instantiates service threads. In cluster A, the DAOS threads are bound to the noisy cores and interact with the FWK if mOS is used. In cluster B, the DAOS server can use all the cores of the storage node. The DAOS server then loads the storage management module. This module scans for local storage on the node and reports the result to a designated master DAOS server that aggregates information about the used and available storage across the cluster. The management module also retrieves the fault domain hierarchy (from a database or specific service) and integrates this with the storage information. The resource manager then uses the DAOS management API to query available storage and allocate a certain amount of storage (i.e. persistent memory) for a new workflow that is to be scheduled. In cluster A, this allocation request may list the compute nodes where the workflow is supposed to run, whereas in case B, it may ask for storage nearby some allocated compute nodes. Once successfully allocated, the master server will initialize a DAOS pool covering the allocated storage by formatting the VOS layout (i.e. fallocate(1) a PMEM file & create VOS super block) and starting the pool service which will initiate the Raft engine in charge of the pool membership and metadata. At this point, the DAOS pool is ready to be handed off to the actual workflow. When the workflow starts, one rank connects to the DAOS pool, then uses local2global() to generate a global connection handle and shares it with all the other application ranks that use global2local() to create a local connection handle. At that point, new containers can be created and existing ones opened collectively or individually by the application tasks. Workflow Execution We consider the workflow represented in the figure below. Each green box represents a different container. All containers are stored in the same DAOS pool represented by the grey box. The simulation reads data from the input container and writes raw timesteps to another container. It also regularly dumps checkpoints to a dedicated ckpt container. The down-sample job reads the raw timesteps and generates sampled timesteps to be analyzed by the post-process which stores analysis data into yet another container. Bulk Synchronous Checkpoint Defensive I/O is used to manage a large simulation run over a period of time larger than the platform's mean time between failure (MTBF). The simulation regularly dumps the current computation state to a dedicated container used to guarantee forward progress in the event of failures. This section elaborates on how checkponting could be implemented on top of the DAOS storage stack. We first consider the traditional approach relying on blocking barriers and then a more loosely coupled execution. Blocking Barrier When the simulation job starts, one task opens the checkpoint container and fetches the current global HCE. It thens obtains an epoch hold and shares the data (the container handle, the current LHE and global HCE) with peer tasks. Each task checks for the latest computation state saved to the checkpoint container by reading with an epoch equal to the global HCE and resumes computation from where it was last checkpointed. To checkpoint, each task executes a barrier to synchronize with the other tasks, writes its current computation state to the checkpoint container at epoch LHE, flushes all updates and finally executes another barrier. Once all tasks have completed the last barrier, one designated task (e.g. rank 0) commits the LHE which is then increased by one on successful commit. This process is repeated regularly until the simulation successfully completes. Non-blocking Barrier We now consider another approach to checkpointing where the execution is more loosely coupled. As in the previous case, one task is responsible for opening the checkpoint container, fetching the global HCE, obtaining an epoch hold and sharing the data with the other peer tasks. However, tasks can now checkpoint their computation state at their own pace without waiting for each other. After the computation of N timesteps, each task dumps its state to the checkpoint container at epoch LHE+1, flushes the changes and calls a non-blocking barrier (e.g. MPI_Ibarrier()) once done. Then after another N timesteps, the new checkpoint is written with epoch LHE+2 and so on. For each checkpoint, the epoch number is incremented. Moreover, each task regularly calls MPI_Test() to check for barrier completion which allows them to recycle the MPI_Request. Upon barrier completion, one designated task (typically rank 0) also commits the associated epoch number. All epochs are guaranteed to be committed in sequence and each committed epoch is a new consistent checkpoint to restart from. On failure, checkpointed states that have been written by individual tasks, but not committed, are automatically rolled back. Producer/Consumer In the previous figure , we have two examples of producer/consumer. The down-sample job consumes raw timesteps generated by the simulation job and produces sampled timesteps analysed by the post-process job. The DAOS stack provides specific mechanims for producer/consumer workflow which even allows the consumer to dumps the result of its analysis into the same container as the producer. Private Container The down-sample job opens the sampled timesteps container, fetchs the current global HCE, obtains an epoch hold and writes new sampled data to this container at epoch LHE. While this is occurring, the post process job opens the container storing analyzed data for write, checks for the latest analyzed timesteps and obtains an epoch hold on this container. It then opens the sampled timesteps container for read, and checks whether the next time-step to be consumed is ready. If not, it waits for a new global HCE to be committed (notified by asynchronous event completion on the event queue) and checks again. When the requested time-step is available, the down-sample job processes input data for this new time-step, dumps the results in its own container and updates the latest analyzed time-step in its metadata. It then commits updates to its output container and waits again for a new epoch to be committed and repeats the same process. Another approach is for the producer job to create explicit snapshots for epochs of interest and have the analysis job waiting and processing snapshots. This avoid processing every single committed epoch. Shared Container We now assume that the container storing the sampled timesteps and the one storing the analyzed data are a single container. In other words, the down-sample job consumes input data and writes output data to the same container. The down-sample job opens the shared container, obtains an hold and dumps new sampled timesteps to the container. As before, the post-process job also opens the container, fetches the latest analyzed timestep, but does not obtain an epoch hold until a new global HCE is ready. Once the post-process job is notified of a new global HCE, it can analyze the new sampled timesteps, obtain an hold and write its analysed data to the same container. Once this is done, the post-process job flushes its updates, commits the held epoch and releases the held epoch. At that point, it can wait again for a new global HCE to be generated by the down-sample job. Concurrent Producers In the previous section, we consider a producer and a consumer job concurrently reading and writing into the same container, but in disjoint objects. We now consider a workflow composed of concurrent producer jobs modifying the same container in a conflicting and uncoordinated manner. This effectively means that the two producers can update the same key of the same KV object or document store or overlapping extents of the same byte array. This model requires the implementation of a concurrency-control mechanism (not part of DAOS) to coordinate conflicting accesses. This section presents an example of such a mechanism based on locking, but alternative approaches can also be considered. A workflow is composed of two applications using a distributed lock manager to serialize contended accesses to DAOS objects. Each application individually opens the same container and grabs an epoch hold whenever it wants to modify some objects in the container. Prior to modifying an object, an application should acquire a write lock on the object. This lock carries a lock value block (LVB) storing the last epoch number in which this object was last modified and committed. Once the lock is acquired, the writer must: read from an epoch equal to the greatest of the epoch specified in the LVB and the handle LRE. submit new writes with an epoch higher than the one in the LVB and the currently held epoch. After all the I/O operations have been completed, flushed, and committed by the application, the LVB is updated with the committed epoch in which the object was modified, and the lock can finally be released. Storage Node Failure and Resilvering In this section, we consider a workflow connected to a DAOS pool and one storage node that suddenly fails. Both DAOS clients and servers communicating with the failed server experience RPC timeouts and inform the RAS system. Failing RPCs are resent repeatedly until the RAS system or the pool metadata service itself decides to declare the storage node dead and evicts it from the pool map. The pool map update, along with the new version, is propagated to all the storage nodes that lazily (in RPC replies) inform clients that a new pool map version is available. Both clients and servers are thus eventually informed of the failure and enter into recovery mode. Server nodes will cooperate to restore redundancy on different servers for the impacted objects, whereas clients will enter in degraded mode and read from other replicas, or reconstruct data from erasure code. This rebuild process is executed online while the container is still being accessed and modified. Once redundancy has been restored for all objects, the poolmap is updated again to inform everyone that the system has recovered from the fault and the system can exit from degraded mode.","title":"Use Cases"},{"location":"overview/use_cases/#use-cases","text":"This section provides a non-exhaustive list of use cases presenting how the DAOS storage model and stack could be used on a real HPC cluster. This document contains the following sections: Storage Management and Workflow Integration Workflow Execution Bulk Synchronous Checkpoint Producer/Consumer Concurrent Producers Storage Node Failure and Resilvering","title":"Use Cases"},{"location":"overview/use_cases/#storage-management-workflow-integration","text":"In this section, we consider two different cluster configurations: Cluster A: All or a majority of the compute nodes have local persistent memory. In other words, each compute node is also a storage node. Cluster B: Storage nodes are dedicated to storage and disseminated across the fabric. They are not used for computation and thus do not run any application code. At boot time, each storage node starts the DAOS server that instantiates service threads. In cluster A, the DAOS threads are bound to the noisy cores and interact with the FWK if mOS is used. In cluster B, the DAOS server can use all the cores of the storage node. The DAOS server then loads the storage management module. This module scans for local storage on the node and reports the result to a designated master DAOS server that aggregates information about the used and available storage across the cluster. The management module also retrieves the fault domain hierarchy (from a database or specific service) and integrates this with the storage information. The resource manager then uses the DAOS management API to query available storage and allocate a certain amount of storage (i.e. persistent memory) for a new workflow that is to be scheduled. In cluster A, this allocation request may list the compute nodes where the workflow is supposed to run, whereas in case B, it may ask for storage nearby some allocated compute nodes. Once successfully allocated, the master server will initialize a DAOS pool covering the allocated storage by formatting the VOS layout (i.e. fallocate(1) a PMEM file & create VOS super block) and starting the pool service which will initiate the Raft engine in charge of the pool membership and metadata. At this point, the DAOS pool is ready to be handed off to the actual workflow. When the workflow starts, one rank connects to the DAOS pool, then uses local2global() to generate a global connection handle and shares it with all the other application ranks that use global2local() to create a local connection handle. At that point, new containers can be created and existing ones opened collectively or individually by the application tasks.","title":"Storage Management &amp; Workflow Integration"},{"location":"overview/use_cases/#workflow-execution","text":"We consider the workflow represented in the figure below. Each green box represents a different container. All containers are stored in the same DAOS pool represented by the grey box. The simulation reads data from the input container and writes raw timesteps to another container. It also regularly dumps checkpoints to a dedicated ckpt container. The down-sample job reads the raw timesteps and generates sampled timesteps to be analyzed by the post-process which stores analysis data into yet another container.","title":"Workflow Execution"},{"location":"overview/use_cases/#bulk-synchronous-checkpoint","text":"Defensive I/O is used to manage a large simulation run over a period of time larger than the platform's mean time between failure (MTBF). The simulation regularly dumps the current computation state to a dedicated container used to guarantee forward progress in the event of failures. This section elaborates on how checkponting could be implemented on top of the DAOS storage stack. We first consider the traditional approach relying on blocking barriers and then a more loosely coupled execution. Blocking Barrier When the simulation job starts, one task opens the checkpoint container and fetches the current global HCE. It thens obtains an epoch hold and shares the data (the container handle, the current LHE and global HCE) with peer tasks. Each task checks for the latest computation state saved to the checkpoint container by reading with an epoch equal to the global HCE and resumes computation from where it was last checkpointed. To checkpoint, each task executes a barrier to synchronize with the other tasks, writes its current computation state to the checkpoint container at epoch LHE, flushes all updates and finally executes another barrier. Once all tasks have completed the last barrier, one designated task (e.g. rank 0) commits the LHE which is then increased by one on successful commit. This process is repeated regularly until the simulation successfully completes. Non-blocking Barrier We now consider another approach to checkpointing where the execution is more loosely coupled. As in the previous case, one task is responsible for opening the checkpoint container, fetching the global HCE, obtaining an epoch hold and sharing the data with the other peer tasks. However, tasks can now checkpoint their computation state at their own pace without waiting for each other. After the computation of N timesteps, each task dumps its state to the checkpoint container at epoch LHE+1, flushes the changes and calls a non-blocking barrier (e.g. MPI_Ibarrier()) once done. Then after another N timesteps, the new checkpoint is written with epoch LHE+2 and so on. For each checkpoint, the epoch number is incremented. Moreover, each task regularly calls MPI_Test() to check for barrier completion which allows them to recycle the MPI_Request. Upon barrier completion, one designated task (typically rank 0) also commits the associated epoch number. All epochs are guaranteed to be committed in sequence and each committed epoch is a new consistent checkpoint to restart from. On failure, checkpointed states that have been written by individual tasks, but not committed, are automatically rolled back.","title":"Bulk Synchronous Checkpoint"},{"location":"overview/use_cases/#producerconsumer","text":"In the previous figure , we have two examples of producer/consumer. The down-sample job consumes raw timesteps generated by the simulation job and produces sampled timesteps analysed by the post-process job. The DAOS stack provides specific mechanims for producer/consumer workflow which even allows the consumer to dumps the result of its analysis into the same container as the producer. Private Container The down-sample job opens the sampled timesteps container, fetchs the current global HCE, obtains an epoch hold and writes new sampled data to this container at epoch LHE. While this is occurring, the post process job opens the container storing analyzed data for write, checks for the latest analyzed timesteps and obtains an epoch hold on this container. It then opens the sampled timesteps container for read, and checks whether the next time-step to be consumed is ready. If not, it waits for a new global HCE to be committed (notified by asynchronous event completion on the event queue) and checks again. When the requested time-step is available, the down-sample job processes input data for this new time-step, dumps the results in its own container and updates the latest analyzed time-step in its metadata. It then commits updates to its output container and waits again for a new epoch to be committed and repeats the same process. Another approach is for the producer job to create explicit snapshots for epochs of interest and have the analysis job waiting and processing snapshots. This avoid processing every single committed epoch. Shared Container We now assume that the container storing the sampled timesteps and the one storing the analyzed data are a single container. In other words, the down-sample job consumes input data and writes output data to the same container. The down-sample job opens the shared container, obtains an hold and dumps new sampled timesteps to the container. As before, the post-process job also opens the container, fetches the latest analyzed timestep, but does not obtain an epoch hold until a new global HCE is ready. Once the post-process job is notified of a new global HCE, it can analyze the new sampled timesteps, obtain an hold and write its analysed data to the same container. Once this is done, the post-process job flushes its updates, commits the held epoch and releases the held epoch. At that point, it can wait again for a new global HCE to be generated by the down-sample job.","title":"Producer/Consumer"},{"location":"overview/use_cases/#concurrent-producers","text":"In the previous section, we consider a producer and a consumer job concurrently reading and writing into the same container, but in disjoint objects. We now consider a workflow composed of concurrent producer jobs modifying the same container in a conflicting and uncoordinated manner. This effectively means that the two producers can update the same key of the same KV object or document store or overlapping extents of the same byte array. This model requires the implementation of a concurrency-control mechanism (not part of DAOS) to coordinate conflicting accesses. This section presents an example of such a mechanism based on locking, but alternative approaches can also be considered. A workflow is composed of two applications using a distributed lock manager to serialize contended accesses to DAOS objects. Each application individually opens the same container and grabs an epoch hold whenever it wants to modify some objects in the container. Prior to modifying an object, an application should acquire a write lock on the object. This lock carries a lock value block (LVB) storing the last epoch number in which this object was last modified and committed. Once the lock is acquired, the writer must: read from an epoch equal to the greatest of the epoch specified in the LVB and the handle LRE. submit new writes with an epoch higher than the one in the LVB and the currently held epoch. After all the I/O operations have been completed, flushed, and committed by the application, the LVB is updated with the committed epoch in which the object was modified, and the lock can finally be released.","title":"Concurrent Producers"},{"location":"overview/use_cases/#storage-node-failure-and-resilvering","text":"In this section, we consider a workflow connected to a DAOS pool and one storage node that suddenly fails. Both DAOS clients and servers communicating with the failed server experience RPC timeouts and inform the RAS system. Failing RPCs are resent repeatedly until the RAS system or the pool metadata service itself decides to declare the storage node dead and evicts it from the pool map. The pool map update, along with the new version, is propagated to all the storage nodes that lazily (in RPC replies) inform clients that a new pool map version is available. Both clients and servers are thus eventually informed of the failure and enter into recovery mode. Server nodes will cooperate to restore redundancy on different servers for the impacted objects, whereas clients will enter in degraded mode and read from other replicas, or reconstruct data from erasure code. This rebuild process is executed online while the container is still being accessed and modified. Once redundancy has been restored for all objects, the poolmap is updated again to inform everyone that the system has recovered from the fault and the system can exit from degraded mode.","title":"Storage Node Failure and Resilvering"}]}